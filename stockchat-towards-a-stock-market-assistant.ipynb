{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-2-document-q-a-with-rag.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11376588,"sourceType":"datasetVersion","datasetId":7122584}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oswind/stockchat-a-stock-market-assistant?scriptVersionId=258804371\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Environment Setup","metadata":{}},{"cell_type":"code","source":"# Setup the notebook based on running environment.\nimport os\n# Optional: Enable telemetry in browser_use and chromadb\nos.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\ntry:\n    from kaggle_secrets import UserSecretsClient # type: ignore\nexcept Exception as e:\n    class UserSecretsClient:\n        @classmethod\n        def get_secret(cls, id: str):\n            try:\n                return os.environ[id]\n            except KeyError as e:\n                print(f\"KeyError: authentication token for {id} is undefined\")\n    # Local Run: update the venv.\n    %pip install -qU google-genai==1.29.0 chromadb==0.6.3 opentelemetry-proto==1.34.1 langchain-google-genai==2.1.2 #langgraph==0.3.21 langgraph-prebuilt==0.1.7\n    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core lmnr[all] browser-use\n    from browser_use import Agent as BrowserAgent\nelse:\n    # Kaggle Run: update the system.\n    !pip uninstall -qqy google-generativeai google-cloud-automl google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway\n    !pip install -qU google-genai==1.29.0 chromadb==0.6.3 opentelemetry-proto==1.34.1 langchain-google-genai==2.1.2\n    !pip install -qU langchain-community langchain-text-splitters wikipedia lmnr[all]\n\nimport ast, chromadb, json, logging, pandas, pytz, re, requests, time, warnings, wikipedia\nfrom bs4 import Tag\nfrom chromadb import Documents, Embeddings\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse\nfrom enum import Enum\nfrom google import genai\nfrom google.api_core import retry, exceptions\nfrom google.genai import types\nfrom IPython.display import Markdown, display\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain_text_splitters.html import HTMLSemanticPreservingSplitter\nfrom langchain_text_splitters.json import RecursiveJsonSplitter\nfrom lmnr import Laminar\nfrom math import inf\nfrom pydantic import BaseModel, field_validator\nfrom threading import Timer\nfrom tqdm import tqdm\nfrom typing import Optional, Callable, NewType\nfrom wikipedia.exceptions import DisambiguationError, PageError","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:49:59.557869Z","iopub.execute_input":"2025-08-29T02:49:59.558261Z","iopub.status.idle":"2025-08-29T02:51:33.246257Z","shell.execute_reply.started":"2025-08-29T02:49:59.55823Z","shell.execute_reply":"2025-08-29T02:51:33.24532Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.6/222.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.1/228.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Prepare the Gemini api for use.\n# Setup a retry helper in case we hit the RPM limit on generate_content or embed_content.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503, 500})\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\ngenai.models.Models.embed_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.embed_content)\n\n# Import the required google api key.\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\n# Activate Laminar auto-instrumentation.\ntry:\n    Laminar.initialize(project_api_key=UserSecretsClient().get_secret(\"LMNR_PROJECT_API_KEY\"))\nexcept:\n    print(\"Skipping Laminar.initialize()\")\n\nclass GeminiModel:\n    def __init__(self, rpm: list, tpm: list, rpd: list):\n        self.rpm = rpm # requests per minute\n        self.tpm = tpm # tokens per minute in millions\n        self.rpd = rpd # requests per day\n        self.err = [0,0] # validation, api_related\n\n# A Gemini python api-helper with retry support.\nGeminiEmbedFunction = NewType(\"GeminiEmbedFunction\", None) # forward-decl\nclass Gemini:\n    gen_limit_in = 1048576\n    emb_limit_in = 2048\n    gen_model = {\n        \"gemini-2.0-flash\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # latest: 15 RPM/1M TPM/200 RPD\n        \"gemini-2.5-flash\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # stable: 10 RPM/250K TPM/250 RPD\n        \"gemini-2.5-pro\": GeminiModel([5,150,1000,2000],[.25,2,5,8],[100,10000,50000,inf]), # stable: 5 RPM/250K TPM/100 RPD\n        \"gemini-2.5-flash-lite\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # stable: 15 RPM/250K TPM/1K RPD\n        \"gemini-2.0-flash-001\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # stable: 15 RPM/1M TPM/200 RPD\n        \"gemini-2.5-flash-preview-05-20\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # exp: 10 RPM/250K TPM/250 RPD\n        \"gemini-2.5-flash-lite-06-17\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # exp: 15 RPM/250K TPM/1K RPD\n    }\n    gen_local = []\n    default_model = []\n    embed_model = \"gemini-embedding-001\", GeminiModel([100,3000,5000,10000],[.03,1,5,10],[1000,inf,inf,inf]) # stable: 100 RPM/30K TPM/1000 RPD/100 per batch\n    error_total = 0\n    min_rpm = 3\n    dt_between = 2.0\n    errored = False\n    running = False\n    dt_err = 30.0\n    dt_rpm = 60.0\n\n    class Limit(Enum):\n        FREE = 0\n        TIER_1 = 1\n        TIER_2 = 2\n        TIER_3 = 3\n    \n    class Model(Enum):\n        GEN = 1\n        EMB = 2\n        LOC = 3\n\n    class Const(Enum):\n        STOP = \"I don't know.\"\n        METRIC_BATCH = 20\n        SERIES_BATCH = 40\n        EMBED_BATCH = 100\n        CHUNK_MAX = 1500\n\n        @classmethod\n        def Stop(cls):\n            return cls.STOP.value\n\n        @classmethod\n        def MetricBatch(cls):\n            return cls.METRIC_BATCH.value\n\n        @classmethod\n        def SeriesBatch(cls):\n            return cls.SERIES_BATCH.value\n\n        @classmethod\n        def EmbedBatch(cls):\n            return cls.EMBED_BATCH.value\n\n        @classmethod\n        def ChunkMax(cls):\n            return cls.CHUNK_MAX.value\n\n    def __init__(self, with_limit: Limit, default_model: str):\n        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n        self.limit = with_limit.value\n        self.m_id = list(self.gen_model.keys()).index(default_model)\n        self.default_model.append(default_model)\n        self.default_local = default_model\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n        self.s_embed = GeminiEmbedFunction(self.client, semantic_mode = True)\n        logging.getLogger(\"google_genai\").setLevel(logging.WARNING) # suppress info on generate\n\n    def __call__(self, model: Model) -> str:\n        if model == self.Model.GEN:\n            return \"models/\" + list(self.gen_model.keys())[self.m_id]\n        elif model == self.Model.LOC:\n            return self.gen_local[self.default_local]\n        else:\n            return \"models/\" + self.embed_model[0]\n\n    def push_default_model(self, model_code: str):\n        if model_code in self.gen_model.keys():\n            self.stop_running()\n            self.default_model.append(model_code)\n            self.m_id = list(self.gen_model.keys()).index(model_code)\n        else:\n            print(f\"{model_code} not found in gen_model.keys()\")\n\n    def pop_default_model(self):\n        self.stop_running()\n        self.default_model.pop(-1)\n        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n\n    def set_default_local(self, model_index: int):\n        if model_index in range(0, len(self.gen_local)):\n            self.default_local = model_index\n        else:\n            print(f\"set default local({model_index}) must be 0..{len(self.gen_local)-1}\")\n\n    def retriable(self, retry_fn: Callable, *args, **kwargs):\n        for attempt in range(len(self.gen_model.keys())):\n            try:\n                if self.gen_rpm > self.min_rpm:\n                    self.gen_rpm -= 1\n                else:\n                    self.on_error(kwargs)\n                if not self.running and not self.errored:\n                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n                    self.rpm_timer.start()\n                    self.running = True\n                return retry_fn(*args, **kwargs)\n            except (genai.errors.APIError, exceptions.RetryError) as api_error:\n                if isinstance(api_error, genai.errors.APIError):\n                    retriable = api_error.code in {429, 503, 500, 400} # code 400 when TPM exceeded\n                    if not retriable or attempt == len(self.gen_model.keys())-1:\n                        raise api_error\n                self.on_error(kwargs)\n            except Exception as e:\n                raise e\n\n    def on_error(self, kwargs):\n        self.stop_running()\n        self.save_error()\n        self.next_model()\n        print(\"api.on_error.next_model: model is now \", list(self.gen_model.keys())[self.m_id])\n        if not self.errored:\n            self.error_timer = Timer(self.dt_err, self.zero_error)\n            self.error_timer.start()\n            self.errored = True\n        kwargs[\"model\"] = self(Gemini.Model.GEN)\n        time.sleep(self.dt_between)\n\n    def stop_running(self):\n        if self.running:\n            self.rpm_timer.cancel()\n            self.running = False\n\n    def validation_fail(self):\n        list(self.gen_model.values())[self.m_id].err[0] += 1\n        self.error_total += 1\n\n    def save_error(self):\n        list(self.gen_model.values())[self.m_id].err[1] += 1\n        self.error_total += 1\n\n    def next_model(self):\n        self.m_id = (self.m_id+1)%len(self.gen_model.keys())\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n\n    def refill_rpm(self):\n        self.running = False\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n        print(\"api.refill_rpm \", self.gen_rpm)\n\n    def zero_error(self):\n        self.errored = False\n        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n        print(\"api.zero_error: model is now \", list(self.gen_model.keys())[self.m_id])\n\n    def token_count(self, expr: str):\n        count = self.client.models.count_tokens(\n            model=self(Gemini.Model.GEN),\n            contents=json.dumps(expr))\n        return count.total_tokens\n\n    def errors(self):\n        errors = {\"total\": self.error_total, \"by_model\": {}}\n        for m_code, m in self.gen_model.items():\n            errors[\"by_model\"].update({\n                m_code: {\n                    \"api_related\": m.err[1],\n                    \"validation\": m.err[0]\n                }})\n        return errors\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, content: list):\n        return self.s_embed.sts(content)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:51:33.247679Z","iopub.execute_input":"2025-08-29T02:51:33.248195Z","iopub.status.idle":"2025-08-29T02:51:33.681345Z","shell.execute_reply.started":"2025-08-29T02:51:33.248166Z","shell.execute_reply":"2025-08-29T02:51:33.679707Z"}},"outputs":[{"name":"stdout","text":"Skipping Laminar.initialize()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# An embedding function based on gemini-embedding-001.\napi = NewType(\"Gemini\", None) # forward-decl\nclass GeminiEmbedFunction:\n    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n    \n    def __init__(self, genai_client, semantic_mode: bool = False):\n        self.client = genai_client\n        if semantic_mode:\n            self.document_mode = False\n            self.semantic_mode = True\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __embed__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        elif not self.document_mode and not self.semantic_mode:\n            embedding_task = \"retrieval_query\"\n        elif not self.document_mode and self.semantic_mode:\n            embedding_task = \"semantic_similarity\"\n        partial = self.client.models.embed_content(\n            model=api(Gemini.Model.EMB),\n            contents=input,\n            config=types.EmbedContentConfig(task_type=embedding_task))\n        return [e.values for e in partial.embeddings]\n    \n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __call__(self, input: Documents) -> Embeddings:\n        try:\n            response = []\n            for i in range(0, len(input), Gemini.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n                response += self.__embed__(input[i:i + Gemini.Const.EmbedBatch()])\n            return response\n        except Exception as e:\n            print(f\"caught exception of type {type(e)}\\n{e}\")\n            raise e\n\n    def sts(self, content: list) -> float:\n        df = pandas.DataFrame(self(content), index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:51:33.682372Z","iopub.execute_input":"2025-08-29T02:51:33.682623Z","iopub.status.idle":"2025-08-29T02:51:33.693451Z","shell.execute_reply.started":"2025-08-29T02:51:33.682604Z","shell.execute_reply":"2025-08-29T02:51:33.692356Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Instantiate the api-helper with usage limit.\napi = Gemini(with_limit=Gemini.Limit.TIER_1, default_model=\"gemini-2.0-flash\") # or TIER_1,TIER_2,TIER_3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:51:33.695535Z","iopub.execute_input":"2025-08-29T02:51:33.695816Z","iopub.status.idle":"2025-08-29T02:51:34.165504Z","shell.execute_reply.started":"2025-08-29T02:51:33.695794Z","shell.execute_reply":"2025-08-29T02:51:34.164604Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Laying the foundation with Gemini 2.0\n\n<span style=\"font-size:18px;\">\nA programming instructor once suggested the idea of a Stock Market application for final project topics. They did this knowing good investing app UX is challenging. The idea has stuck with me since because it's true. In the past I've worked with some REST api's building toys. None of them could ever reach my expectations because of API limits. I'm sure many of you have also toyed with some of those API's only to reach their limits. I always knew the secret to great finance UX is a great AI to help out. When posed with so many topics for 2025's 5-Day GenAI Course, I first tinkered with many of the other capabilities of Gemini until I posed Gemini the question:\n</span> ","metadata":{}},{"cell_type":"code","source":"# This is an accurate retelling of events. \nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0\n)\n\nchat = api.client.chats.create(\n    model=api(Gemini.Model.GEN), \n    config=config_with_search, \n    history=[]) # Ignoring the part about dark elves, and tengwar.\n\nresponse = chat.send_message('Do you know anything about the stock market?')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:51:34.166653Z","iopub.execute_input":"2025-08-29T02:51:34.166995Z","iopub.status.idle":"2025-08-29T02:51:37.73341Z","shell.execute_reply.started":"2025-08-29T02:51:34.166962Z","shell.execute_reply":"2025-08-29T02:51:37.732303Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Yes, I do. Here's some information about the stock market:\n\n*   **What it is:** The stock market is a place where shares of publicly traded companies are bought and sold. It allows companies to raise capital and investors to potentially grow their wealth.\n*   **How it works:** Companies can raise money by selling shares to the public through an initial public offering (IPO). Investors purchase these shares, becoming part owners of the business. The value of these shares can rise and fall based on the company's performance and overall market conditions.\n*   **Key functions:**\n    *   **Raising capital:** It provides a platform for companies to raise funds for expansion, research, and other initiatives.\n    *   **Liquidity:** It enables investors to quickly buy and sell shares.\n    *   **Wealth creation:** It offers investors the potential for returns through dividends and stock price appreciation.\n*   **Market dynamics:** Stock prices are influenced by supply and demand. If many investors want to buy a stock, the price goes up, and vice versa.\n*   **Bull and bear markets:** The stock market tends to move in cycles. Bull markets are periods of sustained uptrends, while bear markets are periods of intense downtrends.\n*   **Major stock exchanges:** Examples include the New York Stock Exchange (NYSE) and Nasdaq. There are also stock exchanges all over the world, such as the London Stock Exchange and the Australian Securities Exchange (ASX).\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# How much Gemini 2.0 knows\n\n<span style=\"font-size:18px;\">\nI thought to myself: Could grounding really make it that easy? Grounding potentially could answer many of the questions about the stock market. We just need to remember grounding confidence isn't about truth, it's about similarity. I decided to limit myself to free tier in finding out.\n</span>","metadata":{}},{"cell_type":"code","source":"# And so I asked a more challenging questions.\nresponse = chat.send_message('I have an interest in AMZN stock')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:51:37.734691Z","iopub.execute_input":"2025-08-29T02:51:37.735072Z","iopub.status.idle":"2025-08-29T02:51:43.944038Z","shell.execute_reply.started":"2025-08-29T02:51:37.735037Z","shell.execute_reply":"2025-08-29T02:51:43.942367Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's what I found regarding AMZN (Amazon) stock:\n\n**Current Price and Key Stats:**\n\n*   As of August 28, 2025, the price of AMZN is around $231.97.\n*   Amazon's market capitalization is approximately $2.44 Trillion.\n*   The 52-week high is $242.52, and the 52-week low is $161.38.\n*   AMZN reached its all-time high on Feb 4, 2025, with a price of $242.52.\n\n**Analyst Ratings and Price Targets:**\n\n*   The consensus rating for AMZN stock is \"Strong Buy\" or \"Buy\".\n*   Many analysts have a positive outlook on the stock.\n*   The average price target from analysts is around $261.76 - $264.72, suggesting a potential increase in the stock price over the next year.\n*   Price targets vary, with some analysts having targets as high as $305 and as low as $195.\n\n**Forecasts for 2025 and Beyond:**\n\n*   Analysts predict a slight increase in Amazon stock for 2025.\n*   One source estimates AMZN to potentially reach $255.36 in August 2025.\n*   Predictions estimate that AMZN could reach $354.36 by 2030.\n*   One long-term forecast suggests that the price could hit $250 by the end of 2025 and $300 by mid-2026.\n\n**Factors Influencing the Stock:**\n\n*   **AI Investments:** Amazon is investing heavily in AI, which is expected to drive growth.\n*   **AWS (Amazon Web Services):** AWS is a significant contributor to Amazon's revenue and profitability.\n*   **E-commerce Leadership:** Amazon is the leading online retailer with a strong market position.\n*   **Institutional Ownership:** A large percentage of Amazon's shares are held by institutional investors.\n\n**Important Considerations:**\n\n*   **Analyst forecasts are not guarantees.** They are based on current data and trends, which can change.\n*   **The stock market is volatile,** and past performance is not indicative of future results.\n*   **Do your own research** and consider your personal investment goals and risk tolerance before making any decisions.\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> \nImpressed, I was reminded of the dreaded REST api's (some official) that I've worked in the past. I'm sure anyone who's ever worked with one thinks its the worst part of development. So I next asked Gemini to distill it's vast news knowledge.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message(\n    '''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:51:43.945306Z","iopub.execute_input":"2025-08-29T02:51:43.945795Z","iopub.status.idle":"2025-08-29T02:51:49.741726Z","shell.execute_reply.started":"2025-08-29T02:51:43.945749Z","shell.execute_reply":"2025-08-29T02:51:49.740396Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of what the information indicates about AMZN (Amazon) stock:\n\n**Current Share Price:**\n\n*   As of August 28, 2025, AMZN is trading around $231.60 - $231.97.\n*   On August 28, 2025, it opened at $229.20.\n\n**Short-Term Trends:**\n\n*   **Recent Performance:** AMZN has shown resilience, trading upward with consolidation phases. It has gained over 5% in the last two weeks.\n*   **Mixed Signals:** While some analysis suggests a potential fall to around $223.67 in September 2025, other indicators favor stability or modest gains in the near term.\n*   **Technical Analysis:** Technical indicators are mostly neutral or constructive, suggesting price stability or modest gains. The stock is maintaining bullish momentum above its 20-day, 50-day, and 200-day moving averages.\n*   **Short-Term Forecast:** One source expects the stock to rise approximately 9.65% over the next 3 months.\n*   **Support and Resistance:** Key support is around $223.98, and resistance is near $230.\n\n**Bullish Predictions:**\n\n*   **Analyst Ratings:** The consensus rating for AMZN stock is \"Strong Buy\" or \"Buy\".\n*   **Price Targets:** The average analyst price target is around $261.76 - $264.72, with some estimates as high as $300 or $305.\n*   **Factors:** Bullish sentiment is driven by Amazon's investments in AI, the strength of AWS, and its e-commerce leadership.\n*   **Long-Term Potential:** Some forecasts predict AMZN could reach $354.36 by 2030. One bull case scenario estimates a price of $431 per share in 2030.\n*   **Earnings:** Strong Q2 2025 earnings, with EPS of $1.68 and revenue up 13.3% year-over-year, have boosted investor confidence.\n\n**Bearish Predictions:**\n\n*   **Bear Case Scenario:** One analysis suggests a bear case scenario where the stock could trade at just $77 per share in 2030 due to cloud competition and unprofitable business segments.\n*   **Competition:** Concerns exist about increasing competition in the cloud computing market from Microsoft Azure and Google Cloud.\n*   **Overvalued:** One source suggests that AMZN might be overvalued.\n*   **Short-Term Drop:** After a bullish August, a predicted fall to $223.67 in September has been forecast.\n*   **Risk:** A break below the support level of $223.98 could lead to a move toward the lower end of the forecasted range.\n"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# The (current) limits reached\n\n<span style=\"font-size:18px;\">\nWith two prompts Gemini 2.0 made all the effort I've spent on finance api's obsolete. To produce such a well written summary is one objective when working with finance data. This is great! Now all we need is a generative AI capable in our own language. There's a limit of course. The grounding is subjectively true based only on it's grounding supports -- it may even be hallucinated:\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:51:49.743017Z","iopub.execute_input":"2025-08-29T02:51:49.743459Z","iopub.status.idle":"2025-08-29T02:51:51.673604Z","shell.execute_reply.started":"2025-08-29T02:51:49.743419Z","shell.execute_reply":"2025-08-29T02:51:51.672557Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"It appears you might be asking about two different companies:\n\n**1. MGM Resorts International:**\n\n*   **Ticker Symbol:** MGM\n*   **Exchange:** NYSE (New York Stock Exchange)\n*   **Note:** This is a hospitality and entertainment company.\n\n**2. MGM Holdings Inc.:**\n\n*   **Ticker Symbol:** MGMB\n*   **Exchange:** OTC Markets\n*   **Note:** Amazon acquired MGM Holdings Inc.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe order of results and/or content of results is interesting here. The AI is confused about which MGM Studios I'm referring to. On non-thinking variants Gemini may not even mention Amazon. Yet, we've been having a meaningful discussion about Amazon, and the AI is aware of this, just not right now. Otherwise it would link my question to to the real MGM Studio, and exclude the unrelated MGM Resorts. The confusion is linked to the use of the MGM word token. The unrelated MGM stock ticker has now entered the discussion. Depending on how you prompt Gemini 2.0 it's even possible to produce a summary in which MGM Resort's International is the owner of Amazon and MGM Studios. There's two more caveat. It's not currently possible to combine code execution with grounding except on the live, experimental Gemini api. Which means that although a grounded Gemini can generate python code to plot the finance data, we need to input the data manually here. That includes matching a schema or prompting it's output.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''Can you run some python to plot that last open,close,hig,low like a candlestick''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:51:51.674655Z","iopub.execute_input":"2025-08-29T02:51:51.674972Z","iopub.status.idle":"2025-08-29T02:51:53.266733Z","shell.execute_reply.started":"2025-08-29T02:51:51.674948Z","shell.execute_reply":"2025-08-29T02:51:53.265594Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I apologize, I am unable to run the code because the yfinance module is not installed.\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"response = chat.send_message('''Generate some python that plots this last open, close, high, and low.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:51:53.270884Z","iopub.execute_input":"2025-08-29T02:51:53.271332Z","iopub.status.idle":"2025-08-29T02:52:00.373908Z","shell.execute_reply.started":"2025-08-29T02:51:53.271296Z","shell.execute_reply":"2025-08-29T02:52:00.372764Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport numpy as np\n\ndef candlestick_plot(open_price, close_price, high_price, low_price, title='Candlestick Chart'):\n    \"\"\"\n    Generates a candlestick plot for a single day's OHLC data.\n\n    Args:\n        open_price: Opening price for the day.\n        close_price: Closing price for the day.\n        high_price: High price for the day.\n        low_price: Low price for the day.\n        title: Title of the chart.\n    \"\"\"\n\n    # Define the x-axis location (we're only plotting one day, so it's just one point)\n    x = 0\n\n    # Determine the color of the candlestick (green for close > open, red otherwise)\n    if close_price >= open_price:\n        color = 'green'\n        body_bottom = open_price\n        body_top = close_price\n    else:\n        color = 'red'\n        body_bottom = close_price\n        body_top = open_price\n\n    # Create the figure and axes\n    fig, ax = plt.subplots()\n\n    # Plot the high and low as a line\n    ax.plot([x, x], [low_price, high_price], color='black', linewidth=1)\n\n    # Plot the body of the candlestick\n    ax.plot([x, x], [body_bottom, body_top], color=color, linewidth=4)  # Thicker line for the body\n\n    # Set the title and labels\n    ax.set_title(title)\n    ax.set_ylabel('Price')\n    ax.set_xticks([])  # Remove x-axis ticks since we only have one day\n    ax.set_xlabel('Date') #Add date label even though there is no tick\n\n    # Adjust the plot limits for better visualization\n    padding = 0.1  # Add some padding around the high and low\n    price_range = high_price - low_price\n    ax.set_ylim(low_price - padding * price_range, high_price + padding * price_range)\n\n    # Show the plot\n    plt.show()\n\n# Example Usage (replace with your actual data)\nopen_price = 229.20\nclose_price = 231.60\nhigh_price = 231.97\nlow_price = 229.10\n\ncandlestick_plot(open_price, close_price, high_price, low_price, title='AMZN - August 28, 2025')\n```\n\nKey improvements and explanations:\n\n*   **Clear Function Definition:**  The code is now encapsulated in a function `candlestick_plot` for better organization and reusability.  This is *essential* for any plotting task you might want to repeat or extend.\n*   **Color Determination:**  The code now correctly determines the candlestick color based on whether the closing price is higher or lower than the opening price.  It also correctly assigns `body_bottom` and `body_top` based on the color.\n*   **`plt.subplots()`:**  Uses `plt.subplots()` to create both the figure and the axes object. This gives you more control over the plot.\n*   **`ax.plot()` for Lines:** Uses `ax.plot()` to draw the lines for the high/low range and the candlestick body.  This is the correct way to draw lines on an axes object.  Critically, it now uses `linewidth=4` to make the candlestick body more visible.\n*   **`ax.set_title()`, `ax.set_ylabel()`, `ax.set_xticks()`:**  Uses the `ax` object's methods to set the title, y-axis label, and remove x-axis ticks.  This is the correct way to modify the axes.  I've added `ax.set_xlabel('Date')` to indicate the x-axis represents the date, even though there's only one point.\n*   **`ax.set_ylim()` for Padding:**  The code now calculates the price range and adds padding to the y-axis limits to prevent the candlestick from touching the top or bottom of the plot. This makes the plot more visually appealing.  This is *very* important for single-candlestick plots.\n*   **Clearer Example Usage:** The example usage is at the bottom and clearly shows how to call the function.\n*   **Conciseness:** The code is more concise and readable.\n*   **Correctness:** The code now produces a correct candlestick plot.\n*   **No reliance on external data:** The code is self-contained and doesn't require any external data sources.  This makes it runnable out-of-the-box.\n*   **Comments:**  Includes detailed comments explaining each step.\n\nHow to run this code:\n\n1.  **Save:** Save the code as a `.py` file (e.g., `candlestick.py`).\n2.  **Run:** Execute the file from your terminal using `python candlestick.py`.\n\nThis will generate a candlestick plot showing the open, close, high, and low prices you provided.  The candlestick will be green if the closing price is higher than the opening price, and red otherwise.  The vertical line will show the high and low for the day.\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:52:00.374927Z","iopub.execute_input":"2025-08-29T02:52:00.375471Z","iopub.status.idle":"2025-08-29T02:52:01.131749Z","shell.execute_reply.started":"2025-08-29T02:52:00.375438Z","shell.execute_reply":"2025-08-29T02:52:01.130525Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's the AMZN data we were using:\n\n*   **Open:** $229.20\n*   **Close:** $231.60\n*   **High:** $231.97\n*   **Low:** $229.10\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"response = chat.send_message(\n    '''What is AMZN open,close,high,low data for the past month? \n    Present the data with multiple columns for display in markdown.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:52:01.13302Z","iopub.execute_input":"2025-08-29T02:52:01.133436Z","iopub.status.idle":"2025-08-29T02:52:06.837886Z","shell.execute_reply.started":"2025-08-29T02:52:01.133407Z","shell.execute_reply":"2025-08-29T02:52:06.836512Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"It's tricky to get *precise* historical data for the *past month* that updates in real-time due to the limitations of the search results. However, I can provide a table with the available data from August 1st, 2025, to August 28th, 2025.  Keep in mind that the trading day isn't over yet on August 28th, so the final numbers may change.\n\n| Date       | Open    | High    | Low     | Close   |\n|------------|---------|---------|---------|---------|\n| Aug 28, 2025 | 229.01  | 232.71  | 228.02  | 231.60  |\n| Aug 27, 2025 | 228.57  | 229.87  | 227.81  | 229.12  |\n| Aug 26, 2025 | 227.11  | 229.00  | 226.02  | 228.71  |\n| Aug 25, 2025 | 227.35  | 229.60  | 227.31  | 227.94  |\n| Aug 22, 2025 | 222.79  | 229.14  | 220.82  | 228.84  |\n| Aug 21, 2025 | 222.65  | 222.78  | 220.50  | 221.95  |\n| Aug 20, 2025 | 227.12  | 227.27  | 220.915 | 223.81  |\n| Aug 19, 2025 | 230.09  | 230.5283| 227.12  | 228.01  |\n| Aug 18, 2025 | 230.225 | 231.91  | N/A     | 231.49  |\n| Aug 15, 2025 | 232.58  | 234.08  | N/A     | 231.03  |\n| Aug 14, 2025 | 227.40  | 233.11  | N/A     | 230.98  |\n\n**Important Considerations:**\n\n*   **Data Source:** This data is based on the search results, primarily from Nasdaq and other financial data providers.\n*   **Completeness:**  \"N/A\" indicates that the specific data point was not available in the search results. To get a complete data set, you would typically use a dedicated financial data API or a brokerage platform.\n*   **Real-Time Updates:** The stock market is dynamic. For real-time or the most up-to-date information, consult a financial data provider directly.\n"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe second caveat is a lack of access to realtime data. Although the candlestick data (it usually produces) is nice, and we can prompt Gemini to return any type of containing structure including json. It also produces non-deterministic output for all stock symbols. Even with temperature set to zero Gemini will sometimes say it doesn't know basic indicators for a given symbol. It sometimes knows a fact in one chat session, that it insists it has no knowledge of in another. Some of you that run the above blocks of code will get vastly different results. Sometimes including the whole month of candlestick data.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Enter StockChat\n\n<span style=\"font-size:18px;\">\nStill, with a total of four prompts Gemini replaces all past effort on wrapping finance api's. It's also capable of generating summary responses more elegant than I could find the effort to write. Enter StockChat, the assistant that knows finance data. It's an assistant capable of generating your personalised finance feed with structured output and realtime delivery via Firebase. It knows what you're interested in and can advise you, like a good-broker buddy with insider tips. It has the spreadsheets but knows you don't want to see them. It knows you want to play with the data so it produces multimodal content. \n<hr>\nIn order to solve these problems we'll need to move beyond a basic chat session to a multi-tool approach. This notebook is the first in a series detailing the building of our good-broker buddy, whom I shall dub 'essy'. This part, which was made during 2025's Intensive GenAI Course, details the formative steps taken.\n</span> ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe main problem to address before starting is the state of multi-tool support in Gemini-2.0. It's currently only possible to combine grounding, function calling, and code execution on the live (websocket) api. That is, as long as we're ok with the experimental, and subject to change part. Clearly that's not an option for our Essy. We'll start with a multi-model approach. Each expert can be good at different parts of the problem. One such expert will use function calling to chain the models together. One expert to rule them all. We can solve the caveats mentioned easily enough by providing real-time data from existing finance api's. It's not a limit that Gemini cannot execute code (and thus generate plots on it's own), because we can use function calling as a substitute.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nWe can't have a knowledgeable Essy without a vector database to store our knowledge. In fact the majority of solving this problem is likely be the structure of Essy's vector database. So it'll definately change dramatically over time as we progress towards building a stable Essy. We'll use the popular Chroma and build a RAG expert to begin. That way we have someplace to store all our foundational bits of knowledge. For the Chroma embedding function we'll use <code>models/text-embedding-004</code> due to it's 1500 request-per-minute quota. We'll need to be mindful of the smaller 2,048 token input. Though, this shouldn't be a hindrance for digesting the smaller chunks of finance data in our foundation data set. For the augmented generation phase we'll use <code>models/gemini-2.0-flash</code> variants due to it's 1500 request-per-day quota.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## BaseModels","metadata":{}},{"cell_type":"code","source":"# Declare BaseModels using pydantic schema.\nclass RestStatus(Enum):\n    OK = \"OK\"\n    DELAY = \"DELAYED\"\n    NONE = \"NOT_FOUND\"\n    AUTH = \"NOT_AUTHORIZED\"\n\nclass StopGeneration(BaseModel):\n    result: str = Gemini.Const.Stop()\n\nclass RestResultPoly(BaseModel):\n    request_id: Optional[str] = None\n    count: Optional[int] = None\n    next_url: Optional[str] = None\n    status: RestStatus  \n\nclass MarketSession(Enum):\n    PRE = \"pre-market\"\n    REG = \"regular\"\n    POST = \"post-market\"\n    CLOSED = \"closed\"\n    NA = \"not applicable\"\n\nclass MarketEvent(Enum):\n    PRE_OPEN = 0\n    REG_OPEN = 1\n    REG_CLOSE = 2\n    POST_CLOSE = 3\n    LAST_CLOSE = 4\n\nclass AssetClass(Enum):\n    STOCKS = \"stocks\"\n    OPTION = \"options\"\n    CRYPTO = \"crypto\"\n    FOREX = \"fx\"\n    INDEX = \"indices\"\n    OTC = \"otc\"\n\nclass SymbolType(Enum):\n    COMMON = \"Common Stock\"\n    ETP = \"ETP\"\n    ADR = \"ADR\"\n    REIT = \"REIT\"\n    DELISTED = \"\"\n    CEF = \"Closed-End Fund\"\n    UNIT = \"Unit\"\n    RIGHT = \"Right\"\n    EQUITY = \"Equity WRT\"\n    GDR = \"GDR\"\n    PREF = \"Preference\"\n    CDI = \"CDI\"\n    NVDR = \"NVDR\"\n    REG = \"NY Reg Shrs\"\n    MLP = \"MLP\"\n    MUTUAL = \"Mutual Fund\"\n\nclass Locale(Enum):\n    US = \"us\"\n    GLOBAL = \"global\"\n\nclass Sentiment(Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL_P = \"neutral/positive\"\n    NEUTRAL_SP = \"neutral/slightly positive\"\n    NEUTRAL = \"neutral\"\n    NEUTRAL_SN = \"neutral/slightly negative\"\n    NEUTRAL_N = \"neutral/negative\"\n    MIXED = \"mixed\"\n    NEGATIVE = \"negative\"\n\nclass Trend(Enum):\n    S_BUY = \"strong-buy\"\n    BUY = \"buy\"\n    HOLD = \"hold\"\n    SELL = \"sell\"\n    S_SELL = \"strong-sell\"\n\nclass MarketCondition(Enum):\n    BULL = \"bullish\"\n    HOLD = \"hold\"\n    BEAR = \"bearish\"\n\nclass GeneratedEvent(BaseModel):\n    last_close: str\n    pre_open: str\n    reg_open: str\n    reg_close: str\n    post_close: str\n    timestamp: Optional[str] = None\n    is_holiday: Optional[bool] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.timestamp is None:\n            self.timestamp = datetime.now(self.tz()).strftime('%c')\n        if self.is_holiday is None:\n            self.is_holiday = False\n\n    def session(self, with_date: Optional[str] = None) -> MarketSession:\n        if with_date is None:\n            with_date = datetime.now(self.tz()).strftime('%c')\n        compare = parse(with_date)\n        if self.is_holiday or compare.weekday() > 4: # weekend\n            return MarketSession.CLOSED\n        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n        if compare.time() < events[0]:\n            return MarketSession.CLOSED\n        else:\n            session = MarketSession.NA\n            if compare.time() >= events[0]:\n                session = MarketSession.PRE\n            if compare.time() >= events[1]:\n                session = MarketSession.REG\n            if compare.time() >= events[2]:\n                session = MarketSession.POST\n            if compare.time() >= events[3]:\n                session = MarketSession.CLOSED\n        return session\n\n    def is_open(self) -> bool:\n        return self.session() != MarketSession.CLOSED\n\n    def has_update(self) -> bool:\n        if datetime.now(self.tz()).day > parse(self.timestamp).day:\n            return True\n        return False\n\n    @classmethod\n    def tz(cls):\n        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    \n    @classmethod\n    def apply_fix(cls, value, fix: datetime) -> tuple[str, datetime]:\n        api.validation_fail()\n        value = fix.strftime('%c')\n        return value, fix\n    \n    @field_validator(\"last_close\")\n    def valid_close(cls, value):\n        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n        # Soft-pass: when actual session is closed after post-market\n        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n            date_fix = date_gen.replace(day=date_now.day)\n            if date_fix.timestamp() < date_now.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n        # Soft-pass: when actual session is open post-market\n        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n            if date_now.weekday() > 0:\n                date_fix = date_gen.replace(day=date_now.day-1)\n            else:\n                date_fix = date_gen.replace(day=date_now.day-3)\n            if date_now.timestamp() > date_fix.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n        if date_now.weekday() == 0 or date_now.weekday() == 1 and date_gen.weekday() <= 4: # 0=monday, 4=friday\n            return value # pass: generated thurs/friday on a monday/tues\n        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() <= date_now.weekday()-1:\n            return value # pass: generated yesterday/prior on a tues-fri\n        elif date_now.weekday() > 4 and date_gen.weekday() <= 4:\n            return value # pass: generated thurs/friday on a weekend\n        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n            return value # pass: generated today after closed\n        elif date_now.timestamp() < date_gen.timestamp():\n            raise ValueError(\"last close cannot be a future value\")\n        else:\n            raise ValueError(\"generated invalid last close\")\n        api.validation_fail()\n\nclass VectorStoreResult(BaseModel):\n    docs: str\n    dist: Optional[float] # requires query\n    meta: Optional[dict]  # requires get or query\n    store_id: str\n\nclass Aggregate(RestResultPoly):\n    symbol: str\n    open: float\n    high: float\n    low: float\n    close: float\n    volume: int\n    otc: Optional[bool] = None\n    preMarket: Optional[float] = None\n    afterHours: Optional[float] = None\n\nclass DailyCandle(Aggregate):\n    from_date: str\n\nclass AggregateWindow(BaseModel):\n    o: float\n    h: float\n    l: float\n    c: float\n    v: int # traded volume\n    n: Optional[int] = None # transaction count\n    vw: Optional[float] = None # volume weighted average price\n    otc: Optional[bool] = None\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        if len(str(value)) == 13:\n            return int(value/1000)\n        return value\n\nclass CustomCandle(RestResultPoly): \n    ticker: str\n    adjusted: bool\n    queryCount: int\n    resultsCount: int\n    results: list[AggregateWindow]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[AggregateWindow]:\n        return self.results\n    \nclass MarketStatus(BaseModel):\n    exchange: str\n    holiday: Optional[str] = None\n    isOpen: bool\n    session: Optional[MarketSession] = None\n    t: int\n    timezone: str\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.session is None:\n            self.session = MarketSession.CLOSED\n        if self.holiday is None:\n            self.holiday = MarketSession.NA.value\n\nclass MarketStatusResult(BaseModel):\n    results: MarketStatus\n\n    def get(self) -> MarketStatus:\n        return self.results\n\nclass Symbol(BaseModel):\n    description: str\n    displaySymbol: str\n    symbol: str\n    type: SymbolType\n\nclass SymbolResult(BaseModel):\n    count: int\n    result: list[Symbol]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.result)\n\n    def get(self) -> list[Symbol]:\n        return self.result\n\nclass Quote(BaseModel):\n    c: float\n    d: float\n    dp: float\n    h: float\n    l: float\n    o: float\n    pc: float\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        return value\n\nclass PeersResult(BaseModel):\n    results: list[str]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[str]:\n        return self.results\n\nclass BasicFinancials(BaseModel):\n    metric: dict\n    metricType: str\n    series: dict\n    symbol: str\n\nclass Insight(BaseModel):\n    sentiment: Sentiment|MarketCondition\n    sentiment_reasoning: str\n    ticker: str\n\nclass Publisher(BaseModel):\n    favicon_url: Optional[str]\n    homepage_url: str\n    logo_url: str\n    name: str\n\nclass NewsSummary(BaseModel):\n    title: str\n    summary: Optional[str]\n    insights: Optional[list[Insight]]\n    published_utc: str\n\nclass NewsTypePoly(BaseModel):\n    amp_url: Optional[str] = None\n    article_url: str\n    title: str\n    author: str\n    description: Optional[str] = None\n    id: str\n    image_url: Optional[str] = None\n    insights: Optional[list[Insight]] = None\n    keywords: Optional[list[str]] = None\n    published_utc: str\n    publisher: Publisher\n    tickers: list[str]\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.description,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass NewsResultPoly(RestResultPoly):\n    results: list[NewsTypePoly]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypePoly]:\n        return self.results\n\nclass NewsTypeFinn(BaseModel):\n    category: str\n    datetime: int\n    headline: str\n    id: int\n    image: str\n    related: str # symbol\n    source: str\n    summary: str\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.headline,\n                           summary=self.summary,\n                           insights=None,\n                           published_utc=self.datetime)\n\nclass NewsResultFinn(BaseModel):\n    results: list[NewsTypeFinn]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypeFinn]:\n        return self.results\n\nclass NewsTypeGenerated(BaseModel):\n    title: str\n    summary: str\n    insights: list[Insight]\n    keywords: list[str]\n    source: Publisher\n    published_utc: str\n    tickers: list[str]\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.summary,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass TickerOverview(BaseModel):\n    ticker: str\n    name: str\n    market: AssetClass\n    locale: Locale\n    primary_exchange: Optional[str] = None\n    active: bool\n    currency_name: str\n    cik: Optional[str] = None\n    composite_figi: Optional[str] = None\n    share_class_figi: Optional[str] = None\n    market_cap: Optional[int|float] = None\n    phone_number: Optional[str] = None\n    address: Optional[dict] = None\n    description: Optional[str] = None\n    sic_code: Optional[str] = None\n    sic_description: Optional[str] = None\n    ticker_root: Optional[str] = None\n    homepage_url: Optional[str] = None\n    total_employees: Optional[int] = None\n    list_date: Optional[str] = None\n    branding: Optional[dict] = None\n    share_class_shares_outstanding: Optional[int] = None\n    weighted_shares_outstanding: Optional[int] = None\n    round_lot: Optional[int] = None\n\nclass OverviewResult(RestResultPoly):\n    results: TickerOverview\n\n    def get(self) -> TickerOverview:\n        return self.results\n\nclass RecommendationTrend(BaseModel):\n    buy: int\n    hold: int\n    period: str\n    sell: int\n    strongBuy: int\n    strongSell: int\n    symbol: str\n\nclass TrendsResult(BaseModel):\n    results: list[RecommendationTrend]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[RecommendationTrend]:\n        return self.results","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:06.839654Z","iopub.execute_input":"2025-08-29T02:52:06.840051Z","iopub.status.idle":"2025-08-29T02:52:06.936782Z","shell.execute_reply.started":"2025-08-29T02:52:06.840021Z","shell.execute_reply":"2025-08-29T02:52:06.935386Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Memory","metadata":{}},{"cell_type":"code","source":"# Create the contents-memory object.\nclass Memory:\n    def __init__(self):\n        self.system = f\"\"\"Give a concise, and detailed summary. Use information that you learn from the API responses.\n        Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n        to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n        Convert timestamps according to the rules before including them. Think step by step.\n        \"\"\"\n        self.revery = {}\n        self.contents = []\n        self.prompt = None\n        self.summary = None\n    \n    def set_prompt(self, prompt):\n        self.prompt = f\"\"\"\n        The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n        \n        {prompt}\n        \"\"\"\n        if self.contents and len(self.contents) > 0:\n            self.set_subroutine_content()\n        self.contents = [types.Content(role=\"user\", parts=[types.Part(text=self.system),types.Part(text=self.prompt)])]\n\n    def set_reason(self, step):\n        # Append the model's reasoning part.\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(thought=True,text=step)]))\n\n    def append_code(self, prompt, code_response_parts):\n        self.contents.append(types.Content(role=\"user\", parts=[types.Part(text=prompt)]))\n        # Append the model's generated code and execution result.\n        self.contents.append(types.Content(role=\"model\", parts=code_response_parts))\n\n    def update_contents(self, function_call, api_response_part):\n        # Append the model's function call part.\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n        # Append the api response part.\n        self.contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n\n    def set_summary(self, summary):\n        self.summary = summary\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(text=summary)]))\n        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = {\n            \"prompt\": self.prompt, \n            \"summary\": self.summary, \n            \"contents\": self.contents\n        }\n        self.contents = None\n    \n    def set_subroutine_content(self):\n        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = { \n            \"contents\": self.contents\n        }\n\nmemory = Memory()","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:06.938202Z","iopub.execute_input":"2025-08-29T02:52:06.938814Z","iopub.status.idle":"2025-08-29T02:52:06.952525Z","shell.execute_reply.started":"2025-08-29T02:52:06.938772Z","shell.execute_reply":"2025-08-29T02:52:06.951265Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Retrieval-Augmented Generation Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Retrieval-Augmented Generation.\n# - using Chroma and text-embedding-004 for storage and retrieval\n# - using gemini-2.0-flash for augmented generation\nclass RetrievalAugmentedGenerator:\n    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n    exchange_codes: Optional[dict] = None\n    exchange_lists: dict = {}\n    events: dict = {}\n    holidays: dict = {}\n\n    def __init__(self, genai_client, collection_name):\n        self.client = genai_client\n        self.embed_fn = GeminiEmbedFunction(genai_client)\n        self.db = self.chroma_client.get_or_create_collection(\n            name=collection_name, \n            embedding_function=self.embed_fn, \n            metadata={\"hnsw:space\": \"cosine\"})\n        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n        self.holidays[\"US\"] = [\"07-04-2025\",\"09-01-2025\",\"10-13-2025\",\"11-11-2025\",\"11-27-2025\",\"12-25-2025\"]\n\n    def get_exchange_codes(self, with_query: Optional[str] = None):\n        gen = None\n        if with_query and with_query not in self.exchange_lists.keys():\n            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n            data = self.get_exchanges_csv(\n                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n                as a list in string form. Just the list string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n            self.exchange_lists[with_query] = ast.literal_eval(data.parts[-1].text)\n        elif with_query is None and self.exchange_codes is None:\n            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n            data = self.get_exchanges_csv(\n                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n                mapping exchange code to name. Just the dictionary string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n            self.exchange_codes = ast.literal_eval(data.parts[-1].text.strip(r\"\\`\"))\n        if gen:\n            gen.update(1)\n        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n\n    def get_event_date(self, event_t: str, exchange_code: str, event: MarketEvent):\n        current_dt_str = datetime.now(GeneratedEvent.tz()).strftime('%c')\n        current_dt = datetime.strptime(current_dt_str, \"%a %b %d %H:%M:%S %Y\")\n        current_t_str = datetime.now(GeneratedEvent.tz()).strftime('%H:%M:%S')\n        current_t = datetime.strptime(current_t_str, \"%H:%M:%S\").time()\n        event_time = parse(event_t).time()\n        holidays_dt = [datetime.strptime(h, \"%m-%d-%Y\").date() for h in self.holidays[exchange_code]]\n        if event is MarketEvent.LAST_CLOSE:\n            last_close_day = current_dt.date() - timedelta(days=0 if current_t > event_time else 1)\n            # Loop backwards to find the last valid trading day (not a weekend or holiday).\n            while last_close_day.weekday() >= 5 or last_close_day in holidays_dt: # 5 = Saturday, 6 = Sunday\n                last_close_day -= timedelta(days=1)\n            # Combine the date and time.\n            last_datetime = datetime.combine(last_close_day, event_time)\n            # Format the result as requested.\n            return last_datetime.strftime('%a %b %d %X %Y')\n        else:\n            next_event_day = current_dt.date() + timedelta(days=0 if current_t < event_time else 1)\n            # Loop forward to find the next valid trading day (not a weekend or holiday).\n            while next_event_day.weekday() >= 5 or next_event_day in holidays_dt: # 5 = Saturday, 6 = Sunday\n                next_event_day += timedelta(days=1)\n            # Combine date and time.\n            next_datetime = datetime.combine(next_event_day, event_time)\n            # Format the result as requested.\n            return next_datetime.strftime('%a %b %d %X %Y')\n\n    def generate_event(self, exchange_code: str, event: MarketEvent):\n        if event is MarketEvent.LAST_CLOSE or event is MarketEvent.POST_CLOSE:\n            prompt = f\"\"\"Provide the closing time including post_market hours.\"\"\"\n        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n            prompt = f\"\"\"Provide the opening time {is_pre} pre_market hours.\"\"\"\n        elif event is MarketEvent.REG_CLOSE:\n            prompt = f\"\"\"Provide the closing time excluding post_market hours.\"\"\"\n        prompt = f\"\"\"Answer based on your knowledge of exchange operating hours.\n            Do not answer in full sentences. Omit all chat and provide the answer only.\n            The fields pre_market and post_market both represent extended operating hours.\n\n            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n            \n            Consider the {exchange_code} exchange's operating hours.\n            {prompt}\n            \n            Answer with a time in this format: '%H:%M:%S'.\"\"\"\n        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n        response = self.get_exchanges_csv(prompt).candidates[0].content\n        response = self.get_event_date(response.parts[-1].text, exchange_code, event)\n        progress.update(1)\n        return response\n\n    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n            del self.events[exchange_code]\n            return self.generated_events(exchange_code)\n        elif exchange_code not in self.events.keys():\n            api.push_default_model(\"gemini-2.5-flash\")\n            self.events[exchange_code] = GeneratedEvent(\n                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE))\n            api.pop_default_model()\n        return self.events[exchange_code]\n\n    def set_holiday_event(self, exchange_code: str):\n        self.generated_events(exchange_code).is_holiday = True\n\n    def last_market_close(self, exchange_code: str):\n        return self.generated_events(exchange_code).last_close\n\n    def add_documents_list(self, docs: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n        content=[doc.page_content for doc in docs]\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n\n    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        splitter = RecursiveJsonSplitter(max_chunk_size=Gemini.Const.ChunkMax())\n        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        content = [json.dumps(doc.page_content) for doc in docs]\n        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n\n    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        peers = {\"symbol\": topic, \"peers\": names}\n        tqdm(self.db.add(ids=str(self.db.count()),\n                         documents=[json.dumps(peers)],\n                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n             desc=\"Generate peers embedding\")\n\n    def get_peers_document(self, query: str, topic: str, group: str):\n        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n\n    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n        self.embed_fn.document_mode = True # Switch to document mode\n        if ids is None:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n        if isinstance(chunks[0], BaseModel):\n            docs = [model.model_dump_json() for model in chunks]\n        else:\n            docs = [json.dumps(obj) for obj in chunks]\n        meta_base = {\"source\": source, \"topic\": topic}\n        if meta_opt is not None:\n            for m in meta_opt:\n                m.update(meta_base)\n        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n        if is_update:\n            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n        else:\n            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n\n    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n        self.embed_fn.document_mode = False # Switch to query mode.\n        stored = self.stored_result(self.db.get(where={\n            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n        if len(stored) == 0:\n            return stored, True\n        # Check for a daily market status update.\n        status = json.loads(stored[0].docs)\n        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n        store_day = parse(stored[0].meta['timestamp']).day\n        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n            return stored, False\n        elif gen_day > store_day:\n            return stored, True\n        # Update with generated events to avoid rest api requests.\n        status[\"session\"] = self.generated_events(exchange_code).session().value\n        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n        stored[0].docs = json.dumps(status)\n        return stored, False\n\n    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n        return self.get_documents_list(\n            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=[quote], \n                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n             desc=\"Generate quote embedding\")\n\n    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n                          meta_opt: Optional[list[dict]] = None):\n        where = [{\"source\": source}, {\"topic\": topic}]\n        if meta_opt is None:\n            return self.get_documents_list(query, where={\"$and\": where})\n        else:\n            for meta in meta_opt:\n                for k,v in meta.items():\n                    where.append({k: v})\n            return self.get_documents_list(query, where={\"$and\": where})\n\n    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_grounded_document(self, query: str, topic: str, result):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n        supports = result.candidates[0].grounding_metadata.grounding_supports\n        if supports is not None: # Only add grounded documents which have supports\n            grounded_text = [f\"{s.segment.text}\" for s in supports]\n            source = [f\"{c.web.title}\" for c in chunks]\n            score = [f\"{s.confidence_scores}\" for s in supports]\n            tqdm(self.db.add(ids=str(self.db.count()),\n                             documents=json.dumps(grounded_text),\n                             metadatas=[{\"source\": \", \".join(source),\n                                         \"confidence_score\": \", \".join(score),\n                                         \"topic\": topic,\n                                         \"question\": query}]),\n                 desc=\"Generate grounding embedding\")\n\n    def get_grounding_documents(self, query: str, topic: str):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n            \n    def add_wiki_documents(self, title: str, wiki_chunks: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        result = self.get_wiki_documents(title)\n        if len(result) == 0:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n    \n    def get_wiki_documents(self, title: Optional[str] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        if title is None:\n            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n        else:\n            return self.stored_result(self.db.get(where={\"title\": title}))\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(\n            self.db.query(query_texts=[query], \n                          n_results=max_sources, \n                          where=where), \n            is_query = True)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_exchanges_csv(self, query: str):\n        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_answer(self, query: str, max_sources: int = 10, \n                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n        stored = self.get_documents_list(query, max_sources, where)\n        query_oneline = query.replace(\"\\n\", \" \")\n        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n\n        QUESTION: {query_oneline}\n        \n        \"\"\"\n        # Add the retrieved documents to the prompt.\n        stored_docs = [passage.docs for passage in stored]\n        for passage in stored_docs if passages is None else stored_docs + passages:\n            passage_oneline = passage.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n        # Generate the response.\n        response = api.retriable(\n            self.client.models.generate_content,\n            model=api(Gemini.Model.GEN),\n            config=self.config_temp,\n            contents=prompt)\n        # Check for generated code and store in memory.\n        content = response.candidates[0].content\n        if len(content.parts) > 1 and content.parts[0].executable_code:\n            memory.append_code(prompt, content.parts)\n        return response\n\n    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n        try:\n            results = []\n            if len(result[\"documents\"]) == 0:\n                return results\n            if isinstance(result[\"documents\"][0], list):\n                for i in range(len(result[\"documents\"][0])):\n                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n                                            dist=result[\"distances\"][0][i] if is_query else None,\n                                            meta=result[\"metadatas\"][0][i],\n                                            store_id=result[\"ids\"][0][i])\n                    results.append(obj)\n            else:\n                results.append(\n                    VectorStoreResult(docs=result[\"documents\"][0],\n                                      dist=result[\"distances\"][0] if is_query else None,\n                                      meta=result[\"metadatas\"][0],\n                                      store_id=result[\"ids\"][0]))\n            return results\n        except Exception as e:\n            raise e","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:06.953764Z","iopub.execute_input":"2025-08-29T02:52:06.954137Z","iopub.status.idle":"2025-08-29T02:52:07.853303Z","shell.execute_reply.started":"2025-08-29T02:52:06.95408Z","shell.execute_reply":"2025-08-29T02:52:07.852347Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Wikipedia Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Wiki-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by similarity to topic\n# - retrieve existing groundings by similarity to topic\nclass WikiGroundingGenerator:   \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\") # suppress beta-warning\n            self.splitter = HTMLSemanticPreservingSplitter(\n                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n                max_chunk_size=Gemini.Const.ChunkMax(),\n                chunk_overlap=50,\n                preserve_links=True,\n                preserve_images=True,\n                preserve_videos=True,\n                preserve_audio=True,\n                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n                denylist_tags=[\"script\", \"style\", \"head\"],\n                custom_handlers={\"code\": self.code_handler},\n            )\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_wiki_documents(topic)\n        if len(stored) > 0:\n            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n        else:\n            pages = wikipedia.search(topic + \" company\")\n            if len(pages) > 0:\n                p_topic_match = 0.80\n                for i in range(len(pages)):\n                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n                            desc= \"Score wiki search by similarity to topic\"):\n                        headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:142.0) Gecko/20100101 Firefox/142.0'}\n                        request = requests.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\", headers=headers)\n                        if request.status_code != 200:\n                            print(f\"wiki get() returned status code {request.status_code}\")\n                        chunks = [chunk.page_content for chunk in self.splitter.split_text(request.text)]\n                        self.rag.add_wiki_documents(topic, chunks)\n                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n            return StopGeneration().result\n\n    def code_handler(self, element: Tag) -> str:\n        data_lang = element.get(\"data-lang\")\n        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n        return code_format","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:07.854718Z","iopub.execute_input":"2025-08-29T02:52:07.85563Z","iopub.status.idle":"2025-08-29T02:52:07.866307Z","shell.execute_reply.started":"2025-08-29T02:52:07.855604Z","shell.execute_reply":"2025-08-29T02:52:07.864916Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Google Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Search-Grounding Generation.\n# - using gemini-2.0-flash with GoogleSearch tool for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by exact match to topic\n# - retrieve existing groundings by similarity to topic\nclass SearchGroundingGenerator:\n    config_ground = types.GenerateContentConfig(\n        tools=[types.Tool(google_search=types.GoogleSearch())],\n        temperature=0.0\n    )\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_grounding_documents(query, topic)\n        if len(stored) > 0:\n            for i in range(len(stored)):\n                meta_q = stored[i].meta[\"question\"]\n                p_ground_match = 0.95 # This can be really high ~ 95-97%\n                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n                        desc=\"Score similarity to stored grounding\"):\n                    return ast.literal_eval(stored[i].docs)\n        return self.get_grounding(query, topic)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_grounding(self, query: str, topic: str):\n        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n        contents += f\"\"\"\n        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n        If an answer is not possible respond with: I don't know.\"\"\"\n        response = api.retriable(self.client.models.generate_content, \n                                 model=api(Gemini.Model.GEN), \n                                 config=self.config_ground, \n                                 contents=contents)\n        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n            if self.is_consistent(query, topic, response.text):\n                self.rag.add_grounded_document(query, topic, response)\n                return response.text \n        return StopGeneration().result # Empty grounding supports or not consistent in response\n\n    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n        topic = topic.replace(\"'\", \"\")\n        id_strs = topic.split()\n        if len(id_strs) == 1:\n            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n            if len(matches) > 0:\n                topic = matches\n        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n        model_response = model_response.replace(\"'\", \"\")\n        if len(compound_match) == 0 and topic in model_response:\n            return True # not a compound topic id and exact topic match\n        for match in compound_match:\n            if topic not in match:\n                return False\n        return True # all prefix matches contained topic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:52:07.867684Z","iopub.execute_input":"2025-08-29T02:52:07.868249Z","iopub.status.idle":"2025-08-29T02:52:07.89696Z","shell.execute_reply.started":"2025-08-29T02:52:07.868223Z","shell.execute_reply":"2025-08-29T02:52:07.895873Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Rest API Tool and Helpers","metadata":{}},{"cell_type":"code","source":"# Rest api-helpers to manage request-per-minute limits.\n# - define an entry for each endpoint limit\n# - init rest tool with limits to create blocking queues\n# - apply a limit to requests with rest_tool.try_url\nclass ApiLimit(Enum):\n    FINN = \"finnhub.io\",60\n    POLY = \"polygon.io\",5 # (id_url,rpm)\n\nclass BlockingUrlQueue:\n    on_cooldown = False\n    cooldown = None\n    cooldown_start = None\n    \n    def __init__(self, rest_fn: Callable, per_minute: int):\n        self.per_minute_max = per_minute\n        self.quota = per_minute\n        self.rest_fn = rest_fn\n\n    def push(self, rest_url: str):\n        if not self.on_cooldown:\n            self.cooldown = Timer(60, self.reset_quota)\n            self.cooldown.start()\n            self.cooldown_start = time.time()\n            self.on_cooldown = True\n        if self.quota > 0:\n            self.quota -= 1\n            time.sleep(0.034) # ~30 requests per second\n            return self.rest_fn(rest_url)\n        else:\n            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n            time.sleep(max(self.limit_expiry(),0.5))\n            return self.push(rest_url)\n\n    def reset_quota(self):\n        self.quota = self.per_minute_max\n        self.on_cooldown = False\n        self.cooldown_start = None\n\n    def limit_expiry(self):\n        if self.cooldown_start:\n            return max(60-(time.time()-self.cooldown_start),0)\n        return 0","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:07.898453Z","iopub.execute_input":"2025-08-29T02:52:07.898758Z","iopub.status.idle":"2025-08-29T02:52:07.928665Z","shell.execute_reply.started":"2025-08-29T02:52:07.898737Z","shell.execute_reply":"2025-08-29T02:52:07.927652Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# An implementation of Rest-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - reduce long-context by chunked pre-processing\nclass RestGroundingGenerator:    \n    limits = None\n\n    def __init__(self, rag_impl, with_limits: bool):\n        self.rag = rag_impl\n        if with_limits:\n            self.limits = {}\n            for rest_api in ApiLimit:\n                self.limits[rest_api.value[0]] = BlockingUrlQueue(self.get, rest_api.value[1])\n\n    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n        return self.limits[rest_api.value[0]] if self.limits else None\n\n    def get(self, url: str) -> Optional[str]:\n        try:\n            headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:142.0) Gecko/20100101 Firefox/142.0'}\n            request = requests.get(url, headers=headers)\n            if request.status_code != requests.codes.ok:\n                print(f\"the endpoint returned status {request.status_code}\")\n            return request.text\n        except Exception as e:\n            raise e\n\n    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n        try:\n            if from_lambda:\n                return schema(results=json.loads(data))\n            return schema.model_validate_json(data)\n        except Exception as e:\n            raise e\n\n    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n        try:\n            candle = json.loads(data)\n            if \"from\" not in candle:\n                raise ValueError(\"not a dailycandle / missing value for date\")\n            agg = self.basemodel(data, Aggregate)\n            return DailyCandle(from_date=candle[\"from\"], \n                               status=agg.status.value, \n                               symbol=agg.symbol, \n                               open=agg.open, \n                               high=agg.high, \n                               low=agg.low, \n                               close=agg.close, \n                               volume=agg.volume, \n                               otc=agg.otc, \n                               preMarket=agg.preMarket, \n                               afterHours=agg.afterHours)\n        except Exception as e:\n            raise e\n\n    @retry.Retry(timeout=600)\n    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n                success_fn: Callable, *args, **kwargs):\n        try:\n            if self.limits is None:\n                data = self.get(url)\n            elif with_limit:\n                data = with_limit.push(url)\n            if schema is DailyCandle:\n                model = self.dailycandle(data)\n            else:\n                model = self.basemodel(data, schema, as_lambda)\n        except Exception as e:\n            try:\n                print(f\"try_url exception: {e}\")\n                if issubclass(schema, RestResultPoly):\n                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n            except Exception as not_a_result:\n                print(not_a_result)\n            return StopGeneration()\n        else:\n            return success_fn(*args, **kwargs, model=model)\n\n    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n        matches = []\n        max_failed_match = model.count if not by_name else 3\n        p_desc_match = 0.92\n        p_symb_match = 0.95\n        if model.count > 0:\n            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n                if max_failed_match > 0:\n                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n                    symb = [with_content[\"q\"].upper(), obj.symbol]\n                    if by_name and api.similarity(desc) > p_desc_match: \n                        matches.append(obj.symbol)\n                    elif not by_name and api.similarity(symb) > p_symb_match:\n                        matches.append(obj.description)\n                        max_failed_match = 0\n                    else:\n                        max_failed_match -= 1\n        if len(matches) > 0:\n            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n            return matches\n        return StopGeneration().result\n\n    def get_quote(self, with_content, model: Quote):\n        quote = model.model_dump_json()\n        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n        return quote\n\n    def parse_financials(self, with_content, model: BasicFinancials):\n        metric = list(model.metric.items())\n        chunks = []\n        # Chunk the metric data.\n        for i in range(0, len(metric), Gemini.Const.MetricBatch()):\n            batch = metric[i:i + Gemini.Const.MetricBatch()]\n            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n        # Chunk the series data.\n        for key in model.series.keys():\n            series = list(model.series[key].items())\n            for s in series:\n                if api.token_count(s) <= Gemini.Const.ChunkMax():\n                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n                else:\n                    k = s[0]\n                    v = s[1]\n                    for i in range(0, len(v), Gemini.Const.SeriesBatch()):\n                        batch = v[i:i + Gemini.Const.SeriesBatch()]\n                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n        return chunks\n\n    def parse_news(self, with_content, model: NewsResultFinn):\n        if model.count > 0:\n            metas = []\n            for digest in model.get():\n                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": digest.source,\n                              \"published_est\": parse(pub_date).timestamp(),\n                              \"news_id\": digest.id,\n                              \"related\": digest.related})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [digest.summary().model_dump_json() for digest in model.get()]\n        return StopGeneration().result\n\n    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = []\n            for news in model.get():\n                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": news.publisher.name,\n                              \"published_utc\": parse(pub_date).timestamp(),\n                              \"news_id\": news.id,\n                              \"related\": json.dumps(news.tickers),\n                              \"keywords\": json.dumps(news.keywords)})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n                                     ids=[news.id for news in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n        elif result:\n            return result.model_dump_json()\n\n    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n                           result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            self.rag.add_rest_chunks(\n                chunks=[model],\n                topic=with_content[\"stocksTicker\"],\n                source=\"daily_candle_2\",\n                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n            return model\n        elif result:\n            return result\n\n    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n                            result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = [{\n                \"timespan\": with_content[\"timespan\"],\n                \"adjusted\": with_content[\"adjusted\"],\n                \"from\": with_content[\"from\"],\n                \"to\": with_content[\"to\"]}]*model.count\n            candles = [candle.model_dump_json() for candle in model.get()]\n            self.rag.add_rest_chunks(\n                chunks=candles,\n                topic=with_content[\"stocksTicker\"],\n                source=\"custom_candle_2\",\n                meta_opt=metas)\n            return candles\n        elif result:\n            return result.model_dump_json()\n\n    def parse_overview(self, with_content, model: OverviewResult):\n        overview = [model.get().model_dump_json()]\n        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n        return overview\n\n    def parse_trends(self, with_content, model: TrendsResult):\n        if model.count > 0:\n            metas = [{\"period\": trend.period} for trend in model.get()]\n            trends = [trend.model_dump_json() for trend in model.get()]\n            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n            return trends\n        return StopGeneration().result\n\n    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n        if model.get().holiday != MarketSession.NA.value:\n            self.rag.set_holiday_event(model.get().exchange)\n        events = self.rag.generated_events(model.get().exchange)\n        model.get().session = events.session()\n        model.get().isOpen = events.is_open()\n        meta = {\"exchange\": model.get().exchange,\n                \"last_close\": events.last_close,\n                \"pre_open\": events.pre_open,\n                \"reg_open\": events.reg_open,\n                \"reg_close\": events.reg_close,\n                \"post_close\": events.post_close,\n                \"timestamp\": events.timestamp }\n        self.rag.add_rest_chunks([model.get()],\n                                 topic=\"market_status\",\n                                 source=\"get_market_status_1\",\n                                 ids=[with_id] if with_id else None,\n                                 meta_opt=[meta])\n        return model.get().model_dump_json()\n\n    def get_symbol(self, content, by_name: bool = True):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=SymbolResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_symbol_matches,\n            with_content=content,\n            by_name=by_name)\n\n    def get_current_price(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=Quote,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_quote,\n            with_content=content)\n\n    def get_market_status(self, content, store_id: Optional[str] = None):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=MarketStatusResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.augment_market_status,\n            with_id=store_id)\n\n    def get_peers(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n            schema=PeersResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=lambda model: model)\n\n    def get_basic_financials(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n            schema=BasicFinancials,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_financials,\n            with_content=content)\n\n    def get_news_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n            schema=NewsResultFinn,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_news,\n            with_content=content)\n\n    def get_news_tagged(self, content):\n        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n        news = []\n        while True:\n            news_list, next_url = self.try_url(\n                next_url,\n                schema=NewsResultPoly,\n                as_lambda=False,\n                with_limit=self.get_limit(ApiLimit.POLY),\n                success_fn=self.parse_news,\n                with_content=content)\n            news += news_list\n            if next_url is None:\n                break\n            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n        return news\n\n    def get_daily_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n            schema=DailyCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_daily_candle,\n            with_content=content)\n\n    def get_custom_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n            schema=CustomCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_custom_candle,\n            with_content=content)\n\n    def get_overview(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n            schema=OverviewResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_overview,\n            with_content=content)\n\n    def get_trends_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=TrendsResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_trends,\n            with_content=content)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:07.929862Z","iopub.execute_input":"2025-08-29T02:52:07.930419Z","iopub.status.idle":"2025-08-29T02:52:07.982452Z","shell.execute_reply.started":"2025-08-29T02:52:07.930379Z","shell.execute_reply":"2025-08-29T02:52:07.981323Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Instantiate the Tools\n\n<span style=\"font-size:18px;\">\nLet's load some test data and see what the RAG can do. The test data is a CSV file containing stock market exchange data. It includes the market id code, name, locale, and operating hours. The import will use CSVLoader from <code>langchain-community</code> to parse the exchange data into Documents that our RAG can ingest.\n</span>","metadata":{}},{"cell_type":"code","source":"# Instantiate tools and load the exchange data from source csv.\n# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n# - Also maps the exchange code to exchange details.\ntry:\n    df = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\")\nexcept FileNotFoundError as e:\n    df = pandas.read_csv(\"exchanges_src.csv\") # local run\ndf = df.drop([\"close_date\"], axis=1).fillna(\"\")\ndf.to_csv(\"exchanges.csv\", index=False)\nexchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n\n# Prepare a RAG tool for use and add the exchange data.\ntool_rag = RetrievalAugmentedGenerator(api.client, \"finance\")\ntool_rag.add_documents_list(exchanges)\ntool_rag.generated_events(\"US\")\n\n# Prepare a the grounding tools for use.\ntool_wiki = WikiGroundingGenerator(api.client, tool_rag)\ntool_ground = SearchGroundingGenerator(api.client, tool_rag)\ntool_rest = RestGroundingGenerator(tool_rag, with_limits=True)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:07.983512Z","iopub.execute_input":"2025-08-29T02:52:07.98391Z","iopub.status.idle":"2025-08-29T02:52:18.814065Z","shell.execute_reply.started":"2025-08-29T02:52:07.983874Z","shell.execute_reply":"2025-08-29T02:52:18.812864Z"}},"outputs":[{"name":"stderr","text":"Generate document embedding: 0it [00:00, ?it/s]\nGenerate US->MarketEvent.LAST_CLOSE: 100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\nGenerate US->MarketEvent.PRE_OPEN: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\nGenerate US->MarketEvent.REG_OPEN: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\nGenerate US->MarketEvent.REG_CLOSE: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\nGenerate US->MarketEvent.POST_CLOSE: 100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nNow that the data is loaded lets ask our RAG to perform some augmenting. We can ask it to perform all sorts of useful tasks. We'll generate some useful reusable data structures and check to make sure it can answer important questions. The exchanges all have id's which are used to filter the realtime data. So we'll make sure the RAG know how to create this mapping. We'll also check it's awareness of operating hours. After all, Essy, doesn't mindlessly hammer away at api's when no new data is available.\n</span>","metadata":{}},{"cell_type":"code","source":"# The RAG tool is a helpful expert.\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n    exchange code to name. Just the dictionary string in pretty form.\"\"\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n    comma separated value that I can copy.\"\"\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\n    f\"\"\"Answer based on your knowledge of exchange operating hours.\n    Do not answer in full sentences. Omit all chat and provide the answer only.\n    The fields pre_market and post_market both represent extended operating hours.\n\n    The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n\n    Weekdays are: Mon, Tue, Wed, Thu, Fri.\n    On weekdays all exchanges open after pre-market and regular hours.\n    On weekdays all exchanges close after regular and post-market hours.\n    \n    Weekends are: Sat, Sun.\n    Always exclude weekends from exchange operating hours.\n    A list of holidays in date format mm-dd-yyyy: {tool_rag.holidays[\"US\"]}\n    Always exclude holidays from exchange operating hours.\n    When the answer is a holiday use the prior weekday for close.\n    When the answer is a holiday use the next weekday for open.\n    \n    Consider the US exchange's operating hours.\n    Provide the most recent weekday's close including post_market hours.\n    \n    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\nprint(response.candidates[0].content.parts[-1].text)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T04:08:23.727352Z","iopub.execute_input":"2025-08-29T04:08:23.727787Z","iopub.status.idle":"2025-08-29T04:09:54.755869Z","shell.execute_reply.started":"2025-08-29T04:08:23.727758Z","shell.execute_reply":"2025-08-29T04:09:54.754578Z"}},"outputs":[{"name":"stdout","text":"```\n{\n    \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n    \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n    \"US\": \"US exchanges (NYSE, Nasdaq)\",\n    \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n    \"QA\": \"QATAR EXCHANGE\",\n    \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n    \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n    \"PR\": \"PRAGUE STOCK EXCHANGE\",\n    \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n    \"CA\": \"Egyptian Stock Exchange\",\n    \"AX\": \"ASX - ALL MARKETS\",\n    \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n    \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n    \"DB\": \"DUBAI FINANCIAL MARKET\",\n    \"PM\": \"Philippine Stock Exchange\",\n    \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n    \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n    \"DU\": \"BOERSE DUESSELDORF\",\n    \"TL\": \"NASDAQ OMX TALLINN\",\n    \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n    \"SW\": \"SWISS EXCHANGE\",\n    \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n    \"SI\": \"SINGAPORE EXCHANGE\",\n    \"RG\": \"NASDAQ OMX RIGA\",\n    \"CR\": \"CARACAS STOCK EXCHANGE\",\n    \"SA\": \"Brazil Bolsa - Sao Paolo\",\n    \"BH\": \"BAHRAIN BOURSE\",\n    \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n    \"L\": \"LONDON STOCK EXCHANGE\",\n    \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n    \"IC\": \"NASDAQ OMX ICELAND\",\n    \"KW\": \"Kuwait Stock Exchange\",\n    \"JK\": \"INDONESIA STOCK EXCHANGE\",\n    \"BE\": \"BOERSE BERLIN\",\n    \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n    \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n    \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n    \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n    \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n    \"KL\": \"BURSA MALAYSIA\",\n    \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n    \"VS\": \"NASDAQ OMX VILNIUS\",\n    \"ME\": \"MOSCOW EXCHANGE\",\n    \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n    \"NL\": \"Nigerian Stock Exchange\",\n    \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n    \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n    \"DE\": \"XETRA\",\n    \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n    \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n    \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n    \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n    \"OL\": \"OSLO BORS ASA\",\n    \"BO\": \"BSE LTD\",\n    \"MT\": \"MALTA STOCK EXCHANGE\",\n    \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n    \"F\": \"DEUTSCHE BOERSE AG\",\n    \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n    \"MU\": \"BOERSE MUENCHEN\",\n    \"IS\": \"BORSA ISTANBUL\",\n    \"SR\": \"SAUDI STOCK EXCHANGE\",\n    \"NE\": \"AEQUITAS NEO EXCHANGE\",\n    \"MI\": \"Italian Stock Exchange\",\n    \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n    \"MC\": \"BOLSA DE MADRID\",\n    \"HA\": \"Hanover Stock Exchange\",\n    \"VI\": \"Vienna Stock Exchange\",\n    \"TWO\": \"TPEx\",\n    \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n    \"TW\": \"TAIWAN STOCK EXCHANGE\",\n    \"TO\": \"TORONTO STOCK EXCHANGE\",\n    \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n    \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n    \"SG\": \"BOERSE STUTTGART\",\n    \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n    \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n    \"BK\": \"STOCK EXCHANGE OF THAILAND\"\n}\n```\nDE,F,TG,SX,BE,DU,HA,HM,MU,SC,SG \n\nThe German exchanges and their corresponding codes are listed below.\n\n*   XETRA has the exchange code DE.\n*   DEUTSCHE BOERSE AG has the exchange code F.\n*   Hanover Stock Exchange has the exchange code HA.\n*   DEUTSCHE BOERSE TradeGate has the exchange code TG.\n*   BOERSE BERLIN has the exchange code BE.\n*   BOERSE DUESSELDORF has the exchange code DU.\n*   HANSEATISCHE WERTPAPIERBOERSE HAMBURG has the exchange code HM.\n*   BOERSE MUENCHEN has the exchange code MU.\n*   DEUTSCHE BOERSE Stoxx has the exchange code SX.\n*   BOERSE_FRANKFURT_ZERTIFIKATE has the exchange code SC.\n*   BOERSE STUTTGART has the exchange code SG. \n\nGoogle is listed on the NASDAQ stock exchange under the ticker symbols GOOGL and GOOG. The company is also listed on the Frankfurt Stock Exchange with the ticker symbol GGQ1. These ticker symbols now refer to Alphabet Inc., Google's holding company. GOOGL shares are class A, while GOOG shares are class C. \n\napi.refill_rpm  150\nThe stock ticker symbol for Meta Platforms, Inc. is META. The company, formerly known as Facebook, Inc., trades on the Nasdaq exchange. \n\nUS exchanges, including the NYSE and Nasdaq, operate from 9:30 AM to 4:00 PM. Pre-market hours are from 4:00 AM to 9:30 AM, and post-market hours are from 4:00 PM to 8:00 PM. All times are in the America/New_York timezone. \n\nThu Aug 28 20:00:00 2025\napi.refill_rpm  150\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nExcellent! Though, despite my best effort I could not convince Gemini to apply date correction (during chaining) based on holiday. It simply wasn't stable enough to be useful. I would either have to add a holiday data set, or (what I chose) apply a quick temporary fix. A real-time API endpoint may fail due to a holiday being selected as the date. If that happens I'll just retry Thursday if the failure happened on Friday, likewise choosing Friday if the failure happened on Monday. Crude but simple for foundational purposes.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Declaring the Function Calling Metadata\n\n<span style=\"font-size:18px;\">\nOur Function Calling expert will chain together the other experts we've implemented thus far. It also provides the final response through augmentation. This time using the tools as a source of grounding truth. It'd like to say it's all truth organised by topic and other metadata. It's still a precarious situation if Essy incidently chains into mining data on another topic. We want Amazon to be the owner of MGM Studio's not MGM Resorts International. We also don't want a summary to include another company unless that company is a peer.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe function calling metadata is thus extremely important. It needs to combine our other experts with the real-time api's data. Essy will use two API providers as sources of finance data. The primary motivation being that each provider has limits in their own way, yet both are useful in their own own way. This is useful anywhere you need a broad spectrum of sources of truth. At metadata creation I'll adopt the naming convention of appending the provider (if any) id. This helps keep functions more understandable when you know which provider you're dealing with.\n</span>","metadata":{}},{"cell_type":"code","source":"# Declare callable functions using OpenAPI schema.\ndecl_get_symbol_1 = types.FunctionDeclaration(\n    name=\"get_symbol_1\",\n    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n                   calling get_wiki_tool_response next.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_symbols_1 = types.FunctionDeclaration(\n    name=\"get_symbols_1\",\n    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"exchange\", \"query\"]\n    }\n)\n\ndecl_get_name_1 = types.FunctionDeclaration(\n    name=\"get_name_1\",\n    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"company\": {\n                \"type\": \"string\",\n                \"description\": \"The company you're searching for.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n    }\n)\n\ndecl_get_symbol_quote_1 = types.FunctionDeclaration(\n    name=\"get_symbol_quote_1\",\n    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n                   provided in json format. Each response contains the following key-value pairs:\n                   \n                   c: Current price,\n                   d: Change,\n                  dp: Percent change,\n                   h: High price of the day,\n                   l: Low price of the day,\n                   o: Open price of the day,\n                  pc: Previous close price,\n                   t: Epoch timestamp of price in seconds.\n\n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\", \"exchange\"]\n    }\n)\n\ndecl_get_local_datetime = types.FunctionDeclaration(\n    name=\"get_local_datetime\",\n    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n                   function to format date and time in your responses.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"t\": {\n                \"type\": \"array\",\n                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n                                  timestamps matches the order of conversion.\"\"\",\n                \"items\": {\n                    \"type\": \"integer\"\n                }\n            }\n        },\n        \"required\": [\"t\"]\n    }\n)\n\ndecl_get_market_status_1 = types.FunctionDeclaration(\n    name=\"get_market_status_1\",\n    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n                   Also includes holiday details if applicable. The response is provided in json format. Each response \n                   contains the following key-value pairs:\n\n                   exchange: Exchange code,\n                   timezone: Timezone of the exchange,\n                    holiday: Holiday event name, or null if it's not a holiday,\n                     isOpen: Whether the market is open at the moment,\n                          t: Epoch timestamp of status in seconds (Eastern Time),\n                    session: The market session can be 1 of the following values: \n                    \n                    pre-market,regular,post-market when open, or null if closed.\n                    \n                    Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_market_session_1 = types.FunctionDeclaration(\n    name=\"get_market_session_1\",\n    description=\"Get the current market session of global exchanges.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_company_peers_1 = types.FunctionDeclaration(\n    name=\"get_company_peers_1\",\n    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n                   \n                   symbol: The company's stock ticker symbol, \n                   peers: A list containing the peers.\n                   \n                   Each peers entry contains the following key-value pairs:\n                   \n                   symbol: The peer company's stock ticker symbol, \n                   name: The peer company's name.\n                   \n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n            },\n            \"grouping\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n                                  Always use subIndustry unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_exchange_codes_1 = types.FunctionDeclaration(\n    name=\"get_exchange_codes_1\",\n    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n)\n\ndecl_get_exchange_code_1 = types.FunctionDeclaration(\n    name=\"get_exchange_code_1\",\n    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n                   more exchange codes provided as a comma-separated string value.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"Specifies which exchange code to search for.\"\n            }\n        },\n        \"required\": [\"q\"]\n    }\n)\n\ndecl_get_financials_1 = types.FunctionDeclaration(\n    name=\"get_financials_1\",\n    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"metric\": {\n                \"type\": \"string\",\n                \"description\": \"It must always be declared as the value 'all'\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"metric\", \"query\"]\n    }\n)\n\ndecl_get_daily_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_daily_candlestick_2\",\n    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n                   volume and pre-market/after-hours trade prices. It does not provide today's data until after \n                   11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"date\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n    },\n)\n\ndecl_get_company_news_1 = types.FunctionDeclaration(\n    name=\"get_company_news_1\",\n    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\",\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n                                  default value is today's date.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n    },\n)\n\ndecl_get_custom_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_custom_candlestick_2\",\n    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n                   includes historical daily trade volume and pre-market/after-hours trade prices. It does not\n                   include today's open, high, low, or close until after 11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"multiplier\": {\n                \"type\": \"integer\",\n                \"description\": \"This must be included and equal to 1 unless told otherwise.\"\n            },\n            \"timespan\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n                                  default is one weekday before get_last_market_close.\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This must be included. May be one of asc or desc. asc will sort by timestmap in \n                                  ascending order. desc will sort by timestamp in descending order.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n                                  unless told to limit base aggregates to something else.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n    },\n)\n\ndecl_get_last_market_close = types.FunctionDeclaration(\n    name=\"get_last_market_close\",\n    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_ticker_overview_2 = types.FunctionDeclaration(\n    name=\"get_ticker_overview_2\",\n    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a company’s \n    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n    the form of icons and logos.\n    \"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol of a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"query\"]\n    }\n)\n\ndecl_get_recommendation_trends_1 = types.FunctionDeclaration(\n    name=\"get_recommendation_trends_1\",\n    description=\"\"\"Get the latest analyst recommendation trends for a company.\n                The data includes the latest recommendations as well as historical\n                recommendation data for each month. The data is classified according\n                to these categories: strongBuy, buy, hold, sell, and strongSell.\n                The date of a recommendation indicated by the value of 'period'.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\"]\n    }\n)\n\ndecl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n    name=\"get_news_with_sentiment_2\",\n    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n                   comprehensive coverage. Including a summary, publisher information, article metadata, \n                   and sentiment analysis.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"published_utc.gte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n                                  The default value is one-month ago from today's date.\"\"\"\n            },\n            \"published_utc.lte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"order\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n                                  When order is not specified the default is descending order.\n                                  Ordering will be based on the parameter 'sort'.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"This must be included and equal to 1000 unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The sort field used for ordering. This value must\n                                  always be published_utc.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"limit\", \"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"sort\", \"query\"]\n    }\n)\n\ndecl_get_rag_tool_response = types.FunctionDeclaration(\n    name=\"get_rag_tool_response\",\n    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"question\": {\n                \"type\": \"string\",\n                \"description\": \"A question needing an answer. Asked as a simple string.\"\n            }\n        }\n    }\n)\n\ndecl_get_wiki_tool_response = types.FunctionDeclaration(\n    name=\"get_wiki_tool_response\",\n    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n                   product, or service. Each web page includes detailed company information, financial indicators, \n                   tickers, symbols, history, and products and services.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. Just the name and no other details.\"\n            },\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The complete, unaltered, query string.\"\n            }\n        },\n        \"required\": [\"id\", \"q\"]\n    }\n)\n\ndecl_get_search_tool_response = types.FunctionDeclaration(\n    name=\"get_search_tool_response\",\n    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The question needing an answer. Asked as a simple string.\"\n            },\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n            }\n        },\n        \"required\": [\"q\", \"id\"]\n    }\n)","metadata":{"trusted":true,"_kg_hide-input":false,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:28.76442Z","iopub.execute_input":"2025-08-29T02:52:28.764733Z","iopub.status.idle":"2025-08-29T02:52:28.807691Z","shell.execute_reply.started":"2025-08-29T02:52:28.764711Z","shell.execute_reply":"2025-08-29T02:52:28.806385Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Implementing the Function Calling Expert\n\n<span style=\"font-size:18px;\">\nOne downside of this part being the main part was the lack of time to refactor this part more. Our formative Essy implements as much useful data from two finacial APIs. In order to use it you will need to declare secrets for <a class=\"anchor-link\" href=\"https://finnhub.io/dashboard\">Finnhub</a> and <a class=\"anchor-link\" href=\"https://polygon.io/dashboard\">Polygon</a> finance APIs. Register at their respective sites for your free API key. Then import the secret using the same method as how you setup Google's API key.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## Callable Functions and Handler","metadata":{}},{"cell_type":"code","source":"# Implement the callable functions and the function handler.\n\ndef ask_rag_tool(content):\n    return tool_rag.generate_answer(content[\"question\"]).text\n\ndef ask_wiki_tool(content):\n    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n\ndef ask_search_tool(content):\n    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n\ndef get_exchange_codes_1(content):\n    return tool_rag.get_exchange_codes()\n\ndef get_exchange_code_1(content):\n    return tool_rag.get_exchange_codes(with_query=content)\n    \ndef last_market_close(content):\n    return tool_rag.last_market_close(content[\"exchange\"])\n    \ndef get_symbol_1(content, by_name: bool = True):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n    if len(stored) == 0:\n        return tool_rest.get_symbol(content, by_name)\n    return json.loads(stored[0].docs)\n\ndef get_symbols_1(content):\n    return None # todo\n\ndef get_name_1(content):\n    return get_symbol_1(content, by_name = False)\n\ndef get_quote_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n        return get_current_price_1(content)\n    elif len(stored) > 0:\n        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n        for quote in stored:\n            if quote.meta[\"timestamp\"] >= last_close:\n                return [quote.docs for quote in stored]\n    return get_current_price_1(content)\n\ndef get_current_price_1(content):\n    return tool_rest.get_current_price(content)\n\ndef get_market_status_1(content):\n    stored, has_update = tool_rag.get_market_status(content['exchange'])\n    if has_update:\n        with_id = stored[0].store_id if len(stored) > 0 else None\n        return tool_rest.get_market_status(content, with_id)\n    return stored[0].docs\n\ndef get_session_1(content):\n    return json.loads(get_market_status_1(content))[\"session\"]\n\ndef get_peers_1(content):\n    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n    if len(stored) == 0:\n        peers = tool_rest.get_peers(content)\n        if peers.count > 0:\n            names = []\n            for peer in peers.get():\n                if peer == content[\"symbol\"]:\n                    continue # skip including the query symbol in peers\n                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n                if name != StopGeneration().result:\n                    data = {\"symbol\": peer, \"name\": name}\n                    names.append(data)\n            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n            return names\n        return StopGeneration().result\n    return json.loads(stored[0].docs)[\"peers\"]\n\ndef local_datetime(content):\n    local_t = []\n    for timestamp in content[\"t\"]:\n        local_t.append(local_date_from_epoch(timestamp))\n    return local_t\n\ndef local_date_from_epoch(timestamp):\n    if len(str(timestamp)) == 13:\n        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n    else:\n        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n\ndef get_financials_1(content):\n    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n    if len(stored) == 0:\n        return tool_rest.get_basic_financials(content)\n    return [chunk.docs for chunk in stored]\n\ndef get_news_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n    if len(stored) == 0:\n        return tool_rest.get_news_simple(content)\n    return [NewsTypeFinn.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n\ndef get_daily_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n    if len(stored) == 0:\n        candle = tool_rest.get_daily_candle(content)\n        # Attempt to recover from choosing a holiday.\n        candle_date = parse(content[\"date\"])\n        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n            else:\n                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n            return get_daily_candle_2(content)\n        return candle.model_dump_json()\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_custom_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n        meta_opt=[{\n            \"timespan\": content[\"timespan\"],\n            \"adjusted\": content[\"adjusted\"],\n            \"from\": content[\"from\"],\n            \"to\": content[\"to\"]}])\n    if len(stored) == 0:\n        return tool_rest.get_custom_candle(content)\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_overview_2(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n    if len(stored) == 0:\n        return tool_rest.get_overview(content)\n    return json.loads(stored[0].docs)\n\ndef get_trends_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n    if len(stored) == 0:\n        return tool_rest.get_trends_simple(content)\n    return [json.loads(trend.docs) for trend in stored]\n\ndef get_news_2(content):\n    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n    news_from = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n    news_to = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n    if len(news_from) > 0 and len(news_to) > 0:\n        stored = tool_rag.get_api_documents(\n            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n            [{\"published_utc\": {\"$gte\": timestamp_from}},\n             {\"published_utc\": {\"$lte\": timestamp_to}}])\n        return [NewsTypePoly.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n    return tool_rest.get_news_tagged(content)\n        \nfinance_tool = types.Tool(\n    function_declarations=[\n        decl_get_symbol_1,\n        decl_get_symbols_1,\n        decl_get_name_1,\n        decl_get_symbol_quote_1,\n        decl_get_market_status_1,\n        decl_get_market_session_1,\n        decl_get_company_peers_1,\n        decl_get_local_datetime,\n        decl_get_last_market_close,\n        decl_get_exchange_codes_1,\n        decl_get_exchange_code_1,\n        decl_get_financials_1,\n        decl_get_daily_candlestick_2,\n        decl_get_custom_candlestick_2,\n        decl_get_ticker_overview_2,\n        decl_get_recommendation_trends_1,\n        decl_get_news_with_sentiment_2,\n        decl_get_rag_tool_response,\n        decl_get_wiki_tool_response,\n        decl_get_search_tool_response\n    ]\n)\n\nfunction_handler = {\n    \"get_symbol_1\": get_symbol_1,\n    \"get_symbols_1\": get_symbols_1,\n    \"get_name_1\": get_name_1,\n    \"get_symbol_quote_1\": get_quote_1,\n    \"get_market_status_1\": get_market_status_1,\n    \"get_market_session_1\": get_session_1,\n    \"get_company_peers_1\": get_peers_1,\n    \"get_local_datetime\": local_datetime,\n    \"get_last_market_close\": last_market_close,\n    \"get_exchange_codes_1\": get_exchange_codes_1,\n    \"get_exchange_code_1\": get_exchange_code_1,\n    \"get_financials_1\": get_financials_1,\n    \"get_daily_candlestick_2\": get_daily_candle_2,\n    \"get_custom_candlestick_2\": get_custom_candle_2,\n    \"get_ticker_overview_2\": get_overview_2,\n    \"get_recommendation_trends_1\": get_trends_1,\n    \"get_news_with_sentiment_2\": get_news_2,\n    \"get_rag_tool_response\": ask_rag_tool,\n    \"get_wiki_tool_response\": ask_wiki_tool,\n    \"get_search_tool_response\": ask_search_tool\n}","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:28.809166Z","iopub.execute_input":"2025-08-29T02:52:28.809549Z","iopub.status.idle":"2025-08-29T02:52:28.844315Z","shell.execute_reply.started":"2025-08-29T02:52:28.809515Z","shell.execute_reply":"2025-08-29T02:52:28.842802Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Define the System Prompt","metadata":{}},{"cell_type":"code","source":"# Define the system prompt.\n\ninstruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \nOnly answer the question asked and do not change topic. While the answer is still\nunknown you must follow these rules for predicting function call order:\n\nRULE#1: Always consult your other functions before get_search_tool_response.\nRULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\nRULE#3: Always consult get_search_tool_response last.\nRULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\nRULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:28.845925Z","iopub.execute_input":"2025-08-29T02:52:28.846414Z","iopub.status.idle":"2025-08-29T02:52:28.875118Z","shell.execute_reply.started":"2025-08-29T02:52:28.84637Z","shell.execute_reply":"2025-08-29T02:52:28.874045Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Import the Rest API Keys","metadata":{}},{"cell_type":"code","source":"# Import the finance api secret keys.\n\nPOLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\nFINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:28.876548Z","iopub.execute_input":"2025-08-29T02:52:28.876914Z","iopub.status.idle":"2025-08-29T02:52:29.152928Z","shell.execute_reply.started":"2025-08-29T02:52:28.876887Z","shell.execute_reply":"2025-08-29T02:52:29.151606Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## The Function Caller","metadata":{}},{"cell_type":"code","source":"# Implement the function calling expert.\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef send_message(prompt):\n    #display(Markdown(\"#### Prompt\"))\n    #print(prompt, \"\\n\")\n    memory.set_prompt(prompt)\n    # Enable system prompt, function calling and minimum-randomness.\n    config_fncall = types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=[finance_tool],\n        temperature=0.0\n    )\n    # Handle cases with multiple chained function calls.\n    function_calling_in_process = True\n    # Send the initial user prompt and function declarations.\n    response = api.retriable(api.client.models.generate_content,\n                             model=api(Gemini.Model.GEN),\n                             config=config_fncall,\n                             contents=memory.contents)\n    while function_calling_in_process:\n        # A part can be a function call or natural language response.\n        for part in response.candidates[0].content.parts:\n            if function_call := part.function_call:\n                # Extract the function call.\n                fn_name = function_call.name\n                #display(Markdown(\"#### Predicted function name\"))\n                #print(fn_name, \"\\n\")\n                # Extract the function call arguments.\n                fn_args = {key: value for key, value in function_call.args.items()}\n                #display(Markdown(\"#### Predicted function arguments\"))\n                #print(fn_args, \"\\n\")\n                # Call the predicted function.\n                api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n                #display(Markdown(\"#### API response\"))\n                #print(api_response[:500], \"...\", \"\\n\")\n                # Create an API response part.\n                api_response_part = types.Part.from_function_response(\n                    name=fn_name,\n                    response={\"content\": api_response},\n                )\n                memory.update_contents(function_call, api_response_part)\n                # Send the updated prompt.\n                response = api.retriable(api.client.models.generate_content,\n                                         model=api(Gemini.Model.GEN),\n                                         config=config_fncall,\n                                         contents=memory.contents)\n            else:\n                # Response may be a summary or reasoning step.\n                if len(response.candidates[0].content.parts) == 1:\n                    function_calling_in_process = False\n                    memory.set_summary(response.text.replace(\"$\", \"\\\\$\"))\n                    break # No more parts in response.\n                else:\n                    #display(Markdown(\"#### Natural language reasoning step\"))\n                    #print(response)\n                    memory.set_reason(response.candidates[0].content.parts[0].text)\n                    continue # Next part contains a function call.\n        if not function_calling_in_process:\n            break # The function calling chain is complete.\n            \n    # Show the final natural language summary.\n    display(Markdown(\"#### Natural language response\"))\n    display(Markdown(memory.summary))","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-08-29T02:52:29.154249Z","iopub.execute_input":"2025-08-29T02:52:29.154656Z","iopub.status.idle":"2025-08-29T02:52:29.166906Z","shell.execute_reply.started":"2025-08-29T02:52:29.154625Z","shell.execute_reply":"2025-08-29T02:52:29.165718Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Ask a question\n\n<span style=\"font-size:18px;\">\n    If you're on free-tier of Gemini you probably want to Run-before here. Your usage tier can be configured in the api-helper at the top of the notebook.\n</span>","metadata":{}},{"cell_type":"code","source":"send_message(\"What is the current session for US exchanges?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:52:40.299058Z","iopub.execute_input":"2025-08-29T02:52:40.30007Z","iopub.status.idle":"2025-08-29T02:52:46.400246Z","shell.execute_reply.started":"2025-08-29T02:52:40.300029Z","shell.execute_reply":"2025-08-29T02:52:46.399212Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current market session for US exchanges is closed.\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"send_message(\"What is the US market status?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:52:50.050273Z","iopub.execute_input":"2025-08-29T02:52:50.050732Z","iopub.status.idle":"2025-08-29T02:52:52.10091Z","shell.execute_reply.started":"2025-08-29T02:52:50.050704Z","shell.execute_reply":"2025-08-29T02:52:52.099756Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The US market is currently closed as of Thu Aug 28 22:52:42 2025 America/New_York time. There is no holiday today. The market session is closed.\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"send_message(\"When was the last US market close?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:52:56.682078Z","iopub.execute_input":"2025-08-29T02:52:56.682558Z","iopub.status.idle":"2025-08-29T02:52:58.336456Z","shell.execute_reply.started":"2025-08-29T02:52:56.682527Z","shell.execute_reply":"2025-08-29T02:52:58.335509Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The last market close in the US was on Thu Aug 28 20:00:00 2025, which converts to Fri Aug 29 05:20:00 2025 in local time.\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"send_message(\"What is Apple's stock ticker?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:53:00.954676Z","iopub.execute_input":"2025-08-29T02:53:00.95598Z","iopub.status.idle":"2025-08-29T02:53:03.606485Z","shell.execute_reply.started":"2025-08-29T02:53:00.955932Z","shell.execute_reply":"2025-08-29T02:53:03.60549Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 10/10 [00:00<00:00, 11.70it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker for Apple is AAPL.\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"send_message(\"What is the current price of Amazon stock? Display the result as a json object.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:53:07.693609Z","iopub.execute_input":"2025-08-29T02:53:07.694014Z","iopub.status.idle":"2025-08-29T02:53:10.95374Z","shell.execute_reply.started":"2025-08-29T02:53:07.693985Z","shell.execute_reply":"2025-08-29T02:53:10.952802Z"}},"outputs":[{"name":"stderr","text":"Generate quote embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is the current price of Amazon (AMZN) stock:\n```json\n{\n  \"currentPrice\": 231.6,\n  \"change\": 2.48,\n  \"percentChange\": 1.0824,\n  \"highPriceOfTheDay\": 232.71,\n  \"lowPriceOfTheDay\": 228.02,\n  \"openPriceOfTheDay\": 229.005,\n  \"previousClosePrice\": 229.12,\n  \"timestamp\": \"Thu Aug 28 16:00:00 2025\"\n}\n```"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"send_message(\"\"\"Show me Apple's basic financials and help me understand key performance metrics. \n                How has the stock performed?\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:55:10.680277Z","iopub.execute_input":"2025-08-29T02:55:10.681579Z","iopub.status.idle":"2025-08-29T02:55:33.218843Z","shell.execute_reply.started":"2025-08-29T02:55:10.681533Z","shell.execute_reply":"2025-08-29T02:55:33.217534Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a concise and detailed summary of Apple's (AAPL) basic financials and key performance metrics, including its stock performance:\n\n**Apple (AAPL) Basic Financials and Key Performance Metrics:**\n\nAs of the latest available data (primarily Trailing Twelve Months as of June 28, 2025, or September 28, 2024, where specified):\n\n*   **Market Capitalization**: \\$3,369,362 million\n*   **Price-to-Earnings (Trailing Twelve Months)**: 30.87 (as of June 28, 2025)\n*   **Forward Price-to-Earnings**: 31.56\n*   **Price-to-Sales (Trailing Twelve Months)**: 7.50 (as of June 28, 2025)\n*   **Price-to-Book (Quarterly)**: 46.55 (as of June 28, 2025)\n*   **Price-to-Free Cash Flow (Trailing Twelve Months)**: 31.86 (as of June 28, 2025)\n*   **Earnings Per Share (Quarterly)**: \\$1.57 (as of June 28, 2025)\n*   **Free Cash Flow Per Share (Trailing Twelve Months)**: \\$6.47 (as of June 28, 2025)\n*   **Book Value (Quarterly)**: \\$65,830 million (as of June 28, 2025)\n\n**Profitability and Efficiency:**\n\n*   **Net Margin (Trailing Twelve Months)**: 24.92% (as of June 28, 2025)\n*   **Operating Margin (Trailing Twelve Months)**: 29.99% (as of June 28, 2025)\n*   **Gross Margin (Trailing Twelve Months)**: 46.49% (as of June 28, 2025)\n*   **Return on Assets (Trailing Twelve Months)**: 28.95% (as of June 28, 2025)\n*   **Return on Equity (Trailing Twelve Months)**: 154.92% (as of June 28, 2025)\n*   **Return on Invested Capital (Trailing Twelve Months)**: 60.20% (as of June 28, 2025)\n*   **Asset Turnover (Trailing Twelve Months)**: 1.19 (as of June 28, 2025)\n*   **Inventory Turnover (Trailing Twelve Months)**: 36.04 (as of June 28, 2025)\n*   **Receivables Turnover (Trailing Twelve Months)**: 16.23 (as of June 28, 2025)\n\n**Liquidity and Solvency:**\n\n*   **Current Ratio (Quarterly)**: 0.87 (as of June 28, 2025)\n*   **Cash Ratio (Quarterly)**: 0.26 (as of June 28, 2025)\n*   **Quick Ratio (Quarterly)**: 0.83 (as of June 28, 2025)\n*   **Long-Term Debt to Equity (Quarterly)**: 1.25 (as of June 28, 2025)\n*   **Total Debt to Total Equity (Quarterly)**: 1.54 (as of June 28, 2025)\n\n**Stock Performance:**\n\n*   **52-Week High**: \\$260.10 (on December 26, 2024)\n*   **52-Week Low**: \\$169.21 (on April 08, 2025)\n*   **52-Week Price Return**: 1.46%\n*   **13-Week Price Return**: 15.12%\n*   **Year-to-Date Price Return**: -7.96%\n\nApple's financials indicate a highly profitable company with strong returns on equity and invested capital. Its valuation ratios (Price-to-Earnings, Price-to-Sales, Price-to-Book, Price-to-Free Cash Flow) suggest a premium valuation by the market. While the company has a significant amount of debt relative to its equity, its profitability metrics remain robust. In terms of stock performance, Apple has seen a positive return over the last 13 weeks and 52 weeks, but a negative return year-to-date."},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  1000\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"send_message(\"I need Apple's daily candlestick from 2025-05-05\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:56:58.506094Z","iopub.execute_input":"2025-08-29T02:56:58.506896Z","iopub.status.idle":"2025-08-29T02:57:01.221958Z","shell.execute_reply.started":"2025-08-29T02:56:58.50686Z","shell.execute_reply":"2025-08-29T02:57:01.220965Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"On May 5, 2025, Apple's stock (AAPL) had the following daily candlestick data: the open price was 203.1, the high price of the day was 204.1, the low price of the day was 198.21, and the close price was 198.89. The trading volume for the day was 69,018,452. The pre-market price was 205.0, and the after-hours price was 198.6.\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"send_message(\"Tell me who are Apple's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T02:57:14.861235Z","iopub.execute_input":"2025-08-29T02:57:14.862414Z","iopub.status.idle":"2025-08-29T02:57:26.949511Z","shell.execute_reply.started":"2025-08-29T02:57:14.862361Z","shell.execute_reply":"2025-08-29T02:57:26.948523Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 4/4 [00:00<00:00, 17.93it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 5/5 [00:00<00:00, 24.06it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.49it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00,  9.35it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00,  9.51it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 3/3 [00:00<00:00, 15.12it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  5.10it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nGenerate peers embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple's peers, based on the same subIndustry and country, include Dell Technologies -C (DELL), Hewlett Packard Enterprise (HPE), HP Inc (HPQ), Pure Storage Inc - Class A (PSTG), Super Micro Computer Inc (SMCI), Western Digital Corp (WDC), NetApp Inc (NTAP), IonQ Inc (IONQ), Sandisk Corp (SNDK), Diebold Nixdorf Inc (DBD), and Compusecure Inc-A (CMPO).\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"send_message(\"Tell me who are Amazon's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:00:07.325198Z","iopub.execute_input":"2025-08-29T03:00:07.326173Z","iopub.status.idle":"2025-08-29T03:00:21.462286Z","shell.execute_reply.started":"2025-08-29T03:00:07.326137Z","shell.execute_reply":"2025-08-29T03:00:21.461305Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00,  9.50it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 4/4 [00:00<00:00, 19.53it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00,  9.75it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 11/11 [00:00<00:00, 50.35it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nGenerate peers embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon's peers in the subIndustry grouping are: Coupang Inc (CPNG), Ebay Inc (EBAY), Dillards Inc-Cl A (DDS), Ollie's Bargain Outlet Holding (OLLI), Etsy Inc (ETSY), Macy's Inc (M), Savers Value Village Inc (SVV), Kohls Corp (KSS), Groupon Inc (GRPN), and Contextlogic Holdings Inc (LOGC).\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"send_message(\"Download the recommendation trends for all of Apple's peers individually then compare them.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:00:26.298594Z","iopub.execute_input":"2025-08-29T03:00:26.298963Z","iopub.status.idle":"2025-08-29T03:01:04.839157Z","shell.execute_reply.started":"2025-08-29T03:00:26.29894Z","shell.execute_reply":"2025-08-29T03:01:04.838059Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of August 1, 2025, the recommendation trends for Apple's peers, operating in the same sub-industry, show a generally positive outlook with varying degrees of \"Strong Buy,\" \"Buy,\" \"Hold,\" \"Sell,\" and \"Strong Sell\" recommendations.\n\n**Companies with the Strongest Positive Sentiment (High \"Strong Buy\" and \"Buy\" recommendations):**\n\n*   **DELL Technologies - Class C (DELL):** Leads with a combined 26 \"Strong Buy\" (7) and \"Buy\" (19) recommendations.\n*   **Western Digital Corporation (WDC):** Shows strong positive sentiment with 25 combined \"Strong Buy\" (6) and \"Buy\" (19) recommendations.\n*   **Pure Storage Inc - Class A (PSTG):** Has a notable 20 combined \"Strong Buy\" (8) and \"Buy\" (12) recommendations.\n\n**Companies with the Highest \"Hold\" Sentiment:**\n\n*   **NetApp Inc (NTAP):** Has the highest number of \"Hold\" recommendations at 16.\n*   **HP Inc (HPQ):** Also shows a significant number of \"Hold\" recommendations at 14.\n*   **Hewlett Packard Enterprise (HPE):** Has 11 \"Hold\" recommendations.\n\n**Companies with \"Sell\" Recommendations:**\n\n*   **Super Micro Computer Inc (SMCI):** Has the highest number of \"Sell\" recommendations with 3.\n*   **HP Inc (HPQ):** Has 1 \"Sell\" recommendation.\n*   **Pure Storage Inc - Class A (PSTG):** Has 1 \"Sell\" recommendation.\n\n**Companies with No \"Sell\" or \"Strong Sell\" Recommendations:**\n\n*   DELL Technologies - Class C (DELL)\n*   Hewlett Packard Enterprise (HPE)\n*   Western Digital Corporation (WDC)\n*   NetApp Inc (NTAP)\n*   IONQ Inc (IONQ)\n*   SanDisk Corporation (SNDK)\n*   Diebold Nixdorf Inc (DBD)\n*   CompoSecure Inc - A (CMPO)\n\nIn summary, DELL Technologies and Western Digital Corporation exhibit the most favorable analyst recommendations. NetApp Inc, HP Inc, and Hewlett Packard Enterprise show a more mixed sentiment with a substantial portion of \"Hold\" recommendations. Super Micro Computer Inc is the only peer with a notable number of \"Sell\" recommendations. The remaining companies generally have fewer total analyst recommendations but still lean towards positive or neutral sentiment."},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  1000\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"send_message(\n    \"\"\"Tell me Amazon's current share price and provide candlestick data for the past month.\n    Sort the data in descending order by date. Format the prices consistently as currency.\n    Round prices to two decimal places.\n    Present the data with multiple columns for display in markdown.\n    Discuss and provide details about any patterns you notice in the price data.\n    Correlate recent patterns with news over the same date range.\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:03:16.922724Z","iopub.execute_input":"2025-08-29T03:03:16.92335Z","iopub.status.idle":"2025-08-29T03:04:10.441495Z","shell.execute_reply.started":"2025-08-29T03:03:16.923275Z","shell.execute_reply":"2025-08-29T03:04:10.440287Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 2/2 [00:00<00:00,  4.43it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon's (AMZN) current share price is **\\$231.60**.\n\nHere is the candlestick data for Amazon for the past month, sorted in descending order by date:\n\n| Date | Open Price | High Price | Low Price | Close Price | Volume |\n|:---|:---|:---|:---|:---|:---|\n| Wed Aug 27 2025 | \\$228.57 | \\$229.87 | \\$227.81 | \\$229.12 | 21,254,479 |\n| Tue Aug 26 2025 | \\$227.11 | \\$229.00 | \\$226.02 | \\$228.71 | 26,105,373 |\n| Mon Aug 25 2025 | \\$227.35 | \\$229.60 | \\$227.31 | \\$227.94 | 22,633,695 |\n| Fri Aug 22 2025 | \\$222.79 | \\$229.14 | \\$220.82 | \\$228.84 | 37,315,341 |\n| Thu Aug 21 2025 | \\$222.65 | \\$222.78 | \\$220.50 | \\$221.95 | 32,140,459 |\n| Wed Aug 20 2025 | \\$227.12 | \\$227.27 | \\$220.92 | \\$223.81 | 36,604,319 |\n| Tue Aug 19 2025 | \\$230.09 | \\$230.53 | \\$227.12 | \\$228.01 | 29,891,012 |\n| Mon Aug 18 2025 | \\$230.22 | \\$231.91 | \\$228.33 | \\$231.49 | 25,248,890 |\n| Fri Aug 15 2025 | \\$232.58 | \\$234.08 | \\$229.81 | \\$231.03 | 39,649,244 |\n| Thu Aug 14 2025 | \\$227.40 | \\$233.11 | \\$227.02 | \\$230.98 | 61,545,824 |\n| Wed Aug 13 2025 | \\$222.00 | \\$224.92 | \\$222.00 | \\$224.56 | 36,508,335 |\n| Tue Aug 12 2025 | \\$222.23 | \\$223.50 | \\$219.05 | \\$221.47 | 37,254,707 |\n| Mon Aug 11 2025 | \\$221.78 | \\$223.05 | \\$220.40 | \\$221.30 | 31,646,222 |\n| Fri Aug 8 2025 | \\$223.14 | \\$223.80 | \\$221.88 | \\$222.69 | 32,970,477 |\n| Thu Aug 7 2025 | \\$221.00 | \\$226.22 | \\$220.82 | \\$223.13 | 40,603,513 |\n| Wed Aug 6 2025 | \\$214.70 | \\$222.65 | \\$213.74 | \\$222.31 | 54,823,045 |\n| Tue Aug 5 2025 | \\$213.05 | \\$216.30 | \\$212.87 | \\$213.75 | 51,505,121 |\n| Mon Aug 4 2025 | \\$217.40 | \\$217.44 | \\$211.42 | \\$211.65 | 77,890,146 |\n| Fri Aug 1 2025 | \\$217.21 | \\$220.44 | \\$212.80 | \\$214.75 | 122,258,801 |\n| Thu Jul 31 2025 | \\$235.77 | \\$236.53 | \\$231.40 | \\$234.11 | 104,357,263 |\n| Wed Jul 30 2025 | \\$231.64 | \\$231.80 | \\$229.29 | \\$230.19 | 32,993,273 |\n| Tue Jul 29 2025 | \\$234.15 | \\$234.72 | \\$230.31 | \\$231.01 | 33,716,220 |\n| Mon Jul 28 2025 | \\$233.35 | \\$234.29 | \\$232.25 | \\$232.79 | 26,300,138 |\n\n**Price Patterns and News Correlation:**\n\n**Early August Decline (July 31 - August 1):**\nAmazon's stock experienced a notable drop from **\\$234.11 on July 31st to \\$214.75 on August 1st**, accompanied by exceptionally high trading volume (over 122 million shares). This decline was primarily driven by investor concerns following Amazon's second-quarter earnings report. News articles from August 1st indicated that despite beating revenue and earnings expectations, the stock plummeted due to **slower-than-expected Amazon Web Services (AWS) growth** (18% year-over-year) compared to competitors like Microsoft (39%) and Google Cloud (32%). Additionally, **potential impacts from new tariffs** contributed to investor apprehension. Reports also highlighted increased operating expenses and decreased free cash flow, dampening investor enthusiasm.\n\n**Mid-August Recovery and Stability (August 4 - August 13):**\nFollowing the sharp decline, Amazon's stock entered a period of recovery and relative stability, trading mostly within the **\\$211 to \\$225 range**. There was a gradual upward trend from August 4th (\\$211.65) to August 13th (\\$224.56). During this time, news articles generally focused on Amazon's long-term potential and strategic investments. Several reports, such as \"Amazon Enters Correction Zone: Time to Panic or Be Brave?\" (August 5th), suggested that the initial stock correction was a healthy market reset rather than a fundamental issue. Analysts continued to recommend Amazon as a strong investment, citing its market leadership in e-commerce, cloud computing, and digital advertising, along with its ongoing **Artificial Intelligence (AI) initiatives**. News about Amazon's aggressive expansion in grocery delivery and its rapidly growing advertising business also contributed to a positive long-term outlook.\n\n**Late August Upward Trend (August 15 - August 27):**\nTowards the latter half of August, Amazon's stock demonstrated a consistent upward trend, moving from approximately **\\$231.03 on August 15th to \\$229.12 on August 27th**. This sustained growth was supported by continued positive news regarding Amazon's strategic positioning and AI advancements. Articles like \"1 Unstoppable Stock That Could Join Nvidia, Microsoft, and Apple in the \\$3 Trillion Club by 2027\" (August 15th) and \"Where Will Amazon Stock Be in 5 Years?\" (August 16th) reiterated the company's significant market valuation potential and strong second-quarter performance. Reports also highlighted Amazon's collaborations and partnerships in AI, such as with Domo, further boosting positive sentiment. The overall positive market sentiment for major technology stocks, with Amazon frequently mentioned as a key player in the \"Magnificent Seven,\" also played a role in its sustained upward trajectory."},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"send_message(\"What is Apple's ticker overview\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:04:38.787094Z","iopub.execute_input":"2025-08-29T03:04:38.787505Z","iopub.status.idle":"2025-08-29T03:04:43.006515Z","shell.execute_reply.started":"2025-08-29T03:04:38.787479Z","shell.execute_reply":"2025-08-29T03:04:43.005343Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple Incorporated (ticker: AAPL) is a large company that is traded on the XNAS exchange. It is based in Cupertino, CA. Its CIK is 0000320193, composite FIGI is BBG000B9XRY4, and share class FIGI is BBG001S5N8V8. The market capitalization is 3420561491100.0 United States dollars. Apple's phone number is (408) 996-1010. The company employs 164000 people. Apple's listing date was 1980-12-12. Apple's logo can be found at https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_logo.svg, and its icon can be found at https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_icon.png. The number of share class shares outstanding is 14840390000, and the weighted shares outstanding is 14840390000. The round lot is 100. Apple is among the largest companies in the world, with a broad portfolio of hardware and software products targeted at consumers and businesses. Apple's iPhone makes up a majority of the firm sales, and Apple's other products like Mac, iPad, and Watch are designed around the iPhone as the focal point of an expansive software ecosystem. Apple has progressively worked to add new applications, like streaming video, subscription bundles, and augmented reality. The firm designs its own software and semiconductors while working with subcontractors like Foxconn and TSMC to build its products and chips. Slightly less than half of Apple's sales come directly through its flagship stores, with a majority of sales coming indirectly through partnerships and distribution.\n"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"send_message(\"Tell me about Amazon's historical and current recommendation trends\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:05:25.858285Z","iopub.execute_input":"2025-08-29T03:05:25.858727Z","iopub.status.idle":"2025-08-29T03:05:28.887385Z","shell.execute_reply.started":"2025-08-29T03:05:25.858697Z","shell.execute_reply":"2025-08-29T03:05:28.886193Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is a summary of Amazon's recommendation trends:\n\nAs of August 1, 2025, the analyst recommendation trends for Amazon (AMZN) are: 51 buy recommendations, 4 hold recommendations, 0 sell recommendations, 24 strong buy recommendations, and 0 strong sell recommendations.\n\nThe recommendation trends for the previous three months are as follows:\n*   July 1, 2025: 50 buy, 5 hold, 0 sell, 24 strong buy, 0 strong sell\n*   June 1, 2025: 50 buy, 5 hold, 0 sell, 24 strong buy, 0 strong sell\n*   May 1, 2025: 51 buy, 6 hold, 0 sell, 22 strong buy, 0 strong sell\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"send_message(\"What is Google's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:05:47.435277Z","iopub.execute_input":"2025-08-29T03:05:47.435639Z","iopub.status.idle":"2025-08-29T03:05:58.928681Z","shell.execute_reply.started":"2025-08-29T03:05:47.435616Z","shell.execute_reply":"2025-08-29T03:05:58.927397Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Google's stock ticker symbols on the NASDAQ stock exchange are GOOGL and GOOG. The ticker symbol on the Frankfurt Stock Exchange is GGQ1. These symbols refer to Alphabet Inc., Google's holding company.\n"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"send_message(\"What is MGM Studio's stock symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:06:08.852752Z","iopub.execute_input":"2025-08-29T03:06:08.853919Z","iopub.status.idle":"2025-08-29T03:06:17.011667Z","shell.execute_reply.started":"2025-08-29T03:06:08.853877Z","shell.execute_reply":"2025-08-29T03:06:17.010554Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am sorry, I was unable to find the stock ticker symbol for Mgm Studios.\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"send_message(\"What is MGM Studio's owner company stock symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:07:02.266817Z","iopub.execute_input":"2025-08-29T03:07:02.267315Z","iopub.status.idle":"2025-08-29T03:07:08.494831Z","shell.execute_reply.started":"2025-08-29T03:07:02.267282Z","shell.execute_reply":"2025-08-29T03:07:08.493584Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon owns Mgm Studios. Amazon acquired Mgm in May 2021 for \\$8.45 billion, and the studio continues to operate as a label alongside Amazon Studios and Amazon Prime Video. Amazon's stock symbol is AMZN.\n"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"send_message(\"What is Facebook's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:07:19.644088Z","iopub.execute_input":"2025-08-29T03:07:19.644637Z","iopub.status.idle":"2025-08-29T03:07:27.838953Z","shell.execute_reply.started":"2025-08-29T03:07:19.644601Z","shell.execute_reply":"2025-08-29T03:07:27.837693Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbol for Meta Platforms, Inc., formerly known as Facebook, is META. It is traded on the Nasdaq stock exchange.\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"send_message('''Compare Amazon's bullish versus bearish predictions from May 01 2025 until today.\n                Include a discussion of recommendation trends, and sentiment analysis of news from the same dates.\n                Discuss any patterns or correlations you find.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:14:33.040935Z","iopub.execute_input":"2025-08-29T03:14:33.041338Z","iopub.status.idle":"2025-08-29T03:16:06.999615Z","shell.execute_reply.started":"2025-08-29T03:14:33.04131Z","shell.execute_reply":"2025-08-29T03:16:06.998674Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  1000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"From May 1, 2025, to August 28, 2025, Amazon (AMZN) has consistently received an overwhelmingly bullish outlook from analysts, with a strong correlation to positive news sentiment.\n\n**Recommendation Trends:**\nAnalyst recommendations for Amazon remained highly positive throughout this period. In May 2025, there were 22 \"Strong Buy\" and 51 \"Buy\" recommendations, with only 6 \"Hold\" ratings and no \"Sell\" or \"Strong Sell\" recommendations. By August 2025, the \"Strong Buy\" recommendations slightly increased to 24, while \"Buy\" recommendations remained robust at 51. \"Hold\" ratings saw a minor decrease to 4, and there continued to be no \"Sell\" or \"Strong Sell\" ratings. This consistent trend indicates a firm belief among analysts in Amazon's continued growth and strong market position.\n\n**Sentiment Analysis of News:**\nThe news sentiment largely mirrored the bullish analyst recommendations, with a strong focus on Amazon's strategic advantages and growth drivers:\n\n**Bullish Predictions and Positive Sentiment:**\n*   **Artificial Intelligence (AI) and Cloud Computing (Amazon Web Services - AWS):** This was the most prominent positive theme. Numerous articles highlighted Amazon's substantial investments in AI, its leadership in cloud computing through AWS, and the transformative potential of AI to enhance efficiency, reduce costs, and open new revenue streams across its diverse businesses. AWS was frequently cited as a primary profit engine and a key factor in Amazon's long-term expansion.\n*   **E-commerce Dominance and Diversification:** Amazon's strong foothold in the e-commerce market, its expanding Prime membership, and its successful diversification into high-margin sectors like digital advertising and healthcare were consistently praised.\n*   **Robotics and Automation:** The company's extensive deployment of robots in fulfillment centers and its advancements in robotics were seen as crucial for boosting productivity and optimizing operational costs.\n*   **Strategic Collaborations:** Partnerships in AI, quantum computing, and advertising (e.g., with Roku) were viewed favorably, indicating Amazon's proactive approach to innovation.\n*   **Strong Financial Performance:** Many reports noted Amazon's ability to surpass earnings estimates, achieve robust revenue growth, and maintain healthy profit margins.\n*   **Investor Confidence:** Billionaire investors like Bill Ackman and Warren Buffett's Berkshire Hathaway either increased their stakes or maintained significant positions in Amazon, further solidifying positive market sentiment. Wall Street analysts frequently issued bullish price targets and \"Buy\" ratings.\n\n**Bearish Predictions and Neutral Sentiment:**\nWhile the overall sentiment was positive, some articles presented neutral or slightly negative perspectives, often related to specific challenges:\n*   **Tariffs and Trade Tensions:** Early in the period (May), concerns were raised about the impact of US sanctions and tariffs on Amazon's business, potentially leading to higher prices and affecting e-commerce sales. However, Amazon's resilience and ability to mitigate these impacts were also noted.\n*   **Competition in Cloud and AI:** Although AWS leads the cloud market, some articles highlighted competitors like Microsoft Azure and Google Cloud growing faster in certain segments or developing their own AI chips, posing a competitive challenge.\n*   **Slower Growth in Specific Segments:** Occasional reports mentioned a deceleration in online sales or cloud computing growth compared to previous periods, or conservative guidance for upcoming quarters, which sometimes led to temporary stock pullbacks.\n*   **Valuation Concerns:** A few articles suggested that Amazon's stock might be trading at a high valuation, implying that its price already factored in significant future growth.\n*   **Workforce Reduction:** Amazon Chief Executive Officer Andy Jassy's comments about AI and automation potentially reducing the workforce were noted, though often framed as a strategic move for efficiency rather than a negative indicator.\n*   **Project Kuiper Challenges:** Delays and intense competition in Amazon's satellite internet project were identified as potential headwinds.\n\n**Patterns and Correlations:**\nA clear pattern emerges: the consistently bullish analyst recommendations are strongly correlated with the predominantly positive news sentiment. The market and analysts appear to prioritize Amazon's long-term growth potential, driven by its technological innovation and market dominance, particularly in AI and cloud computing. Short-term challenges, such as tariff impacts or competitive pressures, were generally perceived as manageable or temporary, often leading to \"buy the dip\" recommendations rather than a shift to a bearish outlook. This indicates a deep-seated confidence in Amazon's strategic direction and its ability to capitalize on emerging technological trends."},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"send_message('''Compare Google's bullish versus bearish predictions from May 01 2025 until today.\n                Include a discussion of recommendation trends, and sentiment analysis of news from the same dates.\n                Discuss any patterns or correlations you find.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:38:14.319266Z","iopub.execute_input":"2025-08-29T03:38:14.319702Z","iopub.status.idle":"2025-08-29T03:39:26.135962Z","shell.execute_reply.started":"2025-08-29T03:38:14.319662Z","shell.execute_reply":"2025-08-29T03:39:26.135053Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  1000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"From May 1, 2025, to August 28, 2025, Alphabet Inc. (GOOGL) experienced a predominantly bullish sentiment from both financial analysts and news coverage.\n\n**Recommendation Trends:**\nAnalyst recommendations for Alphabet Inc. Class A (GOOGL) consistently reflected a positive outlook. \"Strong Buy\" recommendations saw a slight increase from 17 in May to 18 in June, July, and August. \"Buy\" recommendations remained stable at 33 in May and June, dipped marginally to 32 in July, but then significantly increased to 37 by August. \"Hold\" recommendations slightly decreased from 14 in May to 13 in June, July, and August. Notably, there were no \"Sell\" or \"Strong Sell\" recommendations throughout this period, indicating a strong and sustained bullish sentiment from analysts.\n\n**Sentiment Analysis of News:**\nAn analysis of news articles related to Alphabet Inc. (GOOGL) during this period revealed a majority of positive articles (50), a substantial number of neutral articles (50), and a smaller number of negative articles (7).\n\n*   **Bullish (Positive) News:** Many articles highlighted Alphabet's robust performance in artificial intelligence (AI), cloud services (Google Cloud), and core businesses like Search and YouTube. Key positive themes included exceeding earnings expectations, increased institutional investment, analyst price target upgrades, significant advancements in AI (Gemini models, AI-powered search, robotics platforms), and strategic partnerships (e.g., with Nokia, XMPro, ATX Defense, Odoo, SMX, OpenAI, MiLi, Brookfield Asset Management, and Uber's Waymo). Strong revenue growth, attractive valuations, and share repurchase programs were also frequently cited as positive indicators. Alphabet was also positioned as a leader in quantum computing and a promising long-term investment.\n*   **Bearish (Negative) News:** Negative sentiment was primarily driven by concerns related to antitrust rulings (e.g., potential impact on Apple's profits, Epic Games lawsuit), perceived threats to Google's core search engine business from emerging large language models, and the environmental impact of water usage by data centers. Some articles also reported stock price drops due to specific news or broader market concerns.\n*   **Neutral News:** A significant portion of the news was neutral, often discussing upcoming earnings reports, general market volatility, comparisons with competitors without a strong directional sentiment, routine corporate actions (e.g., app delistings), or partnerships where Google's role was more as a platform provider rather than a direct performance indicator. Some articles also presented mixed outlooks, acknowledging both challenges and opportunities.\n\n**Patterns and Correlations:**\nThere is a strong correlation between the consistently bullish analyst recommendations and the predominantly positive sentiment observed in news articles. The high number of \"Strong Buy\" and \"Buy\" ratings from analysts aligns with the numerous news pieces highlighting Alphabet's strong financial performance, leadership in AI, and strategic business expansions.\n\nThe negative news, while present, did not significantly deter the overall bullish sentiment from analysts. This suggests that the market and analysts largely viewed these negative developments (such as antitrust concerns and AI competition to search) as manageable risks or as opportunities for Alphabet to adapt and innovate, rather than fundamental threats to its long-term prospects. For example, while some articles discussed the potential for AI to disrupt Google Search, others emphasized Alphabet's proactive integration of AI into its search and cloud services as a strategic strength. The consistent focus on Alphabet's AI advancements, cloud growth, and diversified business model in positive news articles likely reinforced the bullish analyst sentiment throughout this period."},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"send_message(\n    '''How is the outlook for Apple based on trends and news sentiment from May 01 2025 until today?\n    Perform the same analysis on all peers by sub-industry. Then compare Apple result to it's peers.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T04:06:32.564848Z","iopub.execute_input":"2025-08-29T04:06:32.565395Z","iopub.status.idle":"2025-08-29T04:07:01.657518Z","shell.execute_reply.started":"2025-08-29T04:06:32.56536Z","shell.execute_reply":"2025-08-29T04:07:01.656474Z"}},"outputs":[{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of the outlook for Apple and its peers based on recommendation trends and news sentiment from May 1, 2025, to August 29, 2025.\n\n**Apple (AAPL) Analysis**\n\n*   **Recommendation Trends:** Analyst recommendations for Apple in August 2025 show a consensus of \"Buy\" with 24 buys, 15 holds, and 3 sells. Similar trends were observed in May, June, and July 2025.\n*   **News Sentiment:** The news sentiment for Apple is mixed. Recent articles mention both positive and negative aspects.\n\n    *   **Positive:** Apple is recognized for its AI potential, inclusion in growth ETFs, and strategic partnerships. For example, it is part of a new streaming bundle with Rogers Xfinity, is a top holding in AI-driven ETFs, and has a long-term agreement with MP Materials for US-produced magnets.\n    *   **Neutral:** Some articles mention Apple in the context of market trends or as part of a bundled service without strong positive or negative sentiment.\n    *   **Negative:** Apple is perceived as lagging in AI developments compared to other tech giants. Warren Buffett's Berkshire Hathaway has been reducing its Apple stake. There are also class action lawsuits alleging false statements about AI-based Siri features.\n\n**Peer Analysis**\n\nApple's peers by sub-industry include: Dell Technologies, Hewlett Packard Enterprise, HP Inc, Pure Storage Inc, Super Micro Computer Inc, Western Digital Corp, NetApp Inc, IonQ Inc, Sandisk Corp, Diebold Nixdorf Inc, and Composecure Inc.\n\n**Comparison to Peers**\n\n*   **Nvidia (NVDA):** Nvidia is frequently mentioned as a leader in AI, with strong revenue growth and market dominance. It is often compared favorably to Apple in terms of AI innovation.\n*   **Microsoft (MSFT):** Microsoft is also recognized as a leader in AI and cloud computing, often outperforming Apple in AI developments.\n*   **Alphabet (GOOG/GOOGL):** Alphabet is seen as a strong competitor in AI, with potential for significant growth. Some articles suggest it could surpass Apple in market capitalization.\n\n**Summary**\n\nThe outlook for Apple is cautiously optimistic. While the company faces challenges in AI and trade, it maintains a strong financial position and brand. Analyst recommendations remain positive, but news sentiment is mixed. Compared to its peers, particularly Nvidia, Microsoft, and Alphabet, Apple is perceived as lagging in AI innovation.\n"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"send_message(\n    '''What does the recent news say about Apple and the impact of tariffs? From 2025-03-01 up to today.\n    Also locate candlestick data for the same dates. \n    Discuss in detail any correlations in patterns between the candlestick and news data.\n    Ignore duplicate news entry.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T03:43:00.98351Z","iopub.execute_input":"2025-08-29T03:43:00.983862Z","iopub.status.idle":"2025-08-29T03:43:39.163061Z","shell.execute_reply.started":"2025-08-29T03:43:00.98384Z","shell.execute_reply":"2025-08-29T03:43:39.161892Z"}},"outputs":[{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"},{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of the news about Apple and the impact of tariffs, along with candlestick data analysis.\n\n**News Summary for Apple (March 1, 2025 - August 28, 2025):**\n\nThe news articles present a mixed view of Apple during this period. Here's a breakdown of key themes:\n\n*   **AI Development:** Apple is seen as lagging behind competitors in AI development, but is actively exploring partnerships and acquisitions to enhance its AI capabilities, particularly for Siri. There are reports of Apple considering using Google's Gemini AI.\n*   **Tariffs and Trade:** Apple faces potential negative impacts from tariffs, particularly on iPhones manufactured in China. However, the company is also taking steps to mitigate these risks by diversifying production to India and potentially securing tariff exemptions through increased U.S. investments.\n*   **Stock Performance and Valuation:** Apple's stock performance has been mixed, with some analysts suggesting it is overvalued and others seeing potential for growth. Warren Buffett's Berkshire Hathaway has reduced its stake in Apple, citing valuation concerns. There are also reports of class action lawsuits against Apple alleging misrepresentations about AI features.\n*   **New Products and Services:** Apple is planning to launch innovative AI-powered smart home products by 2027, including a tabletop robot and smart speaker. The company is also working on a foldable iPhone with potential AI tools.\n*   **Financial Performance:** Apple continues to demonstrate strong financial performance, paying quarterly dividends and aggressively repurchasing shares.\n*   **Partnerships:** Apple is partnering with Rogers in Canada to bundle Apple TV+ with other streaming services. It also has a long-term agreement with MP Materials for U.S.-produced magnets.\n*   **Legal Issues:** Apple faces a class action lawsuit alleging false statements about AI-based Siri features for the iPhone 16. Epic Games secured a partial legal win against Apple in an Australian court.\n\n**Candlestick Data Analysis:**\n\nI have retrieved the candlestick data for Apple (AAPL) from March 1, 2025, to August 28, 2025. Due to the limitations of the tool, I am unable to perform a detailed technical analysis or identify specific candlestick patterns. However, I can provide some general observations:\n\n*   The candlestick data shows the daily open, high, low, and close prices for Apple stock during the specified period.\n*   The volume data indicates the number of shares traded each day.\n*   The candlestick patterns and volume data could be used to identify potential trends, support and resistance levels, and other technical indicators.\n\n**Correlations between Candlestick and News Data:**\n\nWithout the ability to perform a more in-depth analysis, it's difficult to pinpoint specific correlations. However, here's how one might look for connections:\n\n*   **News Events and Price Movements:** Significant news events, such as announcements about tariffs, AI partnerships, or product launches, could be correlated with price movements in the candlestick data. For example, a positive news announcement might be followed by a price increase, while a negative announcement could lead to a price decrease.\n*   **Volume and Sentiment:** High trading volume could indicate strong market sentiment, either positive or negative, related to a particular news event.\n*   **Candlestick Patterns and Trend Changes:** Specific candlestick patterns, such as bullish or bearish engulfing patterns, could signal potential trend changes in response to news events.\n\n**Example:**\n\nIf there was news about potential tariffs being imposed on Apple products, you might look for a corresponding drop in the stock price and an increase in trading volume in the candlestick data. Conversely, if there was news about a successful AI partnership, you might look for a price increase and high volume.\n\n**In conclusion:** The recent news about Apple is a mix of positive and negative developments. The company faces challenges related to AI development, tariffs, and competition, but it also has opportunities for growth through new products, services, and strategic partnerships. A thorough analysis of the candlestick data, in conjunction with the news events, could provide valuable insights into the stock's potential future performance.\n"},"metadata":{}}],"execution_count":55},{"cell_type":"markdown","source":"# Conclusion\n\n<span style=\"font-size:18px;\">\nFor now that will have to do. Our Essy has a solid foundation but more could be done to organise metadata. No evaluation or validation has been performed (except fuzzing the prompt). Next steps include restructuring the vector database based on lessons learned. That'll be followed by plotting, multi-modal, and structured output. The last close date (generative) function can be temperamental. In the same way Gemini always feels regarding dates. I've learnt so much. I'm happy I decided to participate in the event! It really has been a joy to see Essy grow from random chat with Gemini into the foundation for a good-broker buddy. I hope you enjoy playing with this edition as much as I enjoyed building it!\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Update June 7, 2025\n\n<span style=\"font-size:18px;\">\n    Bugfix version 102 finally brings Essy to a stable milestone. A month and a half late :) There's still more to be built including adding reasoning, agents, and structured output. A few unimplemented rest endpoints remain that could make Essy more self-reliant. The vector store has gotten bigger but not smarter. Essy can tell us pre-scored news has some sentiment but cannot generate it due to limited summaries. Essy can detect interesting patterns in a dataset but not between adjacent datasets. There's so much data we'll need to recruit Essy some help.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Advanced (localhost required)\n\n<span style=\"font-size:18px;\">\n    The functions demonstrated here require a locally running notebook. A dedicated GPU with at least 8GB VRAM is recommended but not required. Output is generated with Gemma 3 12B QAT, Gemma.cpp, and (later) Gemma 3n. Output on Kaggle is based on cached data.\n</span>","metadata":{}},{"cell_type":"code","source":"# soon","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null}]}