{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-2-document-q-a-with-rag.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11376588,"sourceType":"datasetVersion","datasetId":7122584}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oswind/stockchat-a-stock-market-assistant?scriptVersionId=260361300\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Environment Setup","metadata":{}},{"cell_type":"code","source":"# Setup the notebook based on running environment.\nimport os\n# Optional: Enable telemetry in browser_use and chromadb\nos.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\ntry:\n    from kaggle_secrets import UserSecretsClient # type: ignore\nexcept Exception as e:\n    class UserSecretsClient:\n        @classmethod\n        def get_secret(cls, id: str):\n            try:\n                return os.environ[id]\n            except KeyError as e:\n                print(f\"KeyError: authentication token for {id} is undefined\")\n    # Local Run: update the venv.\n    %pip install -qU google-genai==1.29.0 chromadb==0.6.3 opentelemetry-proto==1.34.1 langchain-google-genai==2.1.2 #langgraph==0.3.21 langgraph-prebuilt==0.1.7\n    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core lmnr[all] browser-use\n    from browser_use import Agent as BrowserAgent\nelse:\n    # Kaggle Run: update the system.\n    !pip uninstall -qqy google-generativeai google-cloud-automl google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway\n    !pip install -qU google-genai==1.29.0 chromadb==0.6.3 opentelemetry-proto==1.34.1 langchain-google-genai==2.1.2\n    !pip install -qU langchain-community langchain-text-splitters wikipedia lmnr[all]\n\nimport ast, chromadb, json, logging, pandas, platform, pytz, re, requests, time, warnings, wikipedia\nfrom bs4 import Tag\nfrom chromadb import Documents, Embeddings\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse\nfrom enum import Enum\nfrom google import genai\nfrom google.api_core import retry, exceptions\nfrom google.genai import types\nfrom IPython.display import Markdown, display\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain_text_splitters.html import HTMLSemanticPreservingSplitter\nfrom langchain_text_splitters.json import RecursiveJsonSplitter\nfrom lmnr import Laminar\nfrom math import inf\nfrom pydantic import BaseModel, field_validator\nfrom threading import Timer\nfrom tqdm import tqdm\nfrom typing import Optional, Callable, NewType\nfrom wikipedia.exceptions import DisambiguationError, PageError","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:09:08.735113Z","iopub.execute_input":"2025-09-06T16:09:08.736058Z","iopub.status.idle":"2025-09-06T16:10:33.140249Z","shell.execute_reply.started":"2025-09-06T16:09:08.735993Z","shell.execute_reply":"2025-09-06T16:10:33.139315Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.6/222.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.4/136.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.8/160.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.4/231.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.0/308.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Prepare the Gemini api for use.\n# Setup a retry helper in case we hit the RPM limit on generate_content or embed_content.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503, 500})\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\ngenai.models.Models.embed_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.embed_content)\n\n# Import the required google api key.\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\n# Activate Laminar auto-instrumentation.\ntry:\n    Laminar.initialize(project_api_key=UserSecretsClient().get_secret(\"LMNR_PROJECT_API_KEY\"))\nexcept:\n    print(\"Skipping Laminar.initialize()\")\n\nclass GeminiModel:\n    def __init__(self, rpm: list, tpm: list, rpd: list):\n        self.rpm = rpm # requests per minute\n        self.tpm = tpm # tokens per minute in millions\n        self.rpd = rpd # requests per day\n        self.err = [0,0] # validation, api_related\n\n# A Gemini python api-helper with retry support.\nGeminiEmbedFunction = NewType(\"GeminiEmbedFunction\", None) # forward-decl\nclass Gemini:\n    gen_limit_in = 1048576\n    emb_limit_in = 2048\n    gen_model = {\n        \"gemini-2.0-flash\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # latest: 15 RPM/1M TPM/200 RPD\n        \"gemini-2.5-flash\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # stable: 10 RPM/250K TPM/250 RPD\n        \"gemini-2.5-pro\": GeminiModel([5,150,1000,2000],[.25,2,5,8],[100,10000,50000,inf]), # stable: 5 RPM/250K TPM/100 RPD\n        \"gemini-2.5-flash-lite\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # stable: 15 RPM/250K TPM/1K RPD\n        \"gemini-2.0-flash-001\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # stable: 15 RPM/1M TPM/200 RPD\n        \"gemini-2.5-flash-preview-05-20\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # exp: 10 RPM/250K TPM/250 RPD\n        \"gemini-2.5-flash-lite-06-17\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # exp: 15 RPM/250K TPM/1K RPD\n    }\n    gen_local = []\n    default_model = []\n    embed_model = \"gemini-embedding-001\", GeminiModel([100,3000,5000,10000],[.03,1,5,10],[1000,inf,inf,inf]) # stable: 100 RPM/30K TPM/1000 RPD/100 per batch\n    error_total = 0\n    min_rpm = 3\n    dt_between = 2.0\n    errored = False\n    running = False\n    dt_err = 45.0\n    dt_rpm = 60.0\n\n    @classmethod\n    def get(cls, url: str):\n        # Create a header matching the OS' tcp-stack fingerprint.\n        system_ua = None\n        match platform.system():\n            case 'Linux':\n                system_ua = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.3'\n            case 'Darwin':\n                system_ua = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.10 Safari/605.1.1'\n            case 'Windows':\n                system_ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.3'\n        try:\n            request = requests.get(url, headers={'User-Agent': system_ua})\n            if request.status_code != requests.codes.ok:\n                print(f\"api.get() returned status {request.status_code}\")\n            return request.text\n        except Exception as e:\n            raise e\n\n    class Limit(Enum):\n        FREE = 0\n        TIER_1 = 1\n        TIER_2 = 2\n        TIER_3 = 3\n    \n    class Model(Enum):\n        GEN = 1\n        EMB = 2\n        LOC = 3\n\n    class Const(Enum):\n        STOP = \"I don't know.\"\n        METRIC_BATCH = 20\n        SERIES_BATCH = 40\n        EMBED_BATCH = 100\n        CHUNK_MAX = 1500\n\n        @classmethod\n        def Stop(cls):\n            return cls.STOP.value\n\n        @classmethod\n        def MetricBatch(cls):\n            return cls.METRIC_BATCH.value\n\n        @classmethod\n        def SeriesBatch(cls):\n            return cls.SERIES_BATCH.value\n\n        @classmethod\n        def EmbedBatch(cls):\n            return cls.EMBED_BATCH.value\n\n        @classmethod\n        def ChunkMax(cls):\n            return cls.CHUNK_MAX.value\n\n    def __init__(self, with_limit: Limit, default_model: str):\n        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n        self.limit = with_limit.value\n        self.m_id = list(self.gen_model.keys()).index(default_model)\n        self.default_model.append(default_model)\n        self.default_local = default_model\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n        self.s_embed = GeminiEmbedFunction(self.client, semantic_mode = True)\n        logging.getLogger(\"google_genai\").setLevel(logging.WARNING) # suppress info on generate\n\n    def __call__(self, model: Model) -> str:\n        if model == self.Model.GEN:\n            return \"models/\" + list(self.gen_model.keys())[self.m_id]\n        elif model == self.Model.LOC:\n            return self.gen_local[self.default_local]\n        else:\n            return \"models/\" + self.embed_model[0]\n\n    def push_default_model(self, model_code: str):\n        if model_code in self.gen_model.keys():\n            self.stop_running()\n            self.default_model.append(model_code)\n            self.m_id = list(self.gen_model.keys()).index(model_code)\n        else:\n            print(f\"{model_code} not found in gen_model.keys()\")\n\n    def pop_default_model(self):\n        self.stop_running()\n        self.default_model.pop(-1)\n        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n\n    def set_default_local(self, model_index: int):\n        if model_index in range(0, len(self.gen_local)):\n            self.default_local = model_index\n        else:\n            print(f\"set default local({model_index}) must be 0..{len(self.gen_local)-1}\")\n\n    def retriable(self, retry_fn: Callable, *args, **kwargs):\n        for attempt in range(len(self.gen_model.keys())):\n            try:\n                if self.gen_rpm > self.min_rpm:\n                    self.gen_rpm -= 1\n                else:\n                    self.on_error(kwargs)\n                if not self.running and not self.errored:\n                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n                    self.rpm_timer.start()\n                    self.running = True\n                return retry_fn(*args, **kwargs)\n            except (genai.errors.APIError, exceptions.RetryError) as api_error:\n                if isinstance(api_error, genai.errors.APIError):\n                    retriable = api_error.code in {429, 503, 500, 400} # code 400 when TPM exceeded\n                    if not retriable or attempt == len(self.gen_model.keys())-1:\n                        raise api_error\n                self.on_error(kwargs)\n            except Exception as e:\n                raise e\n\n    def on_error(self, kwargs):\n        self.generation_fail()\n        kwargs[\"model\"] = self(Gemini.Model.GEN)\n        time.sleep(self.dt_between)\n\n    def stop_running(self):\n        if self.running:\n            self.rpm_timer.cancel()\n            self.running = False\n\n    def validation_fail(self):\n        list(self.gen_model.values())[self.m_id].err[0] += 1\n        self.error_total += 1\n\n    def generation_fail(self):\n        self.stop_running()\n        self.save_error()\n        self.next_model()\n        print(\"api.generation_fail.next_model: model is now \", list(self.gen_model.keys())[self.m_id])\n        if not self.errored:\n            self.error_timer = Timer(self.dt_err, self.zero_error)\n            self.error_timer.start()\n            self.errored = True\n\n    def save_error(self):\n        list(self.gen_model.values())[self.m_id].err[1] += 1\n        self.error_total += 1\n\n    def next_model(self):\n        self.m_id = (self.m_id+1)%len(self.gen_model.keys())\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n\n    def refill_rpm(self):\n        self.running = False\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n        print(\"api.refill_rpm \", self.gen_rpm)\n\n    def zero_error(self):\n        self.errored = False\n        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.limit]\n        print(\"api.zero_error: model is now \", list(self.gen_model.keys())[self.m_id])\n\n    def token_count(self, expr: str):\n        count = self.client.models.count_tokens(\n            model=self(Gemini.Model.GEN),\n            contents=json.dumps(expr))\n        return count.total_tokens\n\n    def errors(self):\n        errors = {\"total\": self.error_total, \"by_model\": {}}\n        for m_code, m in self.gen_model.items():\n            errors[\"by_model\"].update({\n                m_code: {\n                    \"api_related\": m.err[1],\n                    \"validation\": m.err[0]\n                }})\n        return errors\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, content: list):\n        return self.s_embed.sts(content)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:10:33.142152Z","iopub.execute_input":"2025-09-06T16:10:33.142723Z","iopub.status.idle":"2025-09-06T16:10:33.286616Z","shell.execute_reply.started":"2025-09-06T16:10:33.142691Z","shell.execute_reply":"2025-09-06T16:10:33.285727Z"}},"outputs":[{"name":"stdout","text":"Skipping Laminar.initialize()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# An embedding function based on gemini-embedding-001.\napi = NewType(\"Gemini\", None) # forward-decl\nclass GeminiEmbedFunction:\n    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n    \n    def __init__(self, genai_client, semantic_mode: bool = False):\n        self.client = genai_client\n        if semantic_mode:\n            self.document_mode = False\n            self.semantic_mode = True\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __embed__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        elif not self.document_mode and not self.semantic_mode:\n            embedding_task = \"retrieval_query\"\n        elif not self.document_mode and self.semantic_mode:\n            embedding_task = \"semantic_similarity\"\n        partial = self.client.models.embed_content(\n            model=api(Gemini.Model.EMB),\n            contents=input,\n            config=types.EmbedContentConfig(task_type=embedding_task))\n        return [e.values for e in partial.embeddings]\n    \n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __call__(self, input: Documents) -> Embeddings:\n        try:\n            response = []\n            for i in range(0, len(input), Gemini.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n                response += self.__embed__(input[i:i + Gemini.Const.EmbedBatch()])\n            return response\n        except Exception as e:\n            print(f\"caught exception of type {type(e)}\\n{e}\")\n            raise e\n\n    def sts(self, content: list) -> float:\n        df = pandas.DataFrame(self(content), index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:10:33.28741Z","iopub.execute_input":"2025-09-06T16:10:33.287679Z","iopub.status.idle":"2025-09-06T16:10:33.297432Z","shell.execute_reply.started":"2025-09-06T16:10:33.287659Z","shell.execute_reply":"2025-09-06T16:10:33.296614Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Instantiate the api-helper with usage limit.\napi = Gemini(with_limit=Gemini.Limit.TIER_1, default_model=\"gemini-2.0-flash\") # or TIER_1,TIER_2,TIER_3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:33.299365Z","iopub.execute_input":"2025-09-06T16:10:33.299712Z","iopub.status.idle":"2025-09-06T16:10:33.755817Z","shell.execute_reply.started":"2025-09-06T16:10:33.299689Z","shell.execute_reply":"2025-09-06T16:10:33.754519Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Laying the foundation with Gemini 2.0\n\n<span style=\"font-size:18px;\">\nA programming instructor once suggested the idea of a Stock Market application for final project topics. They did this knowing good investing app UX is challenging. The idea has stuck with me since because it's true. In the past I've worked with some REST api's building toys. None of them could ever reach my expectations because of API limits. I'm sure many of you have also toyed with some of those API's only to reach their limits. I always knew the secret to great finance UX is a great AI to help out. When posed with so many topics for 2025's 5-Day GenAI Course, I first tinkered with many of the other capabilities of Gemini until I posed Gemini the question:\n</span> ","metadata":{}},{"cell_type":"code","source":"# This is an accurate retelling of events. \nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0\n)\n\nchat = api.client.chats.create(\n    model=api(Gemini.Model.GEN), \n    config=config_with_search, \n    history=[]) # Ignoring the part about dark elves, and tengwar.\n\nresponse = chat.send_message('Do you know anything about the stock market?')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:33.756975Z","iopub.execute_input":"2025-09-06T16:10:33.757297Z","iopub.status.idle":"2025-09-06T16:10:37.216154Z","shell.execute_reply.started":"2025-09-06T16:10:33.757267Z","shell.execute_reply":"2025-09-06T16:10:37.215421Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Yes, I do. Here's some information about the stock market:\n\n**What it is:**\n\n*   The stock market is a place where shares of publicly traded companies are bought and sold.\n*   It allows companies to raise capital for expansion by issuing shares to investors.\n*   Investors who buy shares become part owners of the business.\n*   The stock market consists of a primary market where companies issue shares and a secondary market where investors trade those shares.\n\n**How it works:**\n\n*   Companies issue shares through an initial public offering (IPO) to raise capital.\n*   Investors buy shares hoping to receive dividends, vote in corporate elections, or sell the shares at a higher price.\n*   The price of stocks rises and falls based on supply and demand.\n*   Brokers facilitate transactions between buyers and sellers.\n\n**Key Concepts:**\n\n*   **Shares:** Represent ownership in a company.\n*   **Dividends:** Payments made to shareholders from company profits.\n*   **Bull Market:** A period of sustained uptrends in the stock market.\n*   **Bear Market:** A period of intense downtrends in the stock market.\n\n**Major Stock Exchanges:**\n\n*   New York Stock Exchange (NYSE)\n*   Nasdaq\n*   London Stock Exchange\n\nKeep in mind that investing in the stock market involves risk, and stock prices can be volatile.\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# How much Gemini 2.0 knows\n\n<span style=\"font-size:18px;\">\nI thought to myself: Could grounding really make it that easy? Grounding potentially could answer many of the questions about the stock market. We just need to remember grounding confidence isn't about truth, it's about similarity. I decided to limit myself to free tier in finding out.\n</span>","metadata":{}},{"cell_type":"code","source":"# And so I asked a more challenging questions.\nresponse = chat.send_message('I have an interest in AMZN stock')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:37.216999Z","iopub.execute_input":"2025-09-06T16:10:37.217285Z","iopub.status.idle":"2025-09-06T16:10:43.790107Z","shell.execute_reply.started":"2025-09-06T16:10:37.217262Z","shell.execute_reply":"2025-09-06T16:10:43.789249Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's some information regarding AMZN (Amazon) stock that you might find helpful:\n\n**Current Stock Status:**\n\n*   As of September 5, 2025, Amazon (NASDAQ: AMZN) is trading around $232.84.\n*   Amazon's market capitalization is approximately $2.48 trillion.\n*   The stock has recovered strongly from its yearly low of $161.43, rising more than 40% in the past year.\n*   The stock hit an all-time high on February 4, 2025, but experienced a downturn in March 2025 when the Nasdaq entered bear market territory.\n\n**Analyst Ratings and Price Targets:**\n\n*   The consensus rating among analysts is \"Strong Buy\".\n*   Based on ratings from 45 analysts, the average price target for AMZN is $261.76, suggesting a potential increase of 12.45% over the next year.\n*   The average price target from 50 analysts is $262.87.\n*   Individual analyst price targets range from a low of $195 to a high of $305.\n*   Analysts are generally optimistic about Amazon's prospects, particularly in the short term.\n\n**Factors Influencing the Stock:**\n\n*   **AWS and AI Partnerships:** Amazon Web Services (AWS) remains a significant profit driver, with revenues exceeding $120 billion annually. The partnership with Anthropic, valued at $183 billion, positions AWS as a key player in the AI space.\n*   **Revenue Growth:** Amazon posted $167.7 billion in revenue in Q2 2025, a 13% increase year-over-year.\n*   **Project Kuiper:** Amazon's satellite internet venture, Project Kuiper, has the potential to generate substantial revenue. JetBlue is partnering with Amazon to use Project Kuiper for in-flight Wi-Fi.\n*   **AI Initiatives:** Amazon is reportedly launching a new AI-powered workspace software called Quick Suite.\n*   **Grocery Expansion:** Amazon's expansion into the grocery market could potentially challenge major players like Walmart and Kroger.\n\n**Potential Risks and Concerns:**\n\n*   **Capital Expenditures:** Aggressive capital expenditures in AI, cloud, and satellite internet could strain free cash flow.\n*   **Competition:** Amazon faces intense competition in both the retail and technology sectors.\n*   **Grocery Market Margins:** The grocery business operates on thin margins, which could impact Amazon's profitability.\n*   **Regulatory Concerns:** Amazon, like other large technology firms, faces increasing regulatory scrutiny.\n*   **Insider Selling:** In the past three months, Amazon insiders have sold a significant amount of company stock.\n\n**Additional Points:**\n\n*   Amazon does not currently pay dividends.\n*   The company reinvests its earnings into growth areas such as e-commerce, logistics, cloud computing (AWS), and artificial intelligence.\n*   Amazon is scheduled to release its next earnings report for the period ending September 30, 2024.\n\n**In summary,** analysts have a generally positive outlook on Amazon stock, with a \"Strong Buy\" consensus. They cite factors like AWS growth, AI partnerships, and Project Kuiper as potential drivers for future growth. However, it's important to consider potential risks such as high capital expenditures, competition, and regulatory concerns.\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> \nImpressed, I was reminded of the dreaded REST api's (some official) that I've worked in the past. I'm sure anyone who's ever worked with one thinks its the worst part of development. So I next asked Gemini to distill it's vast news knowledge.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message(\n    '''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:43.791005Z","iopub.execute_input":"2025-09-06T16:10:43.791251Z","iopub.status.idle":"2025-09-06T16:10:50.368049Z","shell.execute_reply.started":"2025-09-06T16:10:43.791231Z","shell.execute_reply":"2025-09-06T16:10:50.36719Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a breakdown of AMZN's current share price, short-term trends, and bullish versus bearish predictions:\n\n**Current Share Price:**\n\n*   As of September 5, 2025, AMZN is trading around $232.33.\n*   Throughout the last trading session, the stock experienced fluctuations of 1.75%, ranging from a day low of $231.93 to a day high of $235.99.\n\n**Short-Term Trends:**\n\n*   **Mixed Signals:** Technical analysis suggests both bullish and bearish signals.\n*   The stock closed at $235.68 on September 4, 2025, trading above its 21-day moving average of $227.59, which typically signals short-term strength.\n*   The stock is in the middle of a wide and weak rising trend in the short term, and a further rise within the trend is signaled.\n*   However, other sources indicate a short-term bearish trend, with the stock positioned below its 50-day moving average.\n*   **Near support:** Amazon finds support from accumulated volume at $223.30, and this level may hold a buying opportunity as an upwards reaction can be expected when the support is being tested.\n\n**Bullish Predictions:**\n\n*   **Analyst Consensus:** The consensus rating among analysts is \"Strong Buy\".\n*   **Price Targets:** The average analyst price target is around $261.76 - $265.00, suggesting a potential increase over the next year.\n*   **Revenue Growth:** Analysts expect revenue to rise from $710 billion in 2025 to $1.153 trillion by the end of 2030.\n*   **Bull Case Scenario:** Under a bull case scenario, Amazon's share price could reach $431 by 2030. This assumes AWS continues to expand, AI models propel growth, and Amazon tops Wall Street projections.\n*   **Technical Breakout:** A clear technical breakout above resistance and improving fundamental metrics suggest AMZN presents a compelling long opportunity. Traders should target $242 in the near term with extended upside potential toward $252.\n\n**Bearish Predictions:**\n\n*   **Bear Case Scenario:** A bear case scenario projects a share price of $77 by 2030. This is based on factors like cloud competition from Microsoft Azure and unprofitable business segments.\n*   **Short-Term Decline:** Some forecasts predict a short-term decline, with the value of shares potentially dropping to around $217.08 by October 4, 2025.\n*   **Overvalued:** One analysis suggests it may be a bad time to buy AMZN stock because it's trading below the forecast and could be overvalued.\n*   **Consolidation:** AMZN consolidates near 234. Ceiling at 242–245 is the last test before new history.\n\n**Factors to Consider:**\n\n*   **Market Sentiment:** The overall market sentiment is neutral, with retail investors leaning slightly bearish, while institutions are cautiously bullish.\n*   **Earnings Reports:** Monitor earnings and technical breakouts for clearer direction.\n*   **Macroeconomic Conditions:** Macro conditions are supportive, though tariff risks remain.\n*   **Competition:** Amazon faces intense competition in both the retail and technology sectors.\n*   **Regulatory Concerns:** Amazon, like other large technology firms, faces increasing regulatory scrutiny.\n"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# The (current) limits reached\n\n<span style=\"font-size:18px;\">\nWith two prompts Gemini 2.0 made all the effort I've spent on finance api's obsolete. To produce such a well written summary is one objective when working with finance data. This is great! Now all we need is a generative AI capable in our own language. There's a limit of course. The grounding is subjectively true based only on it's grounding supports -- it may even be hallucinated:\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:50.368925Z","iopub.execute_input":"2025-09-06T16:10:50.369167Z","iopub.status.idle":"2025-09-06T16:10:52.57296Z","shell.execute_reply.started":"2025-09-06T16:10:50.369146Z","shell.execute_reply":"2025-09-06T16:10:52.571499Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbol for MGM Resorts International is MGM. It is listed on the New York Stock Exchange (NYSE). As of September 5, 2025, the stock is trading around $36.68.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe order of results and/or content of results is interesting here. The AI is confused about which MGM Studios I'm referring to. On non-thinking variants Gemini may not even mention Amazon. Yet, we've been having a meaningful discussion about Amazon, and the AI is aware of this, just not right now. Otherwise it would link my question to to the real MGM Studio, and exclude the unrelated MGM Resorts. The confusion is linked to the use of the MGM word token. The unrelated MGM stock ticker has now entered the discussion. Depending on how you prompt Gemini 2.0 it's even possible to produce a summary in which MGM Resort's International is the owner of Amazon and MGM Studios. There's two more caveat. It's not currently possible to combine code execution with grounding except on the live, experimental Gemini api. Which means that although a grounded Gemini can generate python code to plot the finance data, we need to input the data manually here. That includes matching a schema or prompting it's output.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''Can you run some python to plot that last open,close,hig,low like a candlestick''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:52.573925Z","iopub.execute_input":"2025-09-06T16:10:52.574203Z","iopub.status.idle":"2025-09-06T16:10:54.310358Z","shell.execute_reply.started":"2025-09-06T16:10:52.574181Z","shell.execute_reply":"2025-09-06T16:10:54.309703Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I apologize, I am unable to provide a candlestick chart for MGM due to the error message \"ModuleNotFoundError: No module named 'yfinance'\". This indicates that the yfinance library, which is essential for fetching stock data, is not accessible in the current environment. Therefore, I cannot execute the Python code to generate the requested plot.\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"response = chat.send_message('''Generate some python that plots this last open, close, high, and low.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:54.312911Z","iopub.execute_input":"2025-09-06T16:10:54.313158Z","iopub.status.idle":"2025-09-06T16:10:55.055918Z","shell.execute_reply.started":"2025-09-06T16:10:54.313139Z","shell.execute_reply":"2025-09-06T16:10:55.055056Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am unable to generate a candlestick chart for MGM due to the error message \"ModuleNotFoundError: No module named 'yfinance'\". This indicates that the yfinance library, which is essential for fetching stock data, is not accessible in the current environment. Therefore, I cannot execute the Python code to generate the requested plot.\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:55.056863Z","iopub.execute_input":"2025-09-06T16:10:55.057168Z","iopub.status.idle":"2025-09-06T16:10:56.119932Z","shell.execute_reply.started":"2025-09-06T16:10:55.057143Z","shell.execute_reply":"2025-09-06T16:10:56.11909Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's the AMZN data I mentioned earlier:\n\n*   During the last trading session (as of September 5, 2025), AMZN experienced fluctuations of 1.75%.\n*   The day's low was $231.93.\n*   The day's high was $235.99.\n*   The closing price on September 4, 2025, was $235.68.\n\nI don't have the opening price for that specific day readily available.\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"response = chat.send_message(\n    '''What is AMZN open,close,high,low data for the past month? \n    Present the data with multiple columns for display in markdown.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:10:56.121045Z","iopub.execute_input":"2025-09-06T16:10:56.121312Z","iopub.status.idle":"2025-09-06T16:10:59.943055Z","shell.execute_reply.started":"2025-09-06T16:10:56.121284Z","shell.execute_reply":"2025-09-06T16:10:59.942214Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's the AMZN (Amazon) stock data for the past month (approximately), presented in a markdown table. Keep in mind that \"past month\" is based on available data up to today, September 6, 2025, and the data may not be complete for the most recent days.\n\n| Date       | Open    | High    | Low     | Close   |\n|------------|---------|---------|---------|---------|\n| 2025-09-05 | $235.19 | $236.00 | $231.93 | $232.33 |\n| 2025-09-04 | $231.19 | $235.77 | $230.78 | $235.68 |\n| 2025-09-03 | $225.21 | $227.17 | $224.36 | $225.99 |\n| 2025-09-02 | $223.52 | $226.17 | $221.83 | $225.34 |\n| 2025-08-29 | $231.32 | $231.81 | $228.16 | $229.00 |\n| 2025-08-28 | $229.01 | $232.71 | N/A     | $231.60 |\n| 2025-08-27 | $228.57 | $229.87 | N/A     | $229.12 |\n| 2025-08-26 | $227.11 | N/A     | N/A     | $228.71 |\n| 2025-08-25 | $227.35 | N/A     | N/A     | $227.94 |\n| 2025-08-22 | $222.79 | N/A     | N/A     | $228.84 |\n\n**Disclaimer:** This data is based on information available as of September 6, 2025, and may be subject to change. N/A indicates that I don't have the data available from the search results.\n"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe second caveat is a lack of access to realtime data. Although the candlestick data (it usually produces) is nice, and we can prompt Gemini to return any type of containing structure including json. It also produces non-deterministic output for all stock symbols. Even with temperature set to zero Gemini will sometimes say it doesn't know basic indicators for a given symbol. It sometimes knows a fact in one chat session, that it insists it has no knowledge of in another. Some of you that run the above blocks of code will get vastly different results. Sometimes including the whole month of candlestick data.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Enter StockChat\n\n<span style=\"font-size:18px;\">\nStill, with a total of four prompts Gemini replaces all past effort on wrapping finance api's. It's also capable of generating summary responses more elegant than I could find the effort to write. Enter StockChat, the assistant that knows finance data. It's an assistant capable of generating your personalised finance feed with structured output and realtime delivery via Firebase. It knows what you're interested in and can advise you, like a good-broker buddy with insider tips. It has the spreadsheets but knows you don't want to see them. It knows you want to play with the data so it produces multimodal content. \n<hr>\nIn order to solve these problems we'll need to move beyond a basic chat session to a multi-tool approach. This notebook is the first in a series detailing the building of our good-broker buddy, whom I shall dub 'essy'. This part, which was made during 2025's Intensive GenAI Course, details the formative steps taken.\n</span> ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe main problem to address before starting is the state of multi-tool support in Gemini-2.0. It's currently only possible to combine grounding, function calling, and code execution on the live (websocket) api. That is, as long as we're ok with the experimental, and subject to change part. Clearly that's not an option for our Essy. We'll start with a multi-model approach. Each expert can be good at different parts of the problem. One such expert will use function calling to chain the models together. One expert to rule them all. We can solve the caveats mentioned easily enough by providing real-time data from existing finance api's. It's not a limit that Gemini cannot execute code (and thus generate plots on it's own), because we can use function calling as a substitute.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nWe can't have a knowledgeable Essy without a vector database to store our knowledge. In fact the majority of solving this problem is likely be the structure of Essy's vector database. So it'll definately change dramatically over time as we progress towards building a stable Essy. We'll use the popular Chroma and build a RAG expert to begin. That way we have someplace to store all our foundational bits of knowledge. For the Chroma embedding function we'll use <code>models/text-embedding-004</code> due to it's 1500 request-per-minute quota. We'll need to be mindful of the smaller 2,048 token input. Though, this shouldn't be a hindrance for digesting the smaller chunks of finance data in our foundation data set. For the augmented generation phase we'll use <code>models/gemini-2.0-flash</code> variants due to it's 1500 request-per-day quota.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## BaseModels","metadata":{}},{"cell_type":"code","source":"# Declare BaseModels using pydantic schema.\nclass RestStatus(Enum):\n    OK = \"OK\"\n    DELAY = \"DELAYED\"\n    NONE = \"NOT_FOUND\"\n    AUTH = \"NOT_AUTHORIZED\"\n\nclass StopGeneration(BaseModel):\n    result: str = Gemini.Const.Stop()\n\nclass RestResultPoly(BaseModel):\n    request_id: Optional[str] = None\n    count: Optional[int] = None\n    next_url: Optional[str] = None\n    status: RestStatus  \n\nclass MarketSession(Enum):\n    PRE = \"pre-market\"\n    REG = \"regular\"\n    POST = \"post-market\"\n    CLOSED = \"closed\"\n    NA = \"not applicable\"\n\nclass MarketEvent(Enum):\n    PRE_OPEN = 0\n    REG_OPEN = 1\n    REG_CLOSE = 2\n    POST_CLOSE = 3\n    LAST_CLOSE = 4\n\nclass AssetClass(Enum):\n    STOCKS = \"stocks\"\n    OPTION = \"options\"\n    CRYPTO = \"crypto\"\n    FOREX = \"fx\"\n    INDEX = \"indices\"\n    OTC = \"otc\"\n\nclass SymbolType(Enum):\n    COMMON = \"Common Stock\"\n    ETP = \"ETP\"\n    ADR = \"ADR\"\n    REIT = \"REIT\"\n    DELISTED = \"\"\n    CEF = \"Closed-End Fund\"\n    UNIT = \"Unit\"\n    RIGHT = \"Right\"\n    EQUITY = \"Equity WRT\"\n    GDR = \"GDR\"\n    PREF = \"Preference\"\n    CDI = \"CDI\"\n    NVDR = \"NVDR\"\n    REG = \"NY Reg Shrs\"\n    MLP = \"MLP\"\n    MUTUAL = \"Mutual Fund\"\n\nclass Locale(Enum):\n    US = \"us\"\n    GLOBAL = \"global\"\n\nclass Sentiment(Enum):\n    V_POS = \"very positive\"\n    POSITIVE = \"positive\"\n    NEUTRAL_P = \"neutral/positive\"\n    NEUTRAL_SP = \"neutral/slightly positive\"\n    NEUTRAL = \"neutral\"\n    NEUTRAL_SN = \"neutral/slightly negative\"\n    NEUTRAL_N = \"neutral/negative\"\n    MIXED = \"mixed\"\n    NEGATIVE = \"negative\"\n    V_NEG = \"very negative\"\n\nclass Trend(Enum):\n    S_BUY = \"strong-buy\"\n    BUY = \"buy\"\n    HOLD = \"hold\"\n    SELL = \"sell\"\n    S_SELL = \"strong-sell\"\n\nclass MarketCondition(Enum):\n    BULL = \"bullish\"\n    HOLD = \"hold\"\n    BEAR = \"bearish\"\n\nclass GeneratedEvent(BaseModel):\n    last_close: str\n    pre_open: str\n    reg_open: str\n    reg_close: str\n    post_close: str\n    timestamp: Optional[str] = None\n    is_holiday: Optional[bool] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.timestamp is None:\n            self.timestamp = datetime.now(self.tz()).strftime('%c')\n        if self.is_holiday is None:\n            self.is_holiday = False\n\n    def session(self, with_date: Optional[str] = None) -> MarketSession:\n        if with_date is None:\n            with_date = datetime.now(self.tz()).strftime('%c')\n        compare = parse(with_date)\n        if self.is_holiday or compare.weekday() > 4: # weekend\n            return MarketSession.CLOSED\n        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n        if compare.time() < events[0]:\n            return MarketSession.CLOSED\n        else:\n            session = MarketSession.NA\n            if compare.time() >= events[0]:\n                session = MarketSession.PRE\n            if compare.time() >= events[1]:\n                session = MarketSession.REG\n            if compare.time() >= events[2]:\n                session = MarketSession.POST\n            if compare.time() >= events[3]:\n                session = MarketSession.CLOSED\n        return session\n\n    def is_open(self) -> bool:\n        return self.session() != MarketSession.CLOSED\n\n    def has_update(self) -> bool:\n        datetime_now = datetime.now(self.tz())\n        self_ts = parse(self.timestamp)\n        # Re-generate events for a new day.\n        if datetime_now.day > self_ts.day:\n            return True\n        # No updates on holidays or when generated after post_close.\n        if self.is_holiday or self_ts.time() >= parse(self.post_close).time():\n            return False\n        # Compare current time to generated event times.\n        for event in [self.pre_open,self.reg_open,self.reg_close]:\n            if datetime_now.time() > parse(event).time():\n                return True\n        # Current time is before pre_open.\n        return False\n\n    @classmethod\n    def tz(cls):\n        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    \n    @classmethod\n    def apply_fix(cls, value, fix: datetime) -> tuple[str, datetime]:\n        api.validation_fail()\n        value = fix.strftime('%c')\n        return value, fix\n    \n    @field_validator(\"last_close\")\n    def valid_close(cls, value):\n        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n        # Soft-pass: when actual session is closed after post-market\n        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n            date_fix = date_gen.replace(day=date_now.day)\n            if date_fix.timestamp() < date_now.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n        # Soft-pass: when actual session is open post-market\n        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n            if date_now.weekday() > 0:\n                date_fix = date_gen.replace(day=date_now.day-1)\n            else:\n                date_fix = date_gen.replace(day=date_now.day-3)\n            if date_now.timestamp() > date_fix.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n        if date_now.weekday() == 0 or date_now.weekday() == 1 and date_gen.weekday() <= 4: # 0=monday, 4=friday\n            return value # pass: generated thurs/friday on a monday/tues\n        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() <= date_now.weekday()-1:\n            return value # pass: generated yesterday/prior on a tues-fri\n        elif date_now.weekday() > 4 and date_gen.weekday() <= 4:\n            return value # pass: generated thurs/friday on a weekend\n        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n            return value # pass: generated today after closed\n        elif date_now.timestamp() < date_gen.timestamp():\n            raise ValueError(\"last close cannot be a future value\")\n        else:\n            raise ValueError(\"generated invalid last close\")\n        api.validation_fail()\n\nclass VectorStoreResult(BaseModel):\n    docs: str\n    dist: Optional[float] # requires query\n    meta: Optional[dict]  # requires get or query\n    store_id: str\n\nclass Aggregate(RestResultPoly):\n    symbol: str\n    open: float\n    high: float\n    low: float\n    close: float\n    volume: int\n    otc: Optional[bool] = None\n    preMarket: Optional[float] = None\n    afterHours: Optional[float] = None\n\nclass DailyCandle(Aggregate):\n    from_date: str\n\nclass AggregateWindow(BaseModel):\n    o: float\n    h: float\n    l: float\n    c: float\n    v: int # traded volume\n    n: Optional[int] = None # transaction count\n    vw: Optional[float] = None # volume weighted average price\n    otc: Optional[bool] = None\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        if len(str(value)) == 13:\n            return int(value/1000)\n        return value\n\nclass CustomCandle(RestResultPoly): \n    ticker: str\n    adjusted: bool\n    queryCount: int\n    resultsCount: int\n    results: list[AggregateWindow]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[AggregateWindow]:\n        return self.results\n    \nclass MarketStatus(BaseModel):\n    exchange: str\n    holiday: Optional[str] = None\n    isOpen: bool\n    session: Optional[MarketSession] = None\n    t: int\n    timezone: str\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.session is None:\n            self.session = MarketSession.CLOSED\n        if self.holiday is None:\n            self.holiday = MarketSession.NA.value\n\nclass MarketStatusResult(BaseModel):\n    results: MarketStatus\n\n    def get(self) -> MarketStatus:\n        return self.results\n\nclass Symbol(BaseModel):\n    description: str\n    displaySymbol: str\n    symbol: str\n    type: SymbolType\n\nclass SymbolResult(BaseModel):\n    count: int\n    result: list[Symbol]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.result)\n\n    def get(self) -> list[Symbol]:\n        return self.result\n\nclass Quote(BaseModel):\n    c: float\n    d: float\n    dp: float\n    h: float\n    l: float\n    o: float\n    pc: float\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        return value\n\nclass PeersResult(BaseModel):\n    results: list[str]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[str]:\n        return self.results\n\nclass BasicFinancials(BaseModel):\n    metric: dict\n    metricType: str\n    series: dict\n    symbol: str\n\nclass Insight(BaseModel):\n    sentiment: Sentiment|MarketCondition\n    sentiment_reasoning: str\n    ticker: str\n\nclass Publisher(BaseModel):\n    favicon_url: Optional[str]\n    homepage_url: str\n    logo_url: str\n    name: str\n\nclass NewsSummary(BaseModel):\n    title: str\n    summary: Optional[str]\n    insights: Optional[list[Insight]]\n    published_utc: str\n\nclass NewsTypePoly(BaseModel):\n    amp_url: Optional[str] = None\n    article_url: str\n    title: str\n    author: str\n    description: Optional[str] = None\n    id: str\n    image_url: Optional[str] = None\n    insights: Optional[list[Insight]] = None\n    keywords: Optional[list[str]] = None\n    published_utc: str\n    publisher: Publisher\n    tickers: list[str]\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.description,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass NewsResultPoly(RestResultPoly):\n    results: list[NewsTypePoly]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypePoly]:\n        return self.results\n\nclass NewsTypeFinn(BaseModel):\n    category: str\n    datetime: int\n    headline: str\n    id: int\n    image: str\n    related: str # symbol\n    source: str\n    summary: str\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.headline,\n                           summary=self.summary,\n                           insights=None,\n                           published_utc=self.datetime)\n\nclass NewsResultFinn(BaseModel):\n    results: list[NewsTypeFinn]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypeFinn]:\n        return self.results\n\nclass NewsTypeGenerated(BaseModel):\n    title: str\n    summary: str\n    insights: list[Insight]\n    keywords: list[str]\n    source: Publisher\n    published_utc: str\n    tickers: list[str]\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.summary,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass TickerOverview(BaseModel):\n    ticker: str\n    name: str\n    market: AssetClass\n    locale: Locale\n    primary_exchange: Optional[str] = None\n    active: bool\n    currency_name: str\n    cik: Optional[str] = None\n    composite_figi: Optional[str] = None\n    share_class_figi: Optional[str] = None\n    market_cap: Optional[int|float] = None\n    phone_number: Optional[str] = None\n    address: Optional[dict] = None\n    description: Optional[str] = None\n    sic_code: Optional[str] = None\n    sic_description: Optional[str] = None\n    ticker_root: Optional[str] = None\n    homepage_url: Optional[str] = None\n    total_employees: Optional[int] = None\n    list_date: Optional[str] = None\n    branding: Optional[dict] = None\n    share_class_shares_outstanding: Optional[int] = None\n    weighted_shares_outstanding: Optional[int] = None\n    round_lot: Optional[int] = None\n\nclass OverviewResult(RestResultPoly):\n    results: TickerOverview\n\n    def get(self) -> TickerOverview:\n        return self.results\n\nclass RecommendationTrend(BaseModel):\n    buy: int\n    hold: int\n    period: str\n    sell: int\n    strongBuy: int\n    strongSell: int\n    symbol: str\n\nclass TrendsResult(BaseModel):\n    results: list[RecommendationTrend]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[RecommendationTrend]:\n        return self.results","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:10:59.944028Z","iopub.execute_input":"2025-09-06T16:10:59.944289Z","iopub.status.idle":"2025-09-06T16:11:00.027691Z","shell.execute_reply.started":"2025-09-06T16:10:59.944263Z","shell.execute_reply":"2025-09-06T16:11:00.026783Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Memory","metadata":{}},{"cell_type":"code","source":"# Create the contents-memory object.\nclass Memory:\n    def __init__(self):\n        self.system = f\"\"\"Give a concise, and detailed summary. Use information that you learn from the API responses.\n        Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n        to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n        Convert timestamps according to the rules before including them. Think step by step.\n        \"\"\"\n        self.revery = {}\n        self.prompt = None\n        self.summary = None\n    \n    def set_prompt(self, prompt):\n        self.prompt = f\"\"\"\n        The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n        \n        {prompt}\n        \"\"\"\n        self.contents = [types.Content(role=\"user\", parts=[types.Part(text=self.prompt)])]\n\n    def set_reason(self, step):\n        # Append the model's reasoning part.\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(thought=True,text=step)]))\n\n    def append_code(self, prompt, code_response_parts):\n        subroutine_content = [types.Content(role=\"user\", parts=[types.Part(text=prompt)]),\n                              types.Content(role=\"model\", parts=code_response_parts)]\n        # Append the model's generated code and execution result.\n        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = { \n            \"contents\": subroutine_content\n        }\n\n    def update_contents(self, function_call, api_response_part):\n        # Append the model's function call part.\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n        # Append the api response part.\n        self.contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n\n    def set_summary(self, summary):\n        self.summary = summary\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(text=summary)]))\n        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = {\n            \"prompt\": self.prompt, \n            \"summary\": self.summary, \n            \"contents\": self.contents\n        }\n        self.contents = None\n\nmemory = Memory()","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:00.028788Z","iopub.execute_input":"2025-09-06T16:11:00.029067Z","iopub.status.idle":"2025-09-06T16:11:00.113927Z","shell.execute_reply.started":"2025-09-06T16:11:00.029044Z","shell.execute_reply":"2025-09-06T16:11:00.113125Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Retrieval-Augmented Generation Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Retrieval-Augmented Generation.\n# - using Chroma and text-embedding-004 for storage and retrieval\n# - using gemini-2.0-flash for augmented generation\nclass RetrievalAugmentedGenerator:\n    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n    exchange_codes: Optional[dict] = None\n    exchange_lists: dict = {}\n    events: dict = {}\n    holidays: dict = {}\n\n    def __init__(self, genai_client, collection_name):\n        self.client = genai_client\n        self.embed_fn = GeminiEmbedFunction(genai_client)\n        self.db = self.chroma_client.get_or_create_collection(\n            name=collection_name, \n            embedding_function=self.embed_fn, \n            metadata={\"hnsw:space\": \"cosine\"})\n        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n        self.set_holidays(\"US\", [\"09-01-2025\",\"10-13-2025\",\"11-11-2025\",\"11-27-2025\",\"12-25-2025\"])\n        self.generated_events(\"US\")\n\n    def set_holidays(self, exchange_code: str, holidays: list):\n        self.holidays[exchange_code] = [datetime.strptime(h, \"%m-%d-%Y\").date() for h in holidays]\n\n    def get_exchange_codes(self, with_query: Optional[str] = None):\n        gen = None\n        if with_query and with_query not in self.exchange_lists.keys():\n            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n            data = self.get_exchanges_csv(\n                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n                as a list in string form. Just the list string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n            self.exchange_lists[with_query] = ast.literal_eval(data.parts[-1].text)\n        elif with_query is None and self.exchange_codes is None:\n            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n            data = self.get_exchanges_csv(\n                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n                mapping exchange code to name. Just the dictionary string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n            self.exchange_codes = ast.literal_eval(data.parts[-1].text.strip(\"\\`\"))\n        if gen:\n            gen.update(1)\n        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n\n    def get_event_date(self, event_t: str, exchange_code: str, event: MarketEvent):\n        current_dt_str = datetime.now(GeneratedEvent.tz()).strftime('%c')\n        current_dt = datetime.strptime(current_dt_str, \"%a %b %d %H:%M:%S %Y\")\n        current_t_str = datetime.now(GeneratedEvent.tz()).strftime('%H:%M:%S')\n        current_t = datetime.strptime(current_t_str, \"%H:%M:%S\").time()\n        event_time = parse(event_t).time()\n        gen_datetime = None\n        if event is MarketEvent.LAST_CLOSE:\n            last_close_day = current_dt.date() - timedelta(days=0 if current_t > event_time else 1)\n            # Loop backwards to find the last valid trading day (not a weekend or holiday).\n            while last_close_day.weekday() >= 5 or last_close_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n                last_close_day -= timedelta(days=1)\n            # Combine the date and time.\n            gen_datetime = datetime.combine(last_close_day, event_time)\n        else:\n            next_event_day = current_dt.date() + timedelta(days=0 if current_t < event_time else 1)\n            # Loop forward to find the next valid trading day (not a weekend or holiday).\n            while next_event_day.weekday() >= 5 or next_event_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n                next_event_day += timedelta(days=1)\n            # Combine date and time.\n            gen_datetime = datetime.combine(next_event_day, event_time)\n        # Format the result as requested.\n        return gen_datetime.strftime('%a %b %d %X %Y')\n\n    def generate_event(self, exchange_code: str, event: MarketEvent):\n        if event is MarketEvent.LAST_CLOSE or event is MarketEvent.POST_CLOSE:\n            prompt = f\"\"\"What is the closing time including post_market hours.\"\"\"\n        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n            prompt = f\"\"\"What is the opening time {is_pre} pre_market hours.\"\"\"\n        elif event is MarketEvent.REG_CLOSE:\n            prompt = f\"\"\"What is the closing time excluding post_market hours.\"\"\"\n        prompt = f\"\"\"Answer based on your knowledge of exchange operating hours.\n            Do not answer in full sentences. Omit all chat and provide the answer only.\n            The fields pre_market and post_market both represent extended operating hours.\n\n            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n            \n            Consider the {exchange_code} exchange's operating hours.\n            {prompt}\n            \n            Answer with the time in this format: '%H:%M:%S'.\n            Omit all other chat and details. Do not use sentences.\"\"\"\n        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n        response = self.get_exchanges_csv(prompt).candidates[0].content\n        if api.Const.Stop() in f\"{response.parts[-1].text}\":\n            progress.close()\n            api.generation_fail()\n            time.sleep(api.dt_between)\n            return self.generate_event(exchange_code, event)\n        else:\n            response = self.get_event_date(response.parts[-1].text, exchange_code, event)\n            progress.update(1)\n            return response\n\n    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n        # Check for an existing GeneratedEvent object having updates.\n        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n            event_obj = self.events[exchange_code]\n            event_state = [(event_obj.pre_open, MarketEvent.PRE_OPEN),\n                           (event_obj.reg_open, MarketEvent.REG_OPEN),\n                           (event_obj.reg_close, MarketEvent.REG_CLOSE),\n                           (event_obj.post_close, MarketEvent.POST_CLOSE)]\n            # Need now in same format as generated.\n            datetime_now = parse(datetime.now(event_obj.tz()).strftime('%c'))\n            gen_ts = parse(event_obj.timestamp)\n            # Re-generate events when day changes.\n            if datetime_now.day > gen_ts.day:\n                del self.events[exchange_code]\n                return self.generated_events(exchange_code)\n            # Update changed events on trading days.\n            for e in event_state:\n                if datetime_now > parse(e[0]):\n                    event_dt = self.generate_event(exchange_code, e[1])\n                    match e[1]:\n                        case MarketEvent.PRE_OPEN:\n                            event_obj.pre_open = event_dt\n                        case MarketEvent.REG_OPEN:\n                            event_obj.reg_open = event_dt\n                        case MarketEvent.REG_CLOSE:\n                            event_obj.reg_close = event_dt\n                        case MarketEvent.POST_CLOSE:\n                            event_obj.post_close = event_dt\n            event_obj.timestamp = datetime.now(event_obj.tz()).strftime('%c')\n            self.events[exchange_code] = event_obj\n        # Generate events for an exchange code not in cache.\n        elif exchange_code not in self.events.keys():\n            self.events[exchange_code] = GeneratedEvent(\n                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE),\n                is_holiday=datetime.now().date() in self.holidays[exchange_code])\n        return self.events[exchange_code]\n\n    def set_holiday_event(self, exchange_code: str):\n        self.generated_events(exchange_code).is_holiday = True\n\n    def last_market_close(self, exchange_code: str):\n        return self.generated_events(exchange_code).last_close\n\n    def add_documents_list(self, docs: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n        content=[doc.page_content for doc in docs]\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n\n    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        splitter = RecursiveJsonSplitter(max_chunk_size=Gemini.Const.ChunkMax())\n        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        content = [json.dumps(doc.page_content) for doc in docs]\n        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n\n    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        peers = {\"symbol\": topic, \"peers\": names}\n        tqdm(self.db.add(ids=str(self.db.count()),\n                         documents=[json.dumps(peers)],\n                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n             desc=\"Generate peers embedding\")\n\n    def get_peers_document(self, query: str, topic: str, group: str):\n        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n\n    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n        self.embed_fn.document_mode = True # Switch to document mode\n        if ids is None:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n        if isinstance(chunks[0], BaseModel):\n            docs = [model.model_dump_json() for model in chunks]\n        else:\n            docs = [json.dumps(obj) for obj in chunks]\n        meta_base = {\"source\": source, \"topic\": topic}\n        if meta_opt is not None:\n            for m in meta_opt:\n                m.update(meta_base)\n        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n        if is_update:\n            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n        else:\n            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n\n    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n        self.embed_fn.document_mode = False # Switch to query mode.\n        stored = self.stored_result(self.db.get(where={\n            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n        if len(stored) == 0:\n            return stored, True\n        # Check for a daily market status update.\n        status = json.loads(stored[0].docs)\n        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n        store_day = parse(stored[0].meta['timestamp']).day\n        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n            return stored, False\n        elif gen_day > store_day:\n            return stored, True\n        # Update with generated events to avoid rest api requests.\n        status[\"session\"] = self.generated_events(exchange_code).session().value\n        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n        stored[0].docs = json.dumps(status)\n        return stored, False\n\n    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n        return self.get_documents_list(\n            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=[quote], \n                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n             desc=\"Generate quote embedding\")\n\n    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n                          meta_opt: Optional[list[dict]] = None):\n        where = [{\"source\": source}, {\"topic\": topic}]\n        if meta_opt is None:\n            return self.get_documents_list(query, where={\"$and\": where})\n        else:\n            for meta in meta_opt:\n                for k,v in meta.items():\n                    where.append({k: v})\n            return self.get_documents_list(query, where={\"$and\": where})\n\n    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_grounded_document(self, query: str, topic: str, result):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n        supports = result.candidates[0].grounding_metadata.grounding_supports\n        if supports is not None: # Only add grounded documents which have supports\n            grounded_text = [f\"{s.segment.text}\" for s in supports]\n            source = [f\"{c.web.title}\" for c in chunks]\n            score = [f\"{s.confidence_scores}\" for s in supports]\n            tqdm(self.db.add(ids=str(self.db.count()),\n                             documents=json.dumps(grounded_text),\n                             metadatas=[{\"source\": \", \".join(source),\n                                         \"confidence_score\": \", \".join(score),\n                                         \"topic\": topic,\n                                         \"question\": query}]),\n                 desc=\"Generate grounding embedding\")\n\n    def get_grounding_documents(self, query: str, topic: str):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n            \n    def add_wiki_documents(self, title: str, wiki_chunks: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        result = self.get_wiki_documents(title)\n        if len(result) == 0:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n    \n    def get_wiki_documents(self, title: Optional[str] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        if title is None:\n            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n        else:\n            return self.stored_result(self.db.get(where={\"title\": title}))\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(\n            self.db.query(query_texts=[query], \n                          n_results=max_sources, \n                          where=where), \n            is_query = True)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_exchanges_csv(self, query: str):\n        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_answer(self, query: str, max_sources: int = 10, \n                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n        stored = self.get_documents_list(query, max_sources, where)\n        query_oneline = query.replace(\"\\n\", \" \")\n        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n\n        QUESTION: {query_oneline}\n        \n        \"\"\"\n        # Add the retrieved documents to the prompt.\n        stored_docs = [passage.docs for passage in stored]\n        for passage in stored_docs if passages is None else stored_docs + passages:\n            passage_oneline = passage.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n        # Generate the response.\n        response = api.retriable(\n            self.client.models.generate_content,\n            model=api(Gemini.Model.GEN),\n            config=self.config_temp,\n            contents=prompt)\n        # Check for generated code and store in memory.\n        content = response.candidates[0].content\n        if len(content.parts) > 1 and content.parts[0].executable_code:\n            memory.append_code(prompt, content.parts)\n        return response\n\n    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n        try:\n            results = []\n            if len(result[\"documents\"]) == 0:\n                return results\n            if isinstance(result[\"documents\"][0], list):\n                for i in range(len(result[\"documents\"][0])):\n                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n                                            dist=result[\"distances\"][0][i] if is_query else None,\n                                            meta=result[\"metadatas\"][0][i],\n                                            store_id=result[\"ids\"][0][i])\n                    results.append(obj)\n            else:\n                results.append(\n                    VectorStoreResult(docs=result[\"documents\"][0],\n                                      dist=result[\"distances\"][0] if is_query else None,\n                                      meta=result[\"metadatas\"][0],\n                                      store_id=result[\"ids\"][0]))\n            return results\n        except Exception as e:\n            raise e","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:00.114897Z","iopub.execute_input":"2025-09-06T16:11:00.115143Z","iopub.status.idle":"2025-09-06T16:11:00.850174Z","shell.execute_reply.started":"2025-09-06T16:11:00.115123Z","shell.execute_reply":"2025-09-06T16:11:00.849282Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Wikipedia Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Wiki-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by similarity to topic\n# - retrieve existing groundings by similarity to topic\nclass WikiGroundingGenerator:   \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\") # suppress beta-warning\n            self.splitter = HTMLSemanticPreservingSplitter(\n                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n                max_chunk_size=Gemini.Const.ChunkMax(),\n                chunk_overlap=50,\n                preserve_links=True,\n                preserve_images=True,\n                preserve_videos=True,\n                preserve_audio=True,\n                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n                denylist_tags=[\"script\", \"style\", \"head\"],\n                custom_handlers={\"code\": self.code_handler},\n            )\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_wiki_documents(topic)\n        if len(stored) > 0:\n            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n        else:\n            pages = wikipedia.search(topic + \" company\")\n            if len(pages) > 0:\n                p_topic_match = 0.80\n                for i in range(len(pages)):\n                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n                            desc= \"Score wiki search by similarity to topic\"):\n                        page_html = api.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n                        chunks = [chunk.page_content for chunk in self.splitter.split_text(page_html)]\n                        self.rag.add_wiki_documents(topic, chunks)\n                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n            return StopGeneration().result\n\n    def code_handler(self, element: Tag) -> str:\n        data_lang = element.get(\"data-lang\")\n        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n        return code_format","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:00.851122Z","iopub.execute_input":"2025-09-06T16:11:00.851373Z","iopub.status.idle":"2025-09-06T16:11:00.860836Z","shell.execute_reply.started":"2025-09-06T16:11:00.851352Z","shell.execute_reply":"2025-09-06T16:11:00.859953Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Google Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Search-Grounding Generation.\n# - using gemini-2.0-flash with GoogleSearch tool for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by exact match to topic\n# - retrieve existing groundings by similarity to topic\nclass SearchGroundingGenerator:\n    config_ground = types.GenerateContentConfig(\n        tools=[types.Tool(google_search=types.GoogleSearch())],\n        temperature=0.0\n    )\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_grounding_documents(query, topic)\n        if len(stored) > 0:\n            for i in range(len(stored)):\n                meta_q = stored[i].meta[\"question\"]\n                p_ground_match = 0.95 # This can be really high ~ 95-97%\n                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n                        desc=\"Score similarity to stored grounding\"):\n                    return ast.literal_eval(stored[i].docs)\n        return self.get_grounding(query, topic)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_grounding(self, query: str, topic: str):\n        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n        contents += f\"\"\"\n        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n        If an answer is not possible respond with: I don't know.\"\"\"\n        response = api.retriable(self.client.models.generate_content, \n                                 model=api(Gemini.Model.GEN), \n                                 config=self.config_ground, \n                                 contents=contents)\n        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n            if self.is_consistent(query, topic, response.text):\n                self.rag.add_grounded_document(query, topic, response)\n                return response.text \n        return StopGeneration().result # Empty grounding supports or not consistent in response\n\n    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n        topic = topic.replace(\"'\", \"\")\n        id_strs = topic.split()\n        if len(id_strs) == 1:\n            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n            if len(matches) > 0:\n                topic = matches[0]\n        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n        model_response = model_response.replace(\"'\", \"\")\n        if len(compound_match) == 0 and topic in model_response:\n            return True # not a compound topic id and exact topic match\n        for match in compound_match:\n            if topic not in match:\n                return False\n        return True # all prefix matches contained topic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:11:00.86174Z","iopub.execute_input":"2025-09-06T16:11:00.862404Z","iopub.status.idle":"2025-09-06T16:11:00.888006Z","shell.execute_reply.started":"2025-09-06T16:11:00.862373Z","shell.execute_reply":"2025-09-06T16:11:00.887115Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Rest API Tool and Helpers","metadata":{}},{"cell_type":"code","source":"# Rest api-helpers to manage request-per-minute limits.\n# - define an entry for each endpoint limit\n# - init rest tool with limits to create blocking queues\n# - apply a limit to requests with rest_tool.try_url\nclass ApiLimit(Enum):\n    FINN = \"finnhub.io\",50\n    POLY = \"polygon.io\",4 # (id_url,rpm)\n\nclass BlockingUrlQueue:\n    on_cooldown = False\n    cooldown = None\n    cooldown_start = None\n    \n    def __init__(self, rest_fn: Callable, per_minute: int):\n        self.per_minute_max = per_minute\n        self.quota = per_minute\n        self.rest_fn = rest_fn\n\n    def push(self, rest_url: str):\n        if not self.on_cooldown:\n            self.cooldown = Timer(60, self.reset_quota)\n            self.cooldown.start()\n            self.cooldown_start = time.time()\n            self.on_cooldown = True\n        if self.quota > 0:\n            self.quota -= 1\n            time.sleep(0.034) # ~30 requests per second\n            return self.rest_fn(rest_url)\n        else:\n            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n            time.sleep(max(self.limit_expiry(),0.5))\n            return self.push(rest_url)\n\n    def reset_quota(self):\n        self.quota = self.per_minute_max\n        self.on_cooldown = False\n        self.cooldown_start = None\n\n    def limit_expiry(self):\n        if self.cooldown_start:\n            return max(60-(time.time()-self.cooldown_start),0)\n        return 0","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:00.889114Z","iopub.execute_input":"2025-09-06T16:11:00.889426Z","iopub.status.idle":"2025-09-06T16:11:00.912753Z","shell.execute_reply.started":"2025-09-06T16:11:00.889402Z","shell.execute_reply":"2025-09-06T16:11:00.911666Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# An implementation of Rest-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - reduce long-context by chunked pre-processing\nclass RestGroundingGenerator:    \n    limits = None\n\n    def __init__(self, rag_impl, with_limits: bool):\n        self.rag = rag_impl\n        if with_limits:\n            self.limits = {}\n            for rest_api in ApiLimit:\n                self.limits[rest_api.value[0]] = BlockingUrlQueue(api.get, rest_api.value[1])\n\n    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n        return self.limits[rest_api.value[0]] if self.limits else None\n\n    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n        try:\n            if from_lambda:\n                return schema(results=json.loads(data))\n            return schema.model_validate_json(data)\n        except Exception as e:\n            raise e\n\n    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n        try:\n            candle = json.loads(data)\n            if \"from\" not in candle:\n                raise ValueError(\"not a dailycandle / missing value for date\")\n            agg = self.basemodel(data, Aggregate)\n            return DailyCandle(from_date=candle[\"from\"], \n                               status=agg.status.value, \n                               symbol=agg.symbol, \n                               open=agg.open, \n                               high=agg.high, \n                               low=agg.low, \n                               close=agg.close, \n                               volume=agg.volume, \n                               otc=agg.otc, \n                               preMarket=agg.preMarket, \n                               afterHours=agg.afterHours)\n        except Exception as e:\n            raise e\n\n    @retry.Retry(timeout=600)\n    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n                success_fn: Callable, *args, **kwargs):\n        try:\n            if self.limits is None:\n                data = api.get(url)\n            elif with_limit:\n                data = with_limit.push(url)\n            if schema is DailyCandle:\n                model = self.dailycandle(data)\n            else:\n                model = self.basemodel(data, schema, as_lambda)\n        except Exception as e:\n            try:\n                print(f\"try_url exception: {e}\")\n                if issubclass(schema, RestResultPoly):\n                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n            except Exception as not_a_result:\n                print(not_a_result)\n            return StopGeneration()\n        else:\n            return success_fn(*args, **kwargs, model=model)\n\n    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n        matches = []\n        max_failed_match = model.count if not by_name else 3\n        p_desc_match = 0.92\n        p_symb_match = 0.95\n        if model.count > 0:\n            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n                if max_failed_match > 0:\n                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n                    symb = [with_content[\"q\"].upper(), obj.symbol]\n                    if by_name and api.similarity(desc) > p_desc_match: \n                        matches.append(obj.symbol)\n                    elif not by_name and api.similarity(symb) > p_symb_match:\n                        matches.append(obj.description)\n                        max_failed_match = 0\n                    else:\n                        max_failed_match -= 1\n        if len(matches) > 0:\n            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n            return matches\n        return StopGeneration().result\n\n    def get_quote(self, with_content, model: Quote):\n        quote = model.model_dump_json()\n        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n        return quote\n\n    def parse_financials(self, with_content, model: BasicFinancials):\n        metric = list(model.metric.items())\n        chunks = []\n        # Chunk the metric data.\n        for i in range(0, len(metric), Gemini.Const.MetricBatch()):\n            batch = metric[i:i + Gemini.Const.MetricBatch()]\n            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n        # Chunk the series data.\n        for key in model.series.keys():\n            series = list(model.series[key].items())\n            for s in series:\n                if api.token_count(s) <= Gemini.Const.ChunkMax():\n                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n                else:\n                    k = s[0]\n                    v = s[1]\n                    for i in range(0, len(v), Gemini.Const.SeriesBatch()):\n                        batch = v[i:i + Gemini.Const.SeriesBatch()]\n                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n        return chunks\n\n    def parse_news(self, with_content, model: NewsResultFinn):\n        if model.count > 0:\n            metas = []\n            for digest in model.get():\n                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": digest.source,\n                              \"published_est\": parse(pub_date).timestamp(),\n                              \"news_id\": digest.id,\n                              \"related\": digest.related})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [digest.summary().model_dump_json() for digest in model.get()]\n        return StopGeneration().result\n\n    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = []\n            for news in model.get():\n                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": news.publisher.name,\n                              \"published_utc\": parse(pub_date).timestamp(),\n                              \"news_id\": news.id,\n                              \"related\": json.dumps(news.tickers),\n                              \"keywords\": json.dumps(news.keywords)})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n                                     ids=[news.id for news in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n        elif result:\n            return result.model_dump_json()\n\n    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n                           result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            self.rag.add_rest_chunks(\n                chunks=[model],\n                topic=with_content[\"stocksTicker\"],\n                source=\"daily_candle_2\",\n                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n            return model\n        elif result:\n            return result\n\n    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n                            result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = [{\n                \"timespan\": with_content[\"timespan\"],\n                \"adjusted\": with_content[\"adjusted\"],\n                \"from\": with_content[\"from\"],\n                \"to\": with_content[\"to\"]}]*model.count\n            candles = [candle.model_dump_json() for candle in model.get()]\n            self.rag.add_rest_chunks(\n                chunks=candles,\n                topic=with_content[\"stocksTicker\"],\n                source=\"custom_candle_2\",\n                meta_opt=metas)\n            return candles\n        elif result:\n            return result.model_dump_json()\n\n    def parse_overview(self, with_content, model: OverviewResult):\n        overview = [model.get().model_dump_json()]\n        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n        return overview\n\n    def parse_trends(self, with_content, model: TrendsResult):\n        if model.count > 0:\n            metas = [{\"period\": trend.period} for trend in model.get()]\n            trends = [trend.model_dump_json() for trend in model.get()]\n            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n            return trends\n        return StopGeneration().result\n\n    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n        if model.get().holiday != MarketSession.NA.value:\n            self.rag.set_holiday_event(model.get().exchange)\n        events = self.rag.generated_events(model.get().exchange)\n        model.get().session = events.session()\n        model.get().isOpen = events.is_open()\n        meta = {\"exchange\": model.get().exchange,\n                \"last_close\": events.last_close,\n                \"pre_open\": events.pre_open,\n                \"reg_open\": events.reg_open,\n                \"reg_close\": events.reg_close,\n                \"post_close\": events.post_close,\n                \"timestamp\": events.timestamp }\n        self.rag.add_rest_chunks([model.get()],\n                                 topic=\"market_status\",\n                                 source=\"get_market_status_1\",\n                                 ids=[with_id] if with_id else None,\n                                 meta_opt=[meta])\n        return model.get().model_dump_json()\n\n    def get_symbol(self, content, by_name: bool = True):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=SymbolResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_symbol_matches,\n            with_content=content,\n            by_name=by_name)\n\n    def get_current_price(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=Quote,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_quote,\n            with_content=content)\n\n    def get_market_status(self, content, store_id: Optional[str] = None):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=MarketStatusResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.augment_market_status,\n            with_id=store_id)\n\n    def get_peers(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n            schema=PeersResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=lambda model: model)\n\n    def get_basic_financials(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n            schema=BasicFinancials,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_financials,\n            with_content=content)\n\n    def get_news_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n            schema=NewsResultFinn,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_news,\n            with_content=content)\n\n    def get_news_tagged(self, content):\n        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n        news = []\n        while True:\n            news_list, next_url = self.try_url(\n                next_url,\n                schema=NewsResultPoly,\n                as_lambda=False,\n                with_limit=self.get_limit(ApiLimit.POLY),\n                success_fn=self.parse_news,\n                with_content=content)\n            news += news_list\n            if next_url is None:\n                break\n            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n        return news\n\n    def get_daily_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n            schema=DailyCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_daily_candle,\n            with_content=content)\n\n    def get_custom_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n            schema=CustomCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_custom_candle,\n            with_content=content)\n\n    def get_overview(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n            schema=OverviewResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_overview,\n            with_content=content)\n\n    def get_trends_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=TrendsResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_trends,\n            with_content=content)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:00.913919Z","iopub.execute_input":"2025-09-06T16:11:00.914235Z","iopub.status.idle":"2025-09-06T16:11:00.961346Z","shell.execute_reply.started":"2025-09-06T16:11:00.914207Z","shell.execute_reply":"2025-09-06T16:11:00.960412Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Instantiate the Tools\n\n<span style=\"font-size:18px;\">\nLet's load some test data and see what the RAG can do. The test data is a CSV file containing stock market exchange data. It includes the market id code, name, locale, and operating hours. The import will use CSVLoader from <code>langchain-community</code> to parse the exchange data into Documents that our RAG can ingest.\n</span>","metadata":{}},{"cell_type":"code","source":"# Instantiate tools and load the exchange data from source csv.\n# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n# - Also maps the exchange code to exchange details.\ntry:\n    df = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\")\nexcept FileNotFoundError as e:\n    df = pandas.read_csv(\"exchanges_src.csv\") # local run\ndf = df.drop([\"close_date\"], axis=1).fillna(\"\")\ndf.to_csv(\"exchanges.csv\", index=False)\nexchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n\n# Prepare a RAG tool for use and add the exchange data.\ntool_rag = RetrievalAugmentedGenerator(api.client, \"finance\")\ntool_rag.add_documents_list(exchanges)\n\n# Prepare a the grounding tools for use.\ntool_wiki = WikiGroundingGenerator(api.client, tool_rag)\ntool_ground = SearchGroundingGenerator(api.client, tool_rag)\ntool_rest = RestGroundingGenerator(tool_rag, with_limits=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:11:00.962425Z","iopub.execute_input":"2025-09-06T16:11:00.962895Z","iopub.status.idle":"2025-09-06T16:11:24.952527Z","shell.execute_reply.started":"2025-09-06T16:11:00.962862Z","shell.execute_reply":"2025-09-06T16:11:24.951765Z"}},"outputs":[{"name":"stderr","text":"Generate US->MarketEvent.LAST_CLOSE:   0%|          | 0/1 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.generation_fail.next_model: model is now  gemini-2.5-flash\n","output_type":"stream"},{"name":"stderr","text":"Generate US->MarketEvent.LAST_CLOSE:   0%|          | 0/1 [00:02<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.generation_fail.next_model: model is now  gemini-2.5-pro\n","output_type":"stream"},{"name":"stderr","text":"Generate US->MarketEvent.LAST_CLOSE:   0%|          | 0/1 [00:10<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.generation_fail.next_model: model is now  gemini-2.5-flash-lite\n","output_type":"stream"},{"name":"stderr","text":"Generate US->MarketEvent.LAST_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\nGenerate US->MarketEvent.PRE_OPEN: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\nGenerate US->MarketEvent.REG_OPEN: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\nGenerate US->MarketEvent.REG_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\nGenerate US->MarketEvent.POST_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\nGenerate document embedding: 0it [00:00, ?it/s]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nNow that the data is loaded lets ask our RAG to perform some augmenting. We can ask it to perform all sorts of useful tasks. We'll generate some useful reusable data structures and check to make sure it can answer important questions. The exchanges all have id's which are used to filter the realtime data. So we'll make sure the RAG know how to create this mapping. We'll also check it's awareness of operating hours. After all, Essy, doesn't mindlessly hammer away at api's when no new data is available.\n</span>","metadata":{}},{"cell_type":"code","source":"# The RAG tool is a helpful expert.\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n    exchange code to name. Just the dictionary string in pretty form.\"\"\")\nprint(response.candidates[0].content.parts[-1].text)\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n    comma separated value that I can copy.\"\"\")\nprint(response.candidates[0].content.parts[-1].text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\n    f\"\"\"Answer based on your knowledge of exchange operating hours.\n    Do not answer in full sentences. Omit all chat and provide the answer only.\n    The fields pre_market and post_market both represent extended operating hours.\n\n    The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n\n    Weekdays are: Mon, Tue, Wed, Thu, Fri.\n    On weekdays all exchanges open after pre-market and regular hours.\n    On weekdays all exchanges close after regular and post-market hours.\n    \n    Weekends are: Sat, Sun.\n    Always exclude weekends from exchange operating hours.\n    A list of holidays in date format mm-dd-yyyy: {tool_rag.holidays[\"US\"]}\n    Always exclude holidays from exchange operating hours.\n    When the answer is a holiday use the prior weekday for close.\n    When the answer is a holiday use the next weekday for open.\n    \n    Consider the US exchange's operating hours.\n    Provide the most recent weekday's close including post_market hours.\n    \n    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\nprint(response.candidates[0].content.parts[-1].text)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:24.953396Z","iopub.execute_input":"2025-09-06T16:11:24.954478Z","iopub.status.idle":"2025-09-06T16:11:30.915863Z","shell.execute_reply.started":"2025-09-06T16:11:24.954444Z","shell.execute_reply":"2025-09-06T16:11:30.914724Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n  \"VN\": \"Vietnam\",\n  \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n  \"US\": \"US exchanges (NYSE, Nasdaq)\",\n  \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n  \"QA\": \"QATAR EXCHANGE\",\n  \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n  \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n  \"PR\": \"PRAGUE STOCK EXCHANGE\",\n  \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n  \"CA\": \"Egyptian Stock Exchange\",\n  \"AX\": \"ASX - ALL MARKETS\",\n  \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n  \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n  \"DB\": \"DUBAI FINANCIAL MARKET\",\n  \"PM\": \"Philippine Stock Exchange\",\n  \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n  \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n  \"DU\": \"BOERSE DUESSELDORF\",\n  \"TL\": \"NASDAQ OMX TALLINN\",\n  \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n  \"SW\": \"SWISS EXCHANGE\",\n  \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n  \"SI\": \"SINGAPORE EXCHANGE\",\n  \"RG\": \"NASDAQ OMX RIGA\",\n  \"CR\": \"CARACAS STOCK EXCHANGE\",\n  \"SA\": \"Brazil Bolsa - Sao Paolo\",\n  \"BH\": \"BAHRAIN BOURSE\",\n  \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n  \"L\": \"LONDON STOCK EXCHANGE\",\n  \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n  \"IC\": \"NASDAQ OMX ICELAND\",\n  \"KW\": \"Kuwait Stock Exchange\",\n  \"JK\": \"INDONESIA STOCK EXCHANGE\",\n  \"BE\": \"BOERSE BERLIN\",\n  \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n  \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n  \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n  \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n  \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n  \"KL\": \"BURSA MALAYSIA\",\n  \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n  \"VS\": \"NASDAQ OMX VILNIUS\",\n  \"ME\": \"MOSCOW EXCHANGE\",\n  \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n  \"NL\": \"Nigerian Stock Exchange\",\n  \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n  \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n  \"DE\": \"XETRA\",\n  \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n  \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n  \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n  \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n  \"OL\": \"OSLO BORS ASA\",\n  \"BO\": \"BSE LTD\",\n  \"MT\": \"MALTA STOCK EXCHANGE\",\n  \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n  \"F\": \"DEUTSCHE BOERSE AG\",\n  \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n  \"MU\": \"BOERSE MUENCHEN\",\n  \"IS\": \"BORSA ISTANBUL\",\n  \"SR\": \"SAUDI STOCK EXCHANGE\",\n  \"NE\": \"AEQUITAS NEO EXCHANGE\",\n  \"MI\": \"Italian Stock Exchange\",\n  \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n  \"MC\": \"BOLSA DE MADRID\",\n  \"HA\": \"Hanover Stock Exchange\",\n  \"VI\": \"Vienna Stock Exchange\",\n  \"TWO\": \"TPEx\",\n  \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n  \"TW\": \"TAIWAN STOCK EXCHANGE\",\n  \"TO\": \"TORONTO STOCK EXCHANGE\",\n  \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n  \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n  \"SG\": \"BOERSE STUTTGART\",\n  \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n  \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n  \"BK\": \"STOCK EXCHANGE OF THAILAND\"\n}\n```\nDE, F, TG, SX, BE, DU, HA, HM, MU, SC, SG \n\nThe Germany exchanges and their corresponding codes are: XETRA (DE), DEUTSCHE BOERSE AG (F), Hanover Stock Exchange (HA), DEUTSCHE BOERSE TradeGate (TG), BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), BOERSE_FRANKFURT_ZERTIFIKATE (SC), and BOERSE STUTTGART (SG). \n\nI don't know. \n\nI don't know. \n\nUS exchanges operate from 09:30 to 16:00. \n\nFri Sep 05 16:00:00 2025\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nExcellent! Though, despite my best effort I could not convince Gemini to apply date correction (during chaining) based on holiday. It simply wasn't stable enough to be useful. I would either have to add a holiday data set, or (what I chose) apply a quick temporary fix. A real-time API endpoint may fail due to a holiday being selected as the date. If that happens I'll just retry Thursday if the failure happened on Friday, likewise choosing Friday if the failure happened on Monday. Crude but simple for foundational purposes.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Declaring the Function Calling Metadata\n\n<span style=\"font-size:18px;\">\nOur Function Calling expert will chain together the other experts we've implemented thus far. It also provides the final response through augmentation. This time using the tools as a source of grounding truth. It'd like to say it's all truth organised by topic and other metadata. It's still a precarious situation if Essy incidently chains into mining data on another topic. We want Amazon to be the owner of MGM Studio's not MGM Resorts International. We also don't want a summary to include another company unless that company is a peer.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe function calling metadata is thus extremely important. It needs to combine our other experts with the real-time api's data. Essy will use two API providers as sources of finance data. The primary motivation being that each provider has limits in their own way, yet both are useful in their own own way. This is useful anywhere you need a broad spectrum of sources of truth. At metadata creation I'll adopt the naming convention of appending the provider (if any) id. This helps keep functions more understandable when you know which provider you're dealing with.\n</span>","metadata":{}},{"cell_type":"code","source":"# Declare callable functions using OpenAPI schema.\ndecl_get_symbol_1 = types.FunctionDeclaration(\n    name=\"get_symbol_1\",\n    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n                   calling get_wiki_tool_response next.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_symbols_1 = types.FunctionDeclaration(\n    name=\"get_symbols_1\",\n    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"exchange\", \"query\"]\n    }\n)\n\ndecl_get_name_1 = types.FunctionDeclaration(\n    name=\"get_name_1\",\n    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"company\": {\n                \"type\": \"string\",\n                \"description\": \"The company you're searching for.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n    }\n)\n\ndecl_get_symbol_quote_1 = types.FunctionDeclaration(\n    name=\"get_symbol_quote_1\",\n    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n                   provided in json format. Each response contains the following key-value pairs:\n                   \n                   c: Current price,\n                   d: Change,\n                  dp: Percent change,\n                   h: High price of the day,\n                   l: Low price of the day,\n                   o: Open price of the day,\n                  pc: Previous close price,\n                   t: Epoch timestamp of price in seconds.\n\n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\", \"exchange\"]\n    }\n)\n\ndecl_get_local_datetime = types.FunctionDeclaration(\n    name=\"get_local_datetime\",\n    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n                   function to format date and time in your responses.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"t\": {\n                \"type\": \"array\",\n                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n                                  timestamps matches the order of conversion.\"\"\",\n                \"items\": {\n                    \"type\": \"integer\"\n                }\n            }\n        },\n        \"required\": [\"t\"]\n    }\n)\n\ndecl_get_market_status_1 = types.FunctionDeclaration(\n    name=\"get_market_status_1\",\n    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n                   Also includes holiday details if applicable. The response is provided in json format. Each response \n                   contains the following key-value pairs:\n\n                   exchange: Exchange code,\n                   timezone: Timezone of the exchange,\n                    holiday: Holiday event name, or null if it's not a holiday,\n                     isOpen: Whether the market is open at the moment,\n                          t: Epoch timestamp of status in seconds (Eastern Time),\n                    session: The market session can be 1 of the following values: \n                    \n                    pre-market,regular,post-market when open, or null if closed.\n                    \n                    Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_market_session_1 = types.FunctionDeclaration(\n    name=\"get_market_session_1\",\n    description=\"Get the current market session of global exchanges.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_company_peers_1 = types.FunctionDeclaration(\n    name=\"get_company_peers_1\",\n    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n                   \n                   symbol: The company's stock ticker symbol, \n                   peers: A list containing the peers.\n                   \n                   Each peers entry contains the following key-value pairs:\n                   \n                   symbol: The peer company's stock ticker symbol, \n                   name: The peer company's name.\n                   \n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n            },\n            \"grouping\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n                                  Always use subIndustry unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_exchange_codes_1 = types.FunctionDeclaration(\n    name=\"get_exchange_codes_1\",\n    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n)\n\ndecl_get_exchange_code_1 = types.FunctionDeclaration(\n    name=\"get_exchange_code_1\",\n    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n                   more exchange codes provided as a comma-separated string value.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"Specifies which exchange code to search for.\"\n            }\n        },\n        \"required\": [\"q\"]\n    }\n)\n\ndecl_get_financials_1 = types.FunctionDeclaration(\n    name=\"get_financials_1\",\n    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"metric\": {\n                \"type\": \"string\",\n                \"description\": \"It must always be declared as the value 'all'\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"metric\", \"query\"]\n    }\n)\n\ndecl_get_daily_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_daily_candlestick_2\",\n    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n                   volume and pre-market/after-hours trade prices. It provides the last trading days' data after \n                   11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"date\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n    },\n)\n\ndecl_get_company_news_1 = types.FunctionDeclaration(\n    name=\"get_company_news_1\",\n    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\",\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n                                  default value is today's date.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n    },\n)\n\ndecl_get_custom_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_custom_candlestick_2\",\n    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n                   includes historical daily trade volume and pre-market/after-hours trade prices. It includes \n                   the last trading days' data after 11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"multiplier\": {\n                \"type\": \"integer\",\n                \"description\": \"This must be included and equal to 1 unless told otherwise.\"\n            },\n            \"timespan\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n                                  default is one weekday before get_last_market_close.\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This must be included. May be one of asc or desc. asc will sort by timestmap in \n                                  ascending order. desc will sort by timestamp in descending order.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n                                  unless told to limit base aggregates to something else.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n    },\n)\n\ndecl_get_last_market_close = types.FunctionDeclaration(\n    name=\"get_last_market_close\",\n    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_ticker_overview_2 = types.FunctionDeclaration(\n    name=\"get_ticker_overview_2\",\n    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a company’s \n    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n    the form of icons and logos.\n    \"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol of a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"query\"]\n    }\n)\n\ndecl_get_recommendation_trends_1 = types.FunctionDeclaration(\n    name=\"get_recommendation_trends_1\",\n    description=\"\"\"Get the latest analyst recommendation trends for a company.\n                The data includes the latest recommendations as well as historical\n                recommendation data for each month. The data is classified according\n                to these categories: strongBuy, buy, hold, sell, and strongSell.\n                The date of a recommendation indicated by the value of 'period'.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\"]\n    }\n)\n\ndecl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n    name=\"get_news_with_sentiment_2\",\n    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n                   comprehensive coverage. Including a summary, publisher information, article metadata, \n                   and sentiment analysis.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"published_utc.gte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n                                  The default value is one-month ago from today's date.\"\"\"\n            },\n            \"published_utc.lte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"order\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n                                  When order is not specified the default is descending order.\n                                  Ordering will be based on the parameter 'sort'.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"This must be included and equal to 1000 unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The sort field used for ordering. This value must\n                                  always be published_utc.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"limit\", \"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"sort\", \"query\"]\n    }\n)\n\ndecl_get_rag_tool_response = types.FunctionDeclaration(\n    name=\"get_rag_tool_response\",\n    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"question\": {\n                \"type\": \"string\",\n                \"description\": \"A question needing an answer. Asked as a simple string.\"\n            }\n        }\n    }\n)\n\ndecl_get_wiki_tool_response = types.FunctionDeclaration(\n    name=\"get_wiki_tool_response\",\n    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n                   product, or service. Each web page includes detailed company information, financial indicators, \n                   tickers, symbols, history, and products and services.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. Just the name and no other details.\"\n            },\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The complete, unaltered, query string.\"\n            }\n        },\n        \"required\": [\"id\", \"q\"]\n    }\n)\n\ndecl_get_search_tool_response = types.FunctionDeclaration(\n    name=\"get_search_tool_response\",\n    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The question needing an answer. Asked as a simple string.\"\n            },\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n            }\n        },\n        \"required\": [\"q\", \"id\"]\n    }\n)","metadata":{"trusted":true,"_kg_hide-input":false,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:30.917187Z","iopub.execute_input":"2025-09-06T16:11:30.917511Z","iopub.status.idle":"2025-09-06T16:11:30.952469Z","shell.execute_reply.started":"2025-09-06T16:11:30.917482Z","shell.execute_reply":"2025-09-06T16:11:30.9515Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"# Implementing the Function Calling Expert\n\n<span style=\"font-size:18px;\">\nOne downside of this part being the main part was the lack of time to refactor this part more. Our formative Essy implements as much useful data from two finacial APIs. In order to use it you will need to declare secrets for <a class=\"anchor-link\" href=\"https://finnhub.io/dashboard\">Finnhub</a> and <a class=\"anchor-link\" href=\"https://polygon.io/dashboard\">Polygon</a> finance APIs. Register at their respective sites for your free API key. Then import the secret using the same method as how you setup Google's API key.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## Callable Functions and Handler","metadata":{}},{"cell_type":"code","source":"# Implement the callable functions and the function handler.\n\ndef ask_rag_tool(content):\n    return tool_rag.generate_answer(content[\"question\"]).text\n\ndef ask_wiki_tool(content):\n    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n\ndef ask_search_tool(content):\n    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n\ndef get_exchange_codes_1(content):\n    return tool_rag.get_exchange_codes()\n\ndef get_exchange_code_1(content):\n    return tool_rag.get_exchange_codes(with_query=content)\n    \ndef last_market_close(content):\n    return tool_rag.last_market_close(content[\"exchange\"])\n    \ndef get_symbol_1(content, by_name: bool = True):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n    if len(stored) == 0:\n        return tool_rest.get_symbol(content, by_name)\n    return json.loads(stored[0].docs)\n\ndef get_symbols_1(content):\n    return None # todo\n\ndef get_name_1(content):\n    return get_symbol_1(content, by_name = False)\n\ndef get_quote_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n        return get_current_price_1(content)\n    elif len(stored) > 0:\n        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n        for quote in stored:\n            if quote.meta[\"timestamp\"] >= last_close:\n                return [quote.docs for quote in stored]\n    return get_current_price_1(content)\n\ndef get_current_price_1(content):\n    return tool_rest.get_current_price(content)\n\ndef get_market_status_1(content):\n    stored, has_update = tool_rag.get_market_status(content['exchange'])\n    if has_update:\n        with_id = stored[0].store_id if len(stored) > 0 else None\n        return tool_rest.get_market_status(content, with_id)\n    return stored[0].docs\n\ndef get_session_1(content):\n    return json.loads(get_market_status_1(content))[\"session\"]\n\ndef get_peers_1(content):\n    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n    if len(stored) == 0:\n        peers = tool_rest.get_peers(content)\n        if peers.count > 0:\n            names = []\n            for peer in peers.get():\n                if peer == content[\"symbol\"]:\n                    continue # skip including the query symbol in peers\n                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n                if name != StopGeneration().result:\n                    data = {\"symbol\": peer, \"name\": name}\n                    names.append(data)\n            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n            return names\n        return StopGeneration().result\n    return json.loads(stored[0].docs)[\"peers\"]\n\ndef local_datetime(content):\n    local_t = []\n    for timestamp in content[\"t\"]:\n        local_t.append(local_date_from_epoch(timestamp))\n    return local_t\n\ndef local_date_from_epoch(timestamp):\n    if len(str(timestamp)) == 13:\n        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n    else:\n        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n\ndef get_financials_1(content):\n    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n    if len(stored) == 0:\n        return tool_rest.get_basic_financials(content)\n    return [chunk.docs for chunk in stored]\n\ndef get_news_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n    if len(stored) == 0:\n        return tool_rest.get_news_simple(content)\n    return [NewsTypeFinn.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n\ndef get_daily_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n    if len(stored) == 0:\n        candle = tool_rest.get_daily_candle(content)\n        # Attempt to recover from choosing a holiday.\n        candle_date = parse(content[\"date\"])\n        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n            else:\n                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n            return get_daily_candle_2(content)\n        return candle.model_dump_json()\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_custom_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n        meta_opt=[{\n            \"timespan\": content[\"timespan\"],\n            \"adjusted\": content[\"adjusted\"],\n            \"from\": content[\"from\"],\n            \"to\": content[\"to\"]}])\n    if len(stored) == 0:\n        return tool_rest.get_custom_candle(content)\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_overview_2(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n    if len(stored) == 0:\n        return tool_rest.get_overview(content)\n    return json.loads(stored[0].docs)\n\ndef get_trends_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n    if len(stored) == 0:\n        return tool_rest.get_trends_simple(content)\n    return [json.loads(trend.docs) for trend in stored]\n\ndef get_news_2(content):\n    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n    news_from = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n    news_to = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n    if len(news_from) > 0 and len(news_to) > 0:\n        stored = tool_rag.get_api_documents(\n            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n            [{\"published_utc\": {\"$gte\": timestamp_from}},\n             {\"published_utc\": {\"$lte\": timestamp_to}}])\n        return [NewsTypePoly.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n    return tool_rest.get_news_tagged(content)\n        \nfinance_tool = types.Tool(\n    function_declarations=[\n        decl_get_symbol_1,\n        decl_get_symbols_1,\n        decl_get_name_1,\n        decl_get_symbol_quote_1,\n        decl_get_market_status_1,\n        decl_get_market_session_1,\n        decl_get_company_peers_1,\n        decl_get_local_datetime,\n        decl_get_last_market_close,\n        decl_get_exchange_codes_1,\n        decl_get_exchange_code_1,\n        decl_get_financials_1,\n        decl_get_daily_candlestick_2,\n        decl_get_custom_candlestick_2,\n        decl_get_ticker_overview_2,\n        decl_get_recommendation_trends_1,\n        decl_get_news_with_sentiment_2,\n        decl_get_rag_tool_response,\n        decl_get_wiki_tool_response,\n        decl_get_search_tool_response\n    ]\n)\n\nfunction_handler = {\n    \"get_symbol_1\": get_symbol_1,\n    \"get_symbols_1\": get_symbols_1,\n    \"get_name_1\": get_name_1,\n    \"get_symbol_quote_1\": get_quote_1,\n    \"get_market_status_1\": get_market_status_1,\n    \"get_market_session_1\": get_session_1,\n    \"get_company_peers_1\": get_peers_1,\n    \"get_local_datetime\": local_datetime,\n    \"get_last_market_close\": last_market_close,\n    \"get_exchange_codes_1\": get_exchange_codes_1,\n    \"get_exchange_code_1\": get_exchange_code_1,\n    \"get_financials_1\": get_financials_1,\n    \"get_daily_candlestick_2\": get_daily_candle_2,\n    \"get_custom_candlestick_2\": get_custom_candle_2,\n    \"get_ticker_overview_2\": get_overview_2,\n    \"get_recommendation_trends_1\": get_trends_1,\n    \"get_news_with_sentiment_2\": get_news_2,\n    \"get_rag_tool_response\": ask_rag_tool,\n    \"get_wiki_tool_response\": ask_wiki_tool,\n    \"get_search_tool_response\": ask_search_tool\n}","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:30.953744Z","iopub.execute_input":"2025-09-06T16:11:30.954078Z","iopub.status.idle":"2025-09-06T16:11:30.987458Z","shell.execute_reply.started":"2025-09-06T16:11:30.954046Z","shell.execute_reply":"2025-09-06T16:11:30.986382Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Define the System Prompt","metadata":{}},{"cell_type":"code","source":"# Define the system prompt.\n\ninstruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \nOnly answer the question asked and do not change topic. While the answer is still\nunknown you must follow these rules for predicting function call order:\n\nRULE#1: Always consult your other functions before get_search_tool_response.\nRULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\nRULE#3: Always consult get_search_tool_response last.\nRULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\nRULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:30.988495Z","iopub.execute_input":"2025-09-06T16:11:30.988875Z","iopub.status.idle":"2025-09-06T16:11:31.011248Z","shell.execute_reply.started":"2025-09-06T16:11:30.988851Z","shell.execute_reply":"2025-09-06T16:11:31.010194Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## Import the Rest API Keys","metadata":{}},{"cell_type":"code","source":"# Import the finance api secret keys.\n\nPOLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\nFINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:31.012385Z","iopub.execute_input":"2025-09-06T16:11:31.012883Z","iopub.status.idle":"2025-09-06T16:11:31.134862Z","shell.execute_reply.started":"2025-09-06T16:11:31.012848Z","shell.execute_reply":"2025-09-06T16:11:31.133916Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## The Function Caller","metadata":{}},{"cell_type":"code","source":"# Implement the function calling expert.\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef send_message(prompt):\n    #display(Markdown(\"#### Prompt\"))\n    #print(prompt, \"\\n\")\n    memory.set_prompt(prompt)\n    # Enable system prompt, function calling and minimum-randomness.\n    config_fncall = types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=[finance_tool],\n        temperature=0.0\n    )\n    # Handle cases with multiple chained function calls.\n    function_calling_in_process = True\n    # Send the initial user prompt and function declarations.\n    response = api.retriable(api.client.models.generate_content,\n                             model=api(Gemini.Model.GEN),\n                             config=config_fncall,\n                             contents=memory.contents)\n    while function_calling_in_process:\n        # A part can be a function call or natural language response.\n        for part in response.candidates[0].content.parts:\n            if function_call := part.function_call:\n                # Extract the function call.\n                fn_name = function_call.name\n                #display(Markdown(\"#### Predicted function name\"))\n                #print(fn_name, \"\\n\")\n                # Extract the function call arguments.\n                fn_args = {key: value for key, value in function_call.args.items()}\n                #display(Markdown(\"#### Predicted function arguments\"))\n                #print(fn_args, \"\\n\")\n                # Call the predicted function.\n                try:\n                    api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n                except KeyError as e: # Gemini sometimes omits required fn_args\n                    api.generation_fail()\n                    time.sleep(api.dt_between)\n                    send_message(prompt)\n                #display(Markdown(\"#### API response\"))\n                #print(api_response[:500], \"...\", \"\\n\")\n                # Create an API response part.\n                api_response_part = types.Part.from_function_response(\n                    name=fn_name,\n                    response={\"content\": api_response},\n                )\n                memory.update_contents(function_call, api_response_part)\n                # Send the updated prompt.\n                response = api.retriable(api.client.models.generate_content,\n                                         model=api(Gemini.Model.GEN),\n                                         config=config_fncall,\n                                         contents=memory.contents)\n            else:\n                # Response may be a summary or reasoning step.\n                if len(response.candidates[0].content.parts) == 1:\n                    function_calling_in_process = False\n                    memory.set_summary(response.text.replace(\"$\", \"\\\\$\"))\n                    break # No more parts in response.\n                else:\n                    #display(Markdown(\"#### Natural language reasoning step\"))\n                    #print(response)\n                    memory.set_reason(response.candidates[0].content.parts[0].text)\n                    continue # Next part contains a function call.\n        if not function_calling_in_process:\n            break # The function calling chain is complete.\n            \n    # Show the final natural language summary.\n    display(Markdown(\"#### Natural language response\"))\n    display(Markdown(memory.summary))","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-09-06T16:11:31.13584Z","iopub.execute_input":"2025-09-06T16:11:31.136145Z","iopub.status.idle":"2025-09-06T16:11:31.147415Z","shell.execute_reply.started":"2025-09-06T16:11:31.136114Z","shell.execute_reply":"2025-09-06T16:11:31.14629Z"}},"outputs":[{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Ask a question\n\n<span style=\"font-size:18px;\">\n    If you're on free-tier of Gemini you probably want to Run-before here. Your usage tier can be configured in the api-helper at the top of the notebook.\n</span>","metadata":{}},{"cell_type":"code","source":"send_message(\"What is the current session for US exchanges?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:12:11.582857Z","iopub.execute_input":"2025-09-06T16:12:11.583224Z","iopub.status.idle":"2025-09-06T16:12:13.3838Z","shell.execute_reply.started":"2025-09-06T16:12:11.583198Z","shell.execute_reply":"2025-09-06T16:12:13.383112Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current session for US exchanges is closed.\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"send_message(\"What is the US market status?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:12:50.538472Z","iopub.execute_input":"2025-09-06T16:12:50.538815Z","iopub.status.idle":"2025-09-06T16:12:51.872624Z","shell.execute_reply.started":"2025-09-06T16:12:50.53879Z","shell.execute_reply":"2025-09-06T16:12:51.871401Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The US market is currently closed. The last status update was on Sat, 06 Sep 2025 12:12:10 EDT.\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"send_message(\"When was the last US market close?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:12:55.895345Z","iopub.execute_input":"2025-09-06T16:12:55.895728Z","iopub.status.idle":"2025-09-06T16:12:56.895458Z","shell.execute_reply.started":"2025-09-06T16:12:55.895701Z","shell.execute_reply":"2025-09-06T16:12:56.894482Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The last US market close was Fri Sep 05 20:00:00 2025.\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"send_message(\"What is Apple's stock ticker?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:13:00.540271Z","iopub.execute_input":"2025-09-06T16:13:00.540619Z","iopub.status.idle":"2025-09-06T16:13:03.144937Z","shell.execute_reply.started":"2025-09-06T16:13:00.540585Z","shell.execute_reply":"2025-09-06T16:13:03.143987Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 10/10 [00:00<00:00, 11.19it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple's stock ticker is AAPL.\n"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"send_message(\"What is the current price of Amazon stock? Display the result as a json object.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:13:07.409087Z","iopub.execute_input":"2025-09-06T16:13:07.409409Z","iopub.status.idle":"2025-09-06T16:13:11.083331Z","shell.execute_reply.started":"2025-09-06T16:13:07.409384Z","shell.execute_reply":"2025-09-06T16:13:11.082646Z"}},"outputs":[{"name":"stderr","text":"Generate quote embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is the current price of Amazon stock:\n```json\n{\n\"c\": 232.33,\n\"d\": -3.35,\n\"dp\": -1.4214,\n\"h\": 236.0,\n\"l\": 231.93,\n\"o\": 235.19,\n\"pc\": 235.68,\n\"t\": 1757102400\n}\n```\nThe current price is \\$232.33 as of Fri Sep  5 16:00:00 2025. The price changed by -3.35, which is -1.4214 percent. The high price of the day is \\$236.0, and the low price of the day is \\$231.93. The open price of the day is \\$235.19, and the previous close price is \\$235.68.\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"send_message(\"\"\"Show me Apple's basic financials and help me understand key performance metrics. \n                How has the stock performed?\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:13:17.54148Z","iopub.execute_input":"2025-09-06T16:13:17.54181Z","iopub.status.idle":"2025-09-06T16:13:33.468747Z","shell.execute_reply.started":"2025-09-06T16:13:17.541787Z","shell.execute_reply":"2025-09-06T16:13:33.467856Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's an overview of Apple's financial performance based on the data:\n\n**Financial Health & Performance:**\n*   **Revenue Growth:** Apple has demonstrated consistent revenue growth over the past 3 and 5 years, with quarterly and TTM (trailing twelve months) growth indicating continued positive momentum.\n*   **Profitability:** Apple maintains strong profitability margins, including gross margin, operating margin, and net profit margin.\n*   **Asset Turnover:** The asset turnover ratio indicates how efficiently Apple is using its assets to generate revenue.\n*   **Return on Equity (ROE):** Apple exhibits a high ROE, suggesting efficient use of equity financing.\n*   **Debt Management:** Apple's debt-to-equity ratio and debt-to-total asset ratio provide insights into the company's financial leverage.\n*   **Earnings Per Share (EPS):** Apple's EPS has generally increased over the years.\n\n**Stock Performance Indicators:**\n*   **52 Week Performance:** The 52-week price return daily is 8.5307. The 52-week high is 260.1, and the 52-week low is 169.2101.\n*   **Price-to-Earnings Ratio (P/E):** The P/E ratio is a valuation metric that compares Apple's stock price to its earnings per share.\n*   **Price-to-Book Ratio (P/B):** The P/B ratio compares Apple's market capitalization to its book value.\n*   **Price-to-Sales Ratio (P/S):** The P/S ratio compares Apple's market capitalization to its revenue.\n*   **Beta:** Beta is a measure of Apple's stock price volatility relative to the overall market.\n\n**Additional Key Metrics:**\n*   **Dividend Yield:** The current dividend yield TTM is 0.456.\n*   **Cash Flow:** Apple's cash flow per share and free cash flow metrics provide insights into the company's ability to generate cash.\n*   **Liquidity Ratios:** Apple's current ratio and quick ratio indicate its ability to meet short-term obligations.\n"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"send_message(\"I need Apple's daily candlestick from 2025-05-05\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:13:57.921744Z","iopub.execute_input":"2025-09-06T16:13:57.922057Z","iopub.status.idle":"2025-09-06T16:14:00.475119Z","shell.execute_reply.started":"2025-09-06T16:13:57.922031Z","shell.execute_reply":"2025-09-06T16:14:00.474136Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"OK. On 2025-05-05, Apple's stock (AAPL) had the following daily candlestick data:\n- Open: 203.1\n- High: 204.1\n- Low: 198.21\n- Close: 198.89\n- Volume: 69018452\n- Pre-Market: 205.0\n- After Hours: 198.6\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"send_message(\"Tell me who are Apple's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:24:46.483179Z","iopub.execute_input":"2025-09-06T16:24:46.483473Z","iopub.status.idle":"2025-09-06T16:24:48.259299Z","shell.execute_reply.started":"2025-09-06T16:24:46.48345Z","shell.execute_reply":"2025-09-06T16:24:48.258618Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple's peers include: DELL TECHNOLOGIES -C (DELL), WESTERN DIGITAL CORP (WDC), HEWLETT PACKARD ENTERPRISE (HPE), HP INC (HPQ), PURE STORAGE INC - CLASS A (PSTG), SUPER MICRO COMPUTER INC (SMCI), NETAPP INC (NTAP), IONQ INC (IONQ), SANDISK CORP (SNDK), QUANTUM COMPUTING INC (QUBT), and DIEBOLD NIXDORF INC (DBD).\n"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"send_message(\"Tell me who are Amazon's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:24:51.865411Z","iopub.execute_input":"2025-09-06T16:24:51.865822Z","iopub.status.idle":"2025-09-06T16:24:53.614043Z","shell.execute_reply.started":"2025-09-06T16:24:51.865798Z","shell.execute_reply":"2025-09-06T16:24:53.613273Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon's peers include COUPANG INC (CPNG), EBAY INC (EBAY), DILLARDS INC-CL A (DDS), OLLIE'S BARGAIN OUTLET HOLDI (OLLI), ETSY INC (ETSY), MACY'S INC (M), SAVERS VALUE VILLAGE INC (SVV), KOHLS CORP (KSS), GROUPON INC (GRPN), and CONTEXTLOGIC HOLDINGS INC (LOGC).\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"send_message(\n    \"\"\"Locate Apple's stock ticker, then download recommendation trends of all Apple's peers by sub-industry, \n    and then finally compare them.\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:27:41.332646Z","iopub.execute_input":"2025-09-06T16:27:41.332965Z","iopub.status.idle":"2025-09-06T16:28:55.932281Z","shell.execute_reply.started":"2025-09-06T16:27:41.332937Z","shell.execute_reply":"2025-09-06T16:28:55.9316Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Of Apple's peers, DELL, WDC, and PSTG have the best analyst ratings, while SMCI and HPQ have the worst.\n\n| Ticker | Strong Buy | Buy | Hold | Sell | Strong Sell |\n|---|---|---|---|---|---|\n| DELL | 7 | 17 | 6 | 0 | 0 |\n| WDC | 6 | 19 | 6 | 0 | 0 |\n| HPE | 6 | 8 | 10 | 0 | 0 |\n| HPQ | 2 | 4 | 14 | 1 | 0 |\n| PSTG | 6 | 12 | 8 | 1 | 0 |\n| SMCI | 2 | 10 | 10 | 3 | 0 |\n| NTAP | 3 | 9 | 15 | 0 | 0 |\n| IONQ | 2 | 9 | 3 | 0 | 0 |\n| SNDK | 6 | 10 | 8 | 0 | 0 |\n| QUBT | 2 | 4 | 2 | 0 | 0 |\n| DBD | 2 | 4 | 1 | 0 | 0 |\n\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"send_message(\n    \"\"\"Tell me Amazon's current share price and provide candlestick data for the past month.\n    Sort the data in descending order by date. Format the prices consistently as currency.\n    Round prices to two decimal places.\n    Present the data with multiple columns for display in markdown.\n    Discuss and provide details about any patterns you notice in the price data.\n    Correlate recent patterns with news over the same date range.\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:30:56.172293Z","iopub.execute_input":"2025-09-06T16:30:56.172642Z","iopub.status.idle":"2025-09-06T16:32:04.778332Z","shell.execute_reply.started":"2025-09-06T16:30:56.172618Z","shell.execute_reply":"2025-09-06T16:32:04.777395Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon's current share price is \\$232.33.\n\n### Candlestick Data for the Past Month (Sorted in Descending Order)\n\n| Date | Open | High | Low | Close |\n|---|---|---|---|---|\n| 2025-09-05 | \\$235.19 | \\$236.00 | \\$231.93 | \\$232.33 |\n| 2025-09-04 | \\$231.19 | \\$235.77 | \\$230.78 | \\$235.68 |\n| 2025-09-03 | \\$225.21 | \\$227.17 | \\$224.36 | \\$225.99 |\n| 2025-09-02 | \\$223.52 | \\$226.17 | \\$221.83 | \\$225.34 |\n| 2025-08-29 | \\$231.32 | \\$231.81 | \\$228.16 | \\$229.00 |\n| 2025-08-28 | \\$229.01 | \\$232.71 | \\$228.02 | \\$231.60 |\n| 2025-08-27 | \\$228.57 | \\$229.87 | \\$227.81 | \\$229.12 |\n| 2025-08-26 | \\$227.11 | \\$229.00 | \\$226.02 | \\$228.71 |\n| 2025-08-25 | \\$227.35 | \\$229.60 | \\$227.31 | \\$227.94 |\n| 2025-08-22 | \\$222.79 | \\$229.14 | \\$220.82 | \\$228.84 |\n| 2025-08-21 | \\$222.65 | \\$222.78 | \\$220.50 | \\$221.95 |\n| 2025-08-20 | \\$227.12 | \\$227.27 | \\$220.92 | \\$223.81 |\n| 2025-08-19 | \\$230.09 | \\$230.53 | \\$227.12 | \\$228.01 |\n| 2025-08-18 | \\$230.23 | \\$231.91 | \\$228.33 | \\$231.49 |\n| 2025-08-15 | \\$232.58 | \\$234.08 | \\$229.81 | \\$231.03 |\n| 2025-08-14 | \\$227.40 | \\$233.11 | \\$227.02 | \\$230.98 |\n| 2025-08-13 | \\$222.00 | \\$224.92 | \\$222.00 | \\$224.56 |\n| 2025-08-12 | \\$222.23 | \\$223.50 | \\$219.05 | \\$221.47 |\n| 2025-08-11 | \\$221.78 | \\$223.05 | \\$220.40 | \\$221.30 |\n| 2025-08-08 | \\$223.14 | \\$223.80 | \\$221.88 | \\$222.69 |\n| 2025-08-07 | \\$221.00 | \\$226.22 | \\$220.82 | \\$223.13 |\n| 2025-08-06 | \\$214.70 | \\$222.65 | \\$213.74 | \\$222.31 |\n\n### Price Data Patterns and News Correlation\n\nThe candlestick data for the past month shows a general upward trend in Amazon's stock price, with some periods of volatility. The stock started the month at \\$214.70 and ended at \\$232.33, representing a significant gain.\n\nThis upward trend is strongly correlated with a wealth of positive news surrounding the company. The news sentiment for Amazon over the past month has been overwhelmingly positive, with numerous reports highlighting the company's strengths and growth prospects.\n\nSeveral key themes emerge from the news that likely contributed to the stock's positive performance:\n\n*   **Artificial Intelligence (AI) Advancements:** Many news articles focused on Amazon's innovations in AI, including the development of a new \"Quick Suite\" AI-powered workspace software and the company's continued investment in AI infrastructure. This has generated significant investor confidence in Amazon's ability to compete in the rapidly growing AI sector.\n*   **E-commerce Expansion:** News of Amazon expanding its same-day grocery delivery service and forming new partnerships, such as the one with Hertz to sell used cars, has reinforced the company's dominance in the e-commerce space.\n*   **Strong Financial Performance and Analyst Ratings:** Reports of strong earnings, bullish analyst ratings, and price targets suggesting significant upside potential have further fueled investor optimism.\n*   **Cloud Computing Growth:** Despite some concerns about a slowdown in AWS growth, the overall sentiment remains positive, with Amazon's cloud division continuing to be a major profit driver.\n\nIn conclusion, the positive news flow, particularly around Amazon's AI initiatives and e-commerce expansion, has likely been a major catalyst for the stock's upward momentum over the past month. The consistent positive sentiment from analysts and the company's strong financial performance have also played a crucial role in boosting investor confidence."},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"send_message(\"What is Apple's ticker overview\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:32:40.962353Z","iopub.execute_input":"2025-09-06T16:32:40.962691Z","iopub.status.idle":"2025-09-06T16:33:01.852781Z","shell.execute_reply.started":"2025-09-06T16:32:40.962667Z","shell.execute_reply":"2025-09-06T16:33:01.851889Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple Inc. (AAPL) is a publicly traded company listed on the XNAS exchange. It operates in the stocks market and its currency is the USD. The company has a market capitalization of \\$3,557,093,079,100.00.\n\nHere are some key details about Apple Inc.:\n\n*   **CIK:** 0000320193\n*   **Composite FIGI:** BBG000B9XRY4\n*   **Share Class FIGI:** BBG001S5N8V8\n*   **Phone Number:** (408) 996-1010\n*   **Address:** ONE APPLE PARK WAY, CUPERTINO, CA 95014\n*   **Description:** Apple is among the largest companies in the world, with a broad portfolio of hardware and software products targeted at consumers and businesses. Apple's iPhone makes up a majority of the firm sales, and Apple's other products like Mac, iPad, and Watch are designed around the iPhone as the focal point of an expansive software ecosystem. Apple has progressively worked to add new applications, like streaming video, subscription bundles, and augmented reality. The firm designs its own software and semiconductors while working with subcontractors like Foxconn and TSMC to build its products and chips. Slightly less than half of Apple's sales come directly through its flagship stores, with a majority of sales coming indirectly through partnerships and distribution.\n*   **SIC Code:** 3571 (ELECTRONIC COMPUTERS)\n*   **Homepage:** https://www.apple.com\n*   **Total Employees:** 164,000\n*   **List Date:** 1980-12-12\n*   **Branding:**\n    *   Logo URL: https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_logo.svg\n    *   Icon URL: https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_icon.png\n*   **Share Information:**\n    *   Share Class Shares Outstanding: 14,840,390,000\n    *   Weighted Shares Outstanding: 14,840,390,000\n    *   Round Lot: 100"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"send_message(\"Tell me about Amazon's historical and current recommendation trends\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:33:09.165412Z","iopub.execute_input":"2025-09-06T16:33:09.165794Z","iopub.status.idle":"2025-09-06T16:33:33.500633Z","shell.execute_reply.started":"2025-09-06T16:33:09.165765Z","shell.execute_reply":"2025-09-06T16:33:33.499842Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here are the recommendation trends for Amazon (AMZN):\n\nSeptember 2025:\n- Strong Buy: 23\n- Buy: 52\n- Hold: 4\n- Sell: 0\n- Strong Sell: 0\n\nAugust 2025:\n- Strong Buy: 24\n- Buy: 51\n- Hold: 4\n- Sell: 0\n- Strong Sell: 0\n\nJuly 2025:\n- Strong Buy: 24\n- Buy: 50\n- Hold: 5\n- Sell: 0\n- Strong Sell: 0\n\nJune 2025:\n- Strong Buy: 24\n- Buy: 50\n- Hold: 5\n- Sell: 0\n- Strong Sell: 0"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"send_message(\"What is Google's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:33:38.188007Z","iopub.execute_input":"2025-09-06T16:33:38.188286Z","iopub.status.idle":"2025-09-06T16:34:03.311263Z","shell.execute_reply.started":"2025-09-06T16:33:38.188267Z","shell.execute_reply":"2025-09-06T16:34:03.310495Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbols for Google are GOOGL and GOOG, and they are listed on the NASDAQ stock exchange. These symbols now refer to Alphabet Inc., which is Google's holding company. The company is also listed on the Frankfurt Stock Exchange under the ticker symbol GGQ1."},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"send_message(\"What is MGM Studio's stock symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:34:11.613401Z","iopub.execute_input":"2025-09-06T16:34:11.614214Z","iopub.status.idle":"2025-09-06T16:35:07.117293Z","shell.execute_reply.started":"2025-09-06T16:34:11.614182Z","shell.execute_reply":"2025-09-06T16:35:07.116412Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am sorry, but I cannot find a stock symbol for MGM Studios. It is possible that it is not a publicly traded company."},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"send_message(\"What is MGM Studio's owner company stock symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:35:15.468593Z","iopub.execute_input":"2025-09-06T16:35:15.46896Z","iopub.status.idle":"2025-09-06T16:35:52.968331Z","shell.execute_reply.started":"2025-09-06T16:35:15.468934Z","shell.execute_reply":"2025-09-06T16:35:52.967152Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"name":"stderr","text":"Generate grounding embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"MGM Studio is owned by Amazon, and its stock symbol is AMZN."},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"send_message(\"What is Facebook's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:35:59.982202Z","iopub.execute_input":"2025-09-06T16:35:59.982502Z","iopub.status.idle":"2025-09-06T16:36:28.134194Z","shell.execute_reply.started":"2025-09-06T16:35:59.982481Z","shell.execute_reply":"2025-09-06T16:36:28.133281Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbol for Facebook is META."},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"send_message('''Compare Amazon's bullish versus bearish predictions from July 01 2025 until today.\n                Include a discussion of recommendation trends, and sentiment analysis of news from the same dates.\n                Discuss any patterns or correlations you find.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:36:34.122927Z","iopub.execute_input":"2025-09-06T16:36:34.123218Z","iopub.status.idle":"2025-09-06T16:37:34.968349Z","shell.execute_reply.started":"2025-09-06T16:36:34.123194Z","shell.execute_reply":"2025-09-06T16:37:34.967276Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is a comparison of Amazon's bullish versus bearish predictions from July 01, 2025, to September 06, 2025, including a discussion of recommendation trends and sentiment analysis of news from the same period.\n\n### Recommendation Trends\n\nAnalyst recommendations for Amazon (AMZN) from July to September 2025 show a consistently strong bullish sentiment. The number of \"strong buy\" and \"buy\" recommendations remained overwhelmingly positive, with very few \"hold\" recommendations and no \"sell\" or \"strong sell\" ratings.\n\n| Period | Strong Buy | Buy | Hold | Sell | Strong Sell |\n|---|---|---|---|---|---|\n| **2025-07-01** | 24 | 50 | 5 | 0 | 0 |\n| **2025-08-01** | 24 | 51 | 4 | 0 | 0 |\n| **2025-09-01** | 23 | 52 | 4 | 0 | 0 |\n\nThis data indicates a stable and overwhelmingly positive outlook from analysts, with a slight increase in \"buy\" recommendations and a slight decrease in \"strong buy\" and \"hold\" recommendations over the three-month period. This suggests that while the overall sentiment remains bullish, there might be a minor shift in the intensity of that sentiment.\n\n### Sentiment Analysis of News\n\nThe sentiment from news articles about Amazon during this period was also predominantly positive, reinforcing the bullish analyst recommendations. Here is a summary of the key themes and sentiments found in the news:\n\n**Bullish Sentiment:**\n\n*   **Strong Financial Performance:** Many articles highlighted Amazon's strong financial performance, including revenue growth, profitability, and the success of its various business segments like AWS, advertising, and e-commerce.\n*   **AI and Cloud Dominance:** A significant number of articles focused on Amazon's leadership in cloud computing with AWS and its heavy investments in Artificial Intelligence. The potential for AI to drive future growth was a recurring theme.\n*   **Market Leadership and Expansion:** News frequently mentioned Amazon's dominant market position and its continuous expansion into new areas like grocery delivery, robotics, and healthcare.\n*   **Positive Analyst Outlook:** Several articles reported on the bullish price targets and \"buy\" ratings from Wall Street analysts, further reinforcing the positive sentiment.\n\n**Bearish/Neutral Sentiment:**\n\n*   **Slower AWS Growth:** Some articles pointed to a slowdown in the growth rate of AWS, especially when compared to competitors like Microsoft Azure. This was a recurring theme in more neutral or slightly bearish articles.\n*   **Valuation Concerns:** A few articles raised concerns about Amazon's high valuation and whether the stock price was getting ahead of its earnings.\n*   **Tariffs and Economic Headwinds:** The potential impact of tariffs and broader economic challenges on Amazon's business was mentioned in some articles, though this was not a dominant theme.\n*   **Competition:** While Amazon's market leadership was acknowledged, the growing competition from other tech giants in areas like cloud and AI was also a point of discussion in some articles.\n\n### Patterns and Correlations\n\nThere is a strong correlation between the bullish analyst recommendations and the positive sentiment found in the news. Both data sources point to a prevailing optimism about Amazon's future prospects.\n\n*   The consistent \"strong buy\" and \"buy\" ratings from analysts are mirrored by the frequent news reports on Amazon's strong financial performance, market leadership, and AI-driven growth potential.\n*   The minor concerns raised in some news articles, such as the slowing growth of AWS, are reflected in the small number of \"hold\" recommendations from analysts. This suggests that while the overall outlook is positive, there are some factors that are giving a few analysts pause.\n*   There is no significant bearish sentiment in either the analyst recommendations or the news analysis, indicating a broad consensus that Amazon's strengths far outweigh its weaknesses.\n\nIn conclusion, the period from July to September 2025 was characterized by a strong and stable bullish outlook for Amazon. Both analyst recommendations and news sentiment were overwhelmingly positive, with only minor concerns being raised. The primary drivers of this optimism were Amazon's strong financial performance, its leadership in cloud and AI, and its continued expansion into new markets."},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"send_message('''Compare Google's bullish versus bearish predictions from July 01 2025 until today.\n                Include a discussion of recommendation trends, and sentiment analysis of news from the same dates.\n                Discuss any patterns or correlations you find.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:38:59.068271Z","iopub.execute_input":"2025-09-06T16:38:59.068792Z","iopub.status.idle":"2025-09-06T16:40:40.935652Z","shell.execute_reply.started":"2025-09-06T16:38:59.068732Z","shell.execute_reply":"2025-09-06T16:40:40.934814Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is a comparison of Google's bullish versus bearish predictions from July 1, 2025, to September 6, 2025, including a discussion of recommendation trends, sentiment analysis of news, and any observed patterns or correlations.\n\n### Bullish vs. Bearish Predictions\n\nOverall, the sentiment surrounding Google (GOOGL) from July to early September 2025 has been predominantly bullish. This is reflected in analyst recommendations, news sentiment, and the stock's price performance.\n\n### Recommendation Trends\n\nAnalyst recommendations show a clear bullish trend for Google during this period. The number of \"buy\" recommendations increased, while \"strong buy\" and \"hold\" recommendations remained stable. There were no \"sell\" or \"strong sell\" recommendations, indicating a strong consensus among analysts that Google is a solid investment.\n\n| Period | Strong Buy | Buy | Hold | Sell | Strong Sell |\n|---|---|---|---|---|---|\n| 2025-09-01 | 18 | 37 | 13 | 0 | 0 |\n| 2025-08-01 | 18 | 37 | 13 | 0 | 0 |\n| 2025-07-01 | 18 | 32 | 13 | 0 | 0 |\n\n### News Sentiment Analysis\n\nNews sentiment analysis from July 1 to September 6, 2025, reveals a largely positive outlook for Google, with some notable bearish points.\n\n**Bullish News:**\n\n*   **Strong Financial Performance:** Many news articles highlighted Google's strong financial performance, particularly in its cloud and search segments.\n*   **AI Advancements:** The successful integration of AI into its products, such as Google Search and Google Cloud, has been a significant driver of positive sentiment.\n*   **Favorable Antitrust Ruling:** A key positive event was the favorable antitrust ruling in early September, which removed a significant overhang for the stock and led to a surge in its price.\n*   **Strategic Partnerships:** Positive news also came from strategic partnerships, such as the collaboration with Apple to use Google's Gemini AI for Siri.\n\n**Bearish News:**\n\n*   **Competition:** Some articles expressed concerns about increasing competition in the AI space from other tech giants.\n*   **Regulatory Risks:** The ongoing antitrust scrutiny, despite the favorable ruling, remains a potential headwind.\n*   **Data Privacy:** A few articles raised concerns about data privacy issues, which could lead to regulatory action and reputational damage.\n\n### Patterns and Correlations\n\nSeveral patterns and correlations can be observed from the data:\n\n*   **Positive Correlation between News Sentiment and Stock Price:** There is a strong positive correlation between news sentiment and Google's stock price. Positive news, such as the favorable antitrust ruling, was immediately followed by a significant increase in the stock price.\n*   **Analyst Recommendations Reflecting Positive Momentum:** The increase in \"buy\" recommendations from analysts in August and September aligns with the positive news flow and the stock's upward trend.\n*   **Overall Bullish Trend:** The combination of positive analyst ratings, predominantly positive news sentiment, and a rising stock price indicates a strong bullish trend for Google during this period. The bearish sentiment, while present, was not significant enough to derail the overall positive momentum.\n\nIn conclusion, the period from July to early September 2025 was very positive for Google. The company's strong financial performance, advancements in AI, and a favorable legal development contributed to a bullish outlook from both analysts and the media, which was reflected in the stock's strong performance."},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"send_message(\n    '''How is the outlook for Apple based on trends and news sentiment from July 01 2025 until today?\n    Perform the same analysis on all peers by sub-industry. Then compare Apple result to it's peers.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:43:43.094931Z","iopub.execute_input":"2025-09-06T16:43:43.095245Z","iopub.status.idle":"2025-09-06T16:44:54.686825Z","shell.execute_reply.started":"2025-09-06T16:43:43.095219Z","shell.execute_reply":"2025-09-06T16:44:54.685873Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Based on my analysis, here's the outlook for Apple and its peers from July 01, 2025, to September 6, 2025.\n\n### Apple (AAPL) Outlook\n\n**Recommendation Trends:**\nApple's analyst recommendations have remained largely positive. In the last four months, the number of \"buy\" and \"strong buy\" recommendations has consistently outnumbered \"hold,\" \"sell,\" and \"strong sell\" ratings.\n- **July 2025:** 24 buy, 14 strong buy, 14 hold, 3 sell, 1 strong sell.\n- **August 2025:** 24 buy, 14 strong buy, 15 hold, 3 sell, 0 strong sell.\n- **September 2025:** 23 buy, 14 strong buy, 15 hold, 3 sell, 0 strong sell.\n\n**News Sentiment:**\nThe news sentiment for Apple during this period has been mixed, with a significant number of articles having a negative or neutral sentiment.\n\n- **Positive:** Several articles highlighted Apple's strong financial performance, including robust App Store revenue, a \\$100 billion U.S. manufacturing investment to avoid tariffs, and a new multiyear supply partnership with Coherent for next-generation VCSEL products. The company's strategic partnerships, such as the one with MP Materials for recycled rare earth magnets, have also been viewed positively.\n- **Negative:** A recurring theme in the negative news has been the delay in the development of Apple Intelligence and Siri AI features, leading to a stock price drop and multiple securities fraud lawsuits. Concerns about a lag in AI advancements, stagnant growth, and high valuation have also been raised by analysts and investors, including Warren Buffett, who has been reducing his stake in the company.\n- **Neutral:** Many articles took a neutral stance, acknowledging both Apple's challenges and its strengths. These reports often pointed to the company's strong brand, loyal customer base, and robust ecosystem as factors that could help it overcome its current difficulties.\n\n### Peer Analysis\n\nHere's a summary of the outlook for Apple's peers in the Computers and Peripherals sub-industry:\n\n*   **Dell Technologies (DELL):** News sentiment for Dell has been mixed. Positive news includes the company being recognized for its channel performance and the launch of new AI-focused PCs. However, there are also concerns about a potential slowdown in PC sales and the company's high valuation.\n*   **Western Digital (WDC):** The sentiment for Western Digital has been largely neutral to positive. The company has been focusing on its new consumer brand identity and has seen strong performance in its flash business.\n*   **Hewlett Packard Enterprise (HPE):** HPE has a generally positive outlook, with a focus on its AI solutions and GreenLake platform. The company has been expanding its partnerships and has seen strong demand for its AI-native offerings.\n*   **HP Inc. (HPQ):** HP has a mixed to positive outlook. The company has been recognized for its channel performance and has been focusing on the AI PC market. However, there are some concerns about the broader PC market.\n*   **Pure Storage (PSTG):** Pure Storage has a very positive outlook, with strong earnings, revenue growth, and a focus on its AI-powered platform. The company has been consistently outperforming expectations.\n*   **Super Micro Computer (SMCI):** Super Micro has a positive outlook, driven by the demand for its AI servers. The company has been expanding its manufacturing capacity and has a strong relationship with Nvidia.\n*   **NetApp (NTAP):** NetApp has a positive outlook, with a focus on its all-flash storage solutions and cloud services. The company has been seeing strong growth and has been upgrading its full-year guidance.\n*   **IonQ (IONQ):** IonQ has a very positive outlook, with significant advancements in its quantum computing technology. The company has been achieving its technical milestones ahead of schedule and has a strong pipeline of potential commercial applications.\n*   **Quantum Computing Inc. (QUBT):** Quantum Computing Inc. has a positive outlook, with a focus on its quantum optimization platform. The company has been securing new contracts and expanding its government and commercial business.\n*   **Diebold Nixdorf (DBD):** Diebold Nixdorf has a mixed outlook. The company has been undergoing a financial restructuring and has been focusing on its new DN Series ATMs. While there are signs of a turnaround, the company still faces challenges.\n\n### Comparison and Conclusion\n\nOverall, the outlook for Apple is mixed. While the company's financial performance remains strong and analyst recommendations are generally positive, there are significant concerns about its AI strategy and innovation pipeline. The multiple lawsuits and the fact that a major investor like Warren Buffett is reducing his stake are also causes for concern.\n\nIn comparison, many of Apple's peers, particularly those in the AI and quantum computing spaces like **IonQ**, **Pure Storage**, and **Super Micro Computer**, have a more positive outlook. These companies are at the forefront of technological innovation and are seeing strong demand for their products and services.\n\nWhile Apple's strong brand and ecosystem should not be underestimated, the company will need to address the concerns about its AI strategy to maintain its leadership position in the tech industry. Investors will be closely watching the upcoming iPhone 17 event and any announcements related to Apple Intelligence for signs of a clear path forward."},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"send_message(\n    '''What does the recent news say about Apple and the impact of tariffs? From 2025-07-01 up to today.\n    Also locate candlestick data for the same dates. \n    Discuss in detail any correlations in patterns between the candlestick and news data.\n    Ignore duplicate news entry.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T16:46:46.672525Z","iopub.execute_input":"2025-09-06T16:46:46.672885Z","iopub.status.idle":"2025-09-06T16:47:41.834076Z","shell.execute_reply.started":"2025-09-06T16:46:46.672859Z","shell.execute_reply":"2025-09-06T16:47:41.833217Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Recent news about Apple (AAPL) from July 1, 2025, to September 6, 2025, has been heavily focused on the impact of tariffs, the company's AI strategy, and legal challenges. An analysis of this news in conjunction with the stock's candlestick data reveals several interesting correlations.\n\n### Candlestick Data Analysis (July 1, 2025 - September 6, 2025)\n\nThe candlestick data for Apple (AAPL) during this period shows a significant amount of volatility, with a general upward trend in the latter half of the period.\n\n*   **Early to Mid-July:** The stock experienced a period of decline and stagnation, with several days of significant downward movement. For example, on July 14th, the stock saw a notable drop.\n*   **Late July to Early August:** The stock began to show signs of recovery, with some upward momentum.\n*   **Mid-August:** A strong upward trend is visible, with a significant price jump around August 7th and 8th. This was followed by a period of sustained gains.\n*   **Late August to Early September:** The stock continued to trade at a higher price point, with some fluctuations.\n\n### News and Tariff Impact Analysis\n\nThe news surrounding Apple during this period was a mix of positive, negative, and neutral sentiment, with a significant focus on tariffs and the company's efforts to mitigate their impact.\n\n**Key News Events and Their Correlation with Stock Performance:**\n\n*   **Early July - Negative Sentiment and Stock Decline:**\n    *   **July 1, 2025:** An article titled \"Apple Stock Had A Nightmare Year — But It May Be Nearing A Turning Point\" highlighted the stock's struggles.\n    *   **July 6, 2025:** Another article discussed how poor earnings quality and high stock market valuations pose a significant risk to investors.\n    *   **Correlation:** This period of negative news corresponds with the stock's decline and stagnation in early to mid-July. The candlestick for July 14th, in particular, shows a significant drop, which aligns with the negative sentiment from the news around that time.\n\n*   **Mid-July - Mixed News and Volatility:**\n    *   **July 15, 2025:** Positive news about Apple's \\$500 million investment in MP Materials to secure a domestic supply of rare earth magnets.\n    *   **July 13, 14, 17, 26, 30, 2025:** A series of negative news articles about a securities fraud lawsuit related to Apple's AI development.\n    *   **Correlation:** This mix of positive and negative news is reflected in the stock's volatility during this period. The positive news about the MP Materials partnership may have contributed to some upward price movement, but the persistent negative news about the lawsuit likely tempered any significant gains.\n\n*   **Early to Mid-August - Positive News and Strong Rally:**\n    *   **August 7, 2025:** A very positive article, \"Apple: Why the Stock Is Protected From Trump Admin’s Semiconductor Tariff Plans,\" announced a \\$100 billion U.S. manufacturing commitment to secure an exemption from potential semiconductor tariffs.\n    *   **August 12, 2025:** Another positive article, \"Apple Stock Jumps on Trump Policy Wins — But AI Doubts Remain,\" highlighted the stock's rise after the investment announcement.\n    *   **August 19, 2025:** Positive news about Apple achieving a milestone by producing all iPhone 17 models in India, further mitigating tariff impacts.\n    *   **Correlation:** This string of positive news, particularly the announcement of the tariff exemption, directly correlates with the strong upward trend in the stock price in mid-August. The candlestick data shows a significant price jump around August 7th and 8th, which aligns perfectly with the timing of this news.\n\n*   **Late August to Early September - Continued Strength with Some Concerns:**\n    *   **August 29, 2025:** News that Warren Buffett's Berkshire Hathaway was continuing to trim its Apple stake.\n    *   **September 2, 2025:** A positive article suggesting Apple is on the verge of an AI-driven supercycle.\n    *   **September 3, 2025:** News of a lawsuit from Elon Musk's xAI against Apple and OpenAI.\n    *   **September 6, 2025:** An article suggesting that Apple's stock is overvalued.\n    *   **Correlation:** The stock maintained its higher price point during this period, suggesting that the positive sentiment from the tariff exemption and production diversification news continued to outweigh concerns about the lawsuit and valuation. However, the news about Berkshire Hathaway selling shares and the overvaluation concerns may have contributed to some of the price fluctuations seen in late August and early September.\n\n### Detailed Correlation Patterns\n\n1.  **Tariff News as a Primary Driver:** The most significant correlation observed is between the news related to tariffs and the stock's performance. Negative news about potential tariffs in early July corresponded with a stock price decline, while the positive news of a tariff exemption in early August triggered a strong and sustained rally. This suggests that investors were highly sensitive to news about the impact of tariffs on Apple's business.\n\n2.  **AI Development as a Secondary Factor:** News about Apple's AI strategy, both positive (potential acquisitions and a future \"supercycle\") and negative (lawsuits and perceived lag in development), also appears to have influenced the stock price, but to a lesser extent than the tariff news. The negative news about the AI lawsuit in mid-July likely contributed to the stock's volatility, but it was not enough to cause a major downturn.\n\n3.  **Investor Sentiment and Market Narratives:** The news articles also reflect broader market narratives about Apple's valuation, growth prospects, and the impact of Warren Buffett's investment decisions. These narratives can create a general sentiment that influences investor behavior, even in the absence of specific, market-moving news. For example, the repeated articles about Berkshire Hathaway selling its stake may have created some underlying selling pressure on the stock.\n\n### Conclusion\n\nIn conclusion, the recent news about Apple and the impact of tariffs had a clear and direct correlation with the stock's candlestick data from July 1, 2025, to September 6, 2025. The company's strategic moves to mitigate tariff risks, such as the \\$100 billion U.S. manufacturing investment and the diversification of production to India, were met with a strong positive reaction from the market, leading to a significant stock price increase. While other factors, such as the company's AI strategy and legal challenges, also played a role, the news related to tariffs was the primary driver of the stock's performance during this period. This analysis highlights the importance of monitoring geopolitical and trade-related news when investing in multinational companies like Apple."},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  150\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"# Conclusion\n\n<span style=\"font-size:18px;\">\nFor now that will have to do. Our Essy has a solid foundation but more could be done to organise metadata. No evaluation or validation has been performed (except fuzzing the prompt). Next steps include restructuring the vector database based on lessons learned. That'll be followed by plotting, multi-modal, and structured output. The last close date (generative) function can be temperamental. In the same way Gemini always feels regarding dates. I've learnt so much. I'm happy I decided to participate in the event! It really has been a joy to see Essy grow from random chat with Gemini into the foundation for a good-broker buddy. I hope you enjoy playing with this edition as much as I enjoyed building it!\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Update June 7, 2025\n\n<span style=\"font-size:18px;\">\n    Bugfix version 102 finally brings Essy to a stable milestone. A month and a half late :) There's still more to be built including adding reasoning, agents, and structured output. A few unimplemented rest endpoints remain that could make Essy more self-reliant. The vector store has gotten bigger but not smarter. Essy can tell us pre-scored news has some sentiment but cannot generate it due to limited summaries. Essy can detect interesting patterns in a dataset but not between adjacent datasets. There's so much data we'll need to recruit Essy some help.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Advanced (localhost required)\n\n<span style=\"font-size:18px;\">\n    The functions demonstrated here require a locally running notebook. A dedicated GPU with at least 8GB VRAM is recommended but not required. Output is generated with Gemma 3 12B QAT, Gemma.cpp, and (later) Gemma 3n. Output on Kaggle is based on cached data.\n</span>","metadata":{}},{"cell_type":"code","source":"# soon","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null}]}