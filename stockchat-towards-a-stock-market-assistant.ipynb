{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-2-document-q-a-with-rag.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11376588,"sourceType":"datasetVersion","datasetId":7122584}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oswind/stockchat-a-stock-market-assistant?scriptVersionId=246444061\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Environment Setup","metadata":{}},{"cell_type":"code","source":"# Setup the notebook based on running environment.\nimport os\n# Optional: Enable telemetry in browser_use and chromadb\nos.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\ntry:\n    from kaggle_secrets import UserSecretsClient # type: ignore\nexcept Exception as e:\n    class UserSecretsClient:\n        @classmethod\n        def get_secret(cls, id: str):\n            try:\n                return os.environ[id]\n            except KeyError as e:\n                print(f\"KeyError: authentication token for {id} is undefined\")\n    # Local Run: update the venv.\n    %pip install -qU google-genai==1.7.0 chromadb==0.6.3 opentelemetry-proto==1.34.1 langchain-google-genai==2.1.2\n    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core lmnr[google-generativeai] browser-use\n    from browser_use import Agent as BrowserAgent\nelse:\n    # Kaggle Run: update the system.\n    !pip uninstall -qqy google-generativeai google-cloud-automl google-cloud-translate datasets cesium bigframes plotnine mlxtend\n    !pip install -qU google-genai==1.7.0 chromadb==0.6.3 opentelemetry-proto==1.34.1 langchain-google-genai==2.1.2\n    !pip install -qU langchain-community langchain-text-splitters wikipedia lmnr[google-generativeai]\n\nimport ast, chromadb, csv, json, logging, pandas, pytz, re, requests, time, warnings, wikipedia\nfrom bs4 import Tag\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse\nfrom dateutil.tz import gettz\nfrom enum import Enum\nfrom google import genai\nfrom google.api_core import retry, exceptions\nfrom google.genai import types\nfrom IPython.display import HTML, Markdown, display\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain_text_splitters.character import RecursiveCharacterTextSplitter\nfrom langchain_text_splitters.html import HTMLSemanticPreservingSplitter\nfrom langchain_text_splitters.json import RecursiveJsonSplitter\nfrom lmnr import Laminar\nfrom pydantic import BaseModel, field_validator\nfrom queue import Queue\nfrom threading import Timer\nfrom tqdm import tqdm\nfrom typing import Optional, Callable, NewType\nfrom wikipedia.exceptions import DisambiguationError, PageError","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare the Gemini api for use.\n# Setup a retry helper in case we hit the RPM limit on generate_content or embed_content.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503, 500})\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\ngenai.models.Models.embed_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.embed_content)\n\n# Import the required google api key.\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\n# Activate Laminar auto-instrumentation.\ntry:\n    Laminar.initialize(project_api_key=UserSecretsClient().get_secret(\"LMNR_PROJECT_API_KEY\"))\nexcept:\n    print(\"Skipping Laminar.initialize()\")\n\n# A Gemini python api-helper with retry support.\nGeminiEmbedFunction = NewType(\"GeminiEmbedFunction\", None) # forward-decl\nclass Gemini:\n    gen_model = [[\"gemini-2.0-flash\",15,2000,10000,30000,0,0],     # latest: 15 RPM/1500 RPD/500 search per day/1M TPM\n                 [\"gemini-2.0-flash-exp\",10,10,10,10,0,0],         #    exp: 10 RPM/...\n                 [\"gemini-2.0-flash-001\",15,2000,10000,30000,0,0], # stable: 15 RPM/... (quota shared with latest)\n                 [\"gemini-2.5-flash-preview-04-17\",10,1000,2000,10000,0,0], # 10 RPM/500 RPD/500 search per day/250K TPM\n                 [\"gemini-2.5-pro-exp-03-25\",5,5,5,5,0,0]] #  5 RPM/25 RPD/500 search per day/250K TPM/1M TPD\n    gen_local = []\n    embed_model = [\"text-embedding-004\",1500] # 1500 RPM / Max 100 per batch embed request\n    error_total = 0\n    min_rpm = 3\n    dt_between = 2.0\n    errored = False\n    running = False\n    dt_err = 30.0\n    dt_rpm = 60.0\n\n    class Limit(Enum):\n        FREE = 1\n        TIER_1 = 2\n        TIER_2 = 3\n        TIER_3 = 4\n    \n    class Model(Enum):\n        GEN = 1\n        EMB = 2\n        LOC = 3\n\n    class Const(Enum):\n        STOP = \"I don't know.\"\n        METRIC_BATCH = 20\n        SERIES_BATCH = 40\n        EMBED_BATCH = 100\n        CHUNK_MAX = 1500\n\n        @classmethod\n        def Stop(cls):\n            return cls.STOP.value\n\n        @classmethod\n        def MetricBatch(cls):\n            return cls.METRIC_BATCH.value\n\n        @classmethod\n        def SeriesBatch(cls):\n            return cls.SERIES_BATCH.value\n\n        @classmethod\n        def EmbedBatch(cls):\n            return cls.EMBED_BATCH.value\n\n        @classmethod\n        def ChunkMax(cls):\n            return cls.CHUNK_MAX.value\n\n    def __init__(self, with_limit: Limit, default_model: int = 0):\n        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n        self.limit = with_limit.value\n        self.m_id = default_model\n        self.default_model = default_model\n        self.default_local = default_model\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n        self.s_embed = GeminiEmbedFunction(self.client, semantic_mode = True)\n        logging.getLogger(\"google_genai\").setLevel(logging.WARNING) # suppress info on generate\n\n    def __call__(self, model: Model) -> str:\n        if model == self.Model.GEN:\n            return \"models/\" + self.gen_model[self.m_id][0]\n        elif model == self.Model.LOC:\n            return self.gen_local[self.default_local]\n        else:\n            return \"models/\" + self.embed_model[0]\n\n    def set_default_model(self, model_index: int):\n        if model_index in range(0, len(self.gen_model)):\n            self.stop_running()\n            self.default_model = model_index\n            self.m_id = model_index\n        else:\n            print(f\"set default model({model_index}) must be 0..{len(self.gen_model)-1}\")\n\n    def set_default_local(self, model_index: int):\n        if model_index in range(0, len(self.gen_local)):\n            self.default_local = model_index\n        else:\n            print(f\"set default local({model_index}) must be 0..{len(self.gen_local)-1}\")\n\n    def retriable(self, retry_fn: Callable, *args, **kwargs):\n        for attempt in range(len(self.gen_model)):\n            try:\n                if self.gen_rpm > self.min_rpm:\n                    self.gen_rpm -= 1\n                else:\n                    self.on_error(kwargs)\n                if not self.running and not self.errored:\n                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n                    self.rpm_timer.start()\n                    self.running = True\n                return retry_fn(*args, **kwargs)\n            except exceptions.RetryError as retry_error:\n                retriable = retry_error.code in {429, 503, 500}\n                if not retriable or attempt == len(self.gen_model)-1:\n                    raise retry_error\n                self.on_error(kwargs)\n            except Exception as e:\n                raise e\n\n    def on_error(self, kwargs):\n        self.stop_running()\n        self.save_error()\n        self.next_model()\n        print(\"api.on_error.next_model: model is now \", self.gen_model[self.m_id][0])\n        if not self.errored:\n            self.error_timer = Timer(self.dt_err, self.zero_error)\n            self.error_timer.start()\n            self.errored = True\n        kwargs[\"model\"] = self(Gemini.Model.GEN)\n        time.sleep(self.dt_between)\n\n    def stop_running(self):\n        if self.running:\n            self.rpm_timer.cancel()\n            self.running = False\n\n    def validation_fail(self):\n        gen_model = self.gen_model[self.m_id]\n        gen_model[len(gen_model)-2] += 1\n        self.error_total += 1\n\n    def save_error(self):\n        gen_model = self.gen_model[self.m_id]\n        gen_model[len(gen_model)-1] += 1\n        self.error_total += 1\n\n    def next_model(self):\n        self.m_id = (self.m_id+1)%len(self.gen_model)\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n\n    def refill_rpm(self):\n        self.running = False\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n        print(\"api.refill_rpm \", self.gen_rpm)\n\n    def zero_error(self):\n        self.errored = False\n        self.m_id = self.default_model\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n        print(\"api.zero_error: model is now \", self.gen_model[self.m_id][0])\n\n    def token_count(self, expr: str):\n        count = self.client.models.count_tokens(\n            model=self(Gemini.Model.GEN),\n            contents=json.dumps(expr))\n        return count.total_tokens\n\n    def errors(self):\n        errors = {\"total\": self.error_total, \"by_model\": {}}\n        for model in self.gen_model:\n            errors[\"by_model\"].update({model[0]: {\"api_related\": model[len(model)-1], \n                                                  \"validation\": model[len(model)-2]}})\n        return errors\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, content: list):\n        return self.s_embed.sts(content)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:32:42.016891Z","iopub.execute_input":"2025-06-20T04:32:42.017883Z","iopub.status.idle":"2025-06-20T04:32:42.371962Z","shell.execute_reply.started":"2025-06-20T04:32:42.01785Z","shell.execute_reply":"2025-06-20T04:32:42.371123Z"}},"outputs":[{"name":"stdout","text":"Skipping Laminar.initialize()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# An embedding function based on text-embedding-004.\napi = NewType(\"Gemini\", None) # forward-decl\nclass GeminiEmbedFunction:\n    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n    \n    def __init__(self, genai_client, semantic_mode: bool = False):\n        self.client = genai_client\n        if semantic_mode:\n            self.document_mode = False\n            self.semantic_mode = True\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __embed__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        elif not self.document_mode and not self.semantic_mode:\n            embedding_task = \"retrieval_query\"\n        elif not self.document_mode and self.semantic_mode:\n            embedding_task = \"semantic_similarity\"\n        partial = self.client.models.embed_content(\n            model=api(Gemini.Model.EMB),\n            contents=input,\n            config=types.EmbedContentConfig(task_type=embedding_task))\n        return [e.values for e in partial.embeddings]\n    \n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __call__(self, input: Documents) -> Embeddings:\n        try:\n            response = []\n            for i in range(0, len(input), Gemini.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n                response += self.__embed__(input[i:i + Gemini.Const.EmbedBatch()])\n            return response\n        except Exception as e:\n            print(f\"caught exception of type {type(e)}\\n{e}\")\n            raise e\n\n    def sts(self, content: list) -> float:\n        df = pandas.DataFrame(self(content), index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:32:42.373011Z","iopub.execute_input":"2025-06-20T04:32:42.373401Z","iopub.status.idle":"2025-06-20T04:32:42.381964Z","shell.execute_reply.started":"2025-06-20T04:32:42.37337Z","shell.execute_reply":"2025-06-20T04:32:42.380981Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Instantiate the api-helper with usage limit.\napi = Gemini(with_limit=Gemini.Limit.FREE) # or TIER_1,TIER_2,TIER_3","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:32:42.384059Z","iopub.execute_input":"2025-06-20T04:32:42.384391Z","iopub.status.idle":"2025-06-20T04:32:42.738829Z","shell.execute_reply.started":"2025-06-20T04:32:42.384364Z","shell.execute_reply":"2025-06-20T04:32:42.738066Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Laying the foundation with Gemini 2.0\n\n<span style=\"font-size:18px;\">\nA programming instructor once suggested the idea of a Stock Market application for final project topics. They did this knowing good investing app UX is challenging. The idea has stuck with me since because it's true. In the past I've worked with some REST api's building toys. None of them could ever reach my expectations because of API limits. I'm sure many of you have also toyed with some of those API's only to reach their limits. I always knew the secret to great finance UX is a great AI to help out. When posed with so many topics for 2025's 5-Day GenAI Course, I first tinkered with many of the other capabilities of Gemini until I posed Gemini the question:\n</span> ","metadata":{}},{"cell_type":"code","source":"# This is an accurate retelling of events. \nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0\n)\n\nchat = api.client.chats.create(\n    model=api(Gemini.Model.GEN), \n    config=config_with_search, \n    history=[]) # Ignoring the part about dark elves, and tengwar.\n\nresponse = chat.send_message('Do you know anything about the stock market?')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:32:42.739721Z","iopub.execute_input":"2025-06-20T04:32:42.73994Z","iopub.status.idle":"2025-06-20T04:32:46.762619Z","shell.execute_reply.started":"2025-06-20T04:32:42.739923Z","shell.execute_reply":"2025-06-20T04:32:46.761924Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Yes, I do. Here's some information about the stock market:\n\n**What it is:**\n\n*   The stock market is a place where stocks or shares of publicly traded companies are bought and sold. This transfer of stock ownership happens between a seller and a buyer, who agree on a price.\n*   It provides a platform for companies to raise capital by issuing stocks and for investors to participate in the growth of these companies.\n\n**Key Components:**\n\n*   **Stock Exchanges:** These are organized marketplaces where stocks are bought and sold. Examples include the New York Stock Exchange (NYSE) and the London Stock Exchange (LSE).\n*   **Market Participants:** These include individual investors, institutional investors like banks, insurance companies, pension funds, and hedge funds, and stockbrokers who execute buy and sell orders.\n*   **Primary Market:** Where new stocks are issued by companies.\n*   **Secondary Market:** Where existing stocks are traded among investors.\n\n**How it Works:**\n\n*   Investors buy and sell stocks based on their expectations of the company's future performance and other market factors.\n*   The price of a stock is determined by supply and demand. If more people want to buy a stock than sell it, the price goes up, and vice versa.\n*   Trades are typically executed through brokers or online trading platforms.\n\n**Size and Scope:**\n\n*   The stock market is a massive global network. The total market capitalization of all publicly traded stocks worldwide was US$111 trillion by the end of 2023.\n*   There are numerous stock exchanges around the world, with the largest ones located in North America, Europe, and Asia.\n\n**Indices:**\n\n*   Stock market indices, like the US500, track the performance of a group of stocks and are used to gauge the overall health of the market.\n*   As of June 20, 2025, the US500 rose to 6013 points.\n\n**Important Considerations:**\n\n*   Investing in the stock market involves risk, and it's possible to lose money.\n*   Factors like trading prices, market ratings, and financial institutions can influence participation in stock markets.\n\nI hope this gives you a good overview of the stock market!\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# How much Gemini 2.0 knows\n\n<span style=\"font-size:18px;\">\nI thought to myself: Could grounding really make it that easy? Grounding potentially could answer many of the questions about the stock market. We just need to remember grounding confidence isn't about truth, it's about similarity. I decided to limit myself to free tier in finding out.\n</span>","metadata":{}},{"cell_type":"code","source":"# And so I asked a more challenging questions.\nresponse = chat.send_message('I have an interest in AMZN stock')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:32:46.763663Z","iopub.execute_input":"2025-06-20T04:32:46.763978Z","iopub.status.idle":"2025-06-20T04:32:52.165673Z","shell.execute_reply.started":"2025-06-20T04:32:46.763952Z","shell.execute_reply":"2025-06-20T04:32:52.164869Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, let's talk about AMZN stock, which represents Amazon.com, Inc. Here's some information that might be helpful:\n\nHere's a breakdown of information regarding AMZN (Amazon) stock:\n\n**What Amazon Does:**\n\n*   Amazon is a global technology company involved in online retail, cloud computing, online advertising, digital streaming, and artificial intelligence.\n*   It operates an online marketplace for buyers and sellers.\n*   They manufacture and sell electronic devices like Kindle, Fire tablets, Echo, Ring, and Eero.\n*   Amazon Web Services (AWS) provides cloud computing platforms and APIs to individuals, companies, and governments.\n\n**Stock Information:**\n\n*   **Current Price:** On June 18, 2025, the closing price of AMZN was $212.53.\n*   **52-Week Range:** The 52-week low was $151.57, and the high was $242.52.\n*   **Market Capitalization:** Amazon's market capitalization is $1,852.64 billion.\n\n**Analyst Ratings and Forecasts:**\n\n*   **Consensus:** The consensus rating for AMZN stock is \"Strong Buy.\"\n*   **Analyst Price Targets:**\n    *   The average price target is around $241.61 to $245.75.\n    *   High estimates go up to $305.\n    *   Low estimates go down to $195.\n*   **Forecasts:**\n    *   Many analysts predict the stock price will increase over the next year.\n    *   One source estimates an average price of $230.15 in 2025.\n    *   Another suggests the stock could reach $217.85 by July 18, 2025.\n    *   Long-term forecasts (2028-2030) range from potential gains of around 30% to nearly 100%.\n\n**Factors to Consider:**\n\n*   **AWS:** Amazon Web Services is a major profit driver and is considered a \"crown jewel\" by analysts. Its growth in the AI market is a significant factor.\n*   **Revenue Growth:** Analysts predict revenue growth of around 10% in 2025.\n*   **Profit Growth:** There are forecasts of a slowdown in profit growth in 2025, which could negatively affect the stock.\n*   **Valuation:** The stock's P/E ratio is around 32.\n*   **Competition:** Amazon faces competition in the cloud services market from companies like Microsoft (Azure) and Google (Google Cloud).\n\n**Recent News:**\n\n*   Amazon is implementing AI solutions throughout its e-commerce division.\n*   Amazon is introducing AI technologies to enhance logistics.\n*   Amazon is telling thousands of corporate employees to relocate.\n\n**Disclaimer:** *This information is for general knowledge only and does not constitute financial advice. Please consult with a financial advisor before making any investment decisions.*\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> \nImpressed, I was reminded of the dreaded REST api's (some official) that I've worked in the past. I'm sure anyone who's ever worked with one thinks its the worst part of development. So I next asked Gemini to distill it's vast news knowledge.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message(\n    '''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:32:52.166671Z","iopub.execute_input":"2025-06-20T04:32:52.167123Z","iopub.status.idle":"2025-06-20T04:32:55.511719Z","shell.execute_reply.started":"2025-06-20T04:32:52.167103Z","shell.execute_reply":"2025-06-20T04:32:55.511079Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's a summary of AMZN's current share price, short-term trends, and bullish versus bearish predictions as of June 20, 2025:\n\n**Current Share Price:**\n\n*   As of June 18, 2025, the closing price of AMZN was $212.53.\n\n**Short-Term Trends:**\n\n*   **Recent Performance:** AMZN has shown some volatility recently.\n*   **Analyst Sentiment:** Overall, analyst sentiment seems positive, with a consensus rating of \"Strong Buy.\"\n\n**Bullish Predictions:**\n\n*   **Price Targets:** Many analysts have price targets above the current price, with average targets ranging from $241.61 to $245.75. Some high estimates go as high as $305.\n*   **Growth Drivers:**\n    *   **AWS Growth:** Continued growth in Amazon Web Services (AWS), particularly in the AI space, is a major bullish factor.\n    *   **E-commerce and Advertising:** Improvements and innovations in Amazon's e-commerce platform and advertising business are expected to drive revenue.\n    *   **Overall Revenue Growth:** Expectations of around 10% revenue growth in 2025 support a bullish outlook.\n*   **Specific Forecasts:** Some forecasts suggest the stock could reach $217.85 by July 18, 2025, and longer-term forecasts (2028-2030) indicate potential gains of 30% to nearly 100%.\n\n**Bearish Predictions:**\n\n*   **Slower Profit Growth:** Some analysts predict a slowdown in profit growth in 2025, which could negatively impact the stock price.\n*   **Competition:** Intense competition in the cloud computing market from Microsoft Azure and Google Cloud could limit AWS's growth.\n*   **Valuation Concerns:** A P/E ratio around 32 might be considered high by some investors, making them cautious.\n*   **Price Targets:** Some analysts have lower price targets, with estimates going as low as $195.\n\n**Summary:**\n\n*   **Overall:** The general sentiment leans towards a bullish outlook for AMZN, driven by AWS growth and improvements in e-commerce and advertising.\n*   **Considerations:** However, potential investors should be aware of possible slower profit growth and strong competition in the cloud market, which could present challenges.\n\n**Disclaimer:** *This information is for general knowledge only and does not constitute financial advice. Please consult with a financial advisor before making any investment decisions.*\n"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# The (current) limits reached\n\n<span style=\"font-size:18px;\">\nWith two prompts Gemini 2.0 made all the effort I've spent on finance api's obsolete. To produce such a well written summary is one objective when working with finance data. This is great! Now all we need is a generative AI capable in our own language. There's a limit of course. The grounding is subjectively true based only on it's grounding supports -- it may even be hallucinated:\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:32:55.51245Z","iopub.execute_input":"2025-06-20T04:32:55.512658Z","iopub.status.idle":"2025-06-20T04:32:57.548723Z","shell.execute_reply.started":"2025-06-20T04:32:55.512641Z","shell.execute_reply":"2025-06-20T04:32:57.548001Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"It appears you might be asking about two different companies with similar names:\n\n**1. MGM Resorts International:**\n\n*   **Ticker Symbol:** MGM\n*   **Exchange:** New York Stock Exchange (NYSE)\n\n**2. Metro-Goldwyn-Mayer (MGM Studios):**\n\n*   MGM Studios was acquired by Amazon in 2022 and is no longer a publicly traded company. It is now a subsidiary of Amazon MGM Studios.\n*   Historically, it traded under the ticker symbol MGM but was delisted.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe order of results and/or content of results is interesting here. The AI is confused about which MGM Studios I'm referring to. On non-thinking variants Gemini may not even mention Amazon. Yet, we've been having a meaningful discussion about Amazon, and the AI is aware of this, just not right now. Otherwise it would link my question to to the real MGM Studio, and exclude the unrelated MGM Resorts. The confusion is linked to the use of the MGM word token. The unrelated MGM stock ticker has now entered the discussion. Depending on how you prompt Gemini 2.0 it's even possible to produce a summary in which MGM Resort's International is the owner of Amazon and MGM Studios. There's two more caveat. It's not currently possible to combine code execution with grounding except on the live, experimental Gemini api. Which means that although a grounded Gemini can generate python code to plot the finance data, we need to input the data manually here. That includes matching a schema or prompting it's output.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''Can you run some python to plot that last open,close,hig,low like a candlestick''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:32:57.549565Z","iopub.execute_input":"2025-06-20T04:32:57.549808Z","iopub.status.idle":"2025-06-20T04:32:59.037476Z","shell.execute_reply.started":"2025-06-20T04:32:57.549786Z","shell.execute_reply":"2025-06-20T04:32:59.036465Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I apologize, I am unable to fulfill that request at this time. I am missing the capability to execute the code with the necessary libraries.\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"response = chat.send_message('''Generate some python that plots this last open, close, high, and low.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:32:59.039972Z","iopub.execute_input":"2025-06-20T04:32:59.040171Z","iopub.status.idle":"2025-06-20T04:33:08.124465Z","shell.execute_reply.started":"2025-06-20T04:32:59.040156Z","shell.execute_reply":"2025-06-20T04:33:08.123619Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's Python code using `matplotlib` to create a candlestick plot for a single day's OHLC (Open, High, Low, Close) data.  I'll also include an example of how you might adapt it to work with `yfinance` to fetch the data directly, though I can't execute that part.\n\n```python\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport pandas as pd\n# Example OHLC data (replace with your actual data)\ndata = {\n    'Date': ['2025-06-18'],  # Or whatever the date is\n    'Open': [210.00],       # Replace with the actual open price\n    'High': [215.50],       # Replace with the actual high price\n    'Low': [208.75],        # Replace with the actual low price\n    'Close': [212.53]      # Replace with the actual close price\n}\n\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n\ndef candlestick_plot(df, ax=None):\n    \"\"\"\n    Plots a candlestick chart for a single day's OHLC data.\n\n    Args:\n        df: DataFrame with 'Date', 'Open', 'High', 'Low', 'Close' columns.\n        ax: Matplotlib Axes object to plot on. If None, a new figure and axes are created.\n    \"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    # Determine color based on whether the closing price is higher or lower than the opening price\n    if df['Close'][0] >= df['Open'][0]:\n        color = 'green'  # Or 'lime', 'forestgreen', etc.\n    else:\n        color = 'red'  # Or 'firebrick', 'salmon', etc.\n\n    # Plot the high-low line\n    ax.vlines(df['Date'], df['Low'], df['High'], color='black', linewidth=1)\n\n    # Plot the candlestick body\n    ax.vlines(df['Date'], df['Open'], df['Close'], color=color, linewidth=4)  # Thicker line for the body\n\n    ax.set_title('Single Day Candlestick Chart')\n    ax.set_ylabel('Price')\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))  # Format date on x-axis\n    ax.xaxis.set_major_locator(mdates.AutoDateLocator()) #Automatically choose the right number of dates\n    plt.xticks(rotation=45)  # Rotate date labels for readability\n    ax.grid(True)\n\n    return ax\n\n# Create the plot\nfig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size as needed\ncandlestick_plot(df, ax)\nplt.tight_layout()  # Adjust layout to prevent labels from overlapping\nplt.show()\n\n\n# Example using yfinance (you'll need to install it: pip install yfinance)\n# This part I CANNOT RUN, but it shows how you *would* do it.\n# ```python\n# import yfinance as yf\n#\n# # Get the data for AMZN for a specific date\n# ticker = \"AMZN\"\n# start_date = \"2025-06-18\"  # Replace with the desired date\n# end_date = \"2025-06-19\"  # Add one day to get data for the specified date\n#\n# amzn_data = yf.download(ticker, start=start_date, end=end_date)\n#\n# # Reset the index to make 'Date' a column\n# amzn_data = amzn_data.reset_index()\n#\n# # Rename columns to match the expected format\n# amzn_data = amzn_data.rename(columns={'Open': 'Open', 'High': 'High', 'Low': 'Low', 'Close': 'Close', 'Date': 'Date'})\n#\n# # Call the candlestick_plot function\n# fig, ax = plt.subplots(figsize=(8, 6))\n# candlestick_plot(amzn_data, ax)\n# plt.tight_layout()\n# plt.show()\n# ```\n\n```\n\nKey improvements and explanations:\n\n*   **Clearer Structure:**  The code is now organized into a function `candlestick_plot` for better reusability.\n*   **Date Handling:**  The code now explicitly converts the 'Date' column to datetime objects using `pd.to_datetime`.  This is crucial for `matplotlib` to handle the dates correctly.  The x-axis is formatted to show the date.\n*   **Color Coding:** The candlestick body is colored green if the closing price is higher than the opening price and red otherwise.\n*   **Error Handling (Implicit):**  The `if ax is None:` block allows the function to be used with or without an existing `Axes` object.\n*   **Clarity:** Added comments to explain each step.\n*   **`yfinance` Example (Commented Out):**  I've included a commented-out example of how you *would* use `yfinance` to fetch the data directly.  This is the part I cannot execute.  It shows how to download the data, reset the index, rename the columns, and then pass the data to the `candlestick_plot` function.  It also includes the necessary `pip install yfinance` instruction.\n*   **`plt.tight_layout()`:**  This is added to prevent labels from overlapping, especially the date labels.\n*   **`figsize`:** Added `figsize` to `plt.subplots` to control the size of the plot.\n*   **`ax.grid(True)`:** Added a grid for better readability.\n*   **`AutoDateLocator`:**  Uses `mdates.AutoDateLocator()` to automatically choose the best number of date ticks on the x-axis.\n*   **Single Data Point:** The code is specifically designed to handle a single day's data, as requested.  If you have multiple days, you'll need to modify the plotting logic (likely using `candlestick_ohlc` from `matplotlib.finance`, but that's more complex).\n\nTo use this code:\n\n1.  **Install `matplotlib`:** If you don't have it already, run `pip install matplotlib` in your terminal.\n2.  **Replace Example Data:**  Replace the example OHLC data in the `data` dictionary with the actual open, high, low, and close prices for the day you're interested in.  Make sure the date is in a format that `pd.to_datetime` can understand (YYYY-MM-DD is a good choice).\n3.  **Run the Code:** Execute the Python script.  A candlestick chart will be displayed.\n\nIf you want to use the `yfinance` part:\n\n1.  **Install `yfinance`:** Run `pip install yfinance` in your terminal.\n2.  **Uncomment the `yfinance` section:** Remove the `#` characters from the lines in the `yfinance` example.\n3.  **Run the Code:** Execute the Python script.  It will download the data from Yahoo Finance and create the candlestick chart.  Remember that I cannot test this part.\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:33:08.125266Z","iopub.execute_input":"2025-06-20T04:33:08.12548Z","iopub.status.idle":"2025-06-20T04:33:08.869313Z","shell.execute_reply.started":"2025-06-20T04:33:08.125461Z","shell.execute_reply":"2025-06-20T04:33:08.86845Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, according to the information I have, here's the AMZN data from June 18, 2025:\n\n*   **Open:** Not available in my current data.\n*   **High:** Not available in my current data.\n*   **Low:** Not available in my current data.\n*   **Close:** $212.53\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"response = chat.send_message(\n    '''What is AMZN open,close,high,low data for the past month? \n    Present the data with multiple columns for display in markdown.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:33:08.870491Z","iopub.execute_input":"2025-06-20T04:33:08.870801Z","iopub.status.idle":"2025-06-20T04:33:16.514318Z","shell.execute_reply.started":"2025-06-20T04:33:08.870777Z","shell.execute_reply":"2025-06-20T04:33:16.513667Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's the AMZN OHLC (Open, High, Low, Close) data for the past month (approximately, based on available data in June 2025).  Note that \"past month\" is relative to June 20, 2025, and the data is limited to what I could retrieve.\n\n| Date       | Open    | High    | Low     | Close   |\n|------------|---------|---------|---------|---------|\n| 2025-06-18 | $215.09 | $217.96 | $212.34 | $212.52 |\n| 2025-06-17 | $215.195| $217.41 | $214.56 | $214.82 |\n| 2025-06-16 | $212.31 | $217.06 | $211.60 | $216.10 |\n| 2025-06-13 | $209.96 | $214.05 | $209.62 | $212.10 |\n| 2025-06-12 | $211.78 | $213.58 | $211.33 | $213.24 |\n| 2025-06-11 | $217.41 | $218.40 | $212.89 | $213.20 |\n| 2025-06-10 | $216.78 | $217.69 | $214.15 | $217.61 |\n| 2025-06-09 | $214.75 | $217.85 | $212.88 | $216.98 |\n| 2025-06-06 | $212.40 | $213.87 | $210.50 | $213.57 |\n| 2025-06-05 | $209.55 | $212.81 | $207.56 | $207.91 |\n| 2025-06-04 | $206.55 | $208.18 | $205.18 | $207.23 |\n| 2025-06-03 | $207.11 | $208.95 | $205.03 | $205.71 |\n| 2025-06-02 | $204.98 | $207.00 | $202.68 | $206.65 |\n| 2025-05-30 | $204.84 | $205.99 | $201.70 | $205.01 |\n| 2025-05-29 | $208.03 | $208.81 | $204.23 | $205.70 |\n| 2025-05-28 | $205.92 | $207.66 | $204.41 | $204.72 |\n| 2025-05-27 | $203.09 | $206.69 | $202.19 | $206.02 |\n| 2025-05-23 | $198.90 | $202.37 | $197.85 | $200.99 |\n| 2025-05-22 | $201.38 | $205.76 | $200.16 | $203.10 |\n| 2025-05-21 | $201.61 | $203.46 | $200.06 | $201.12 |\n| 2025-05-20 | $204.63 | $205.59 | $202.65 | $204.07 |\n| 2025-05-19 | $201.65 | $206.62 | $201.26 | $206.16 |\n| 2025-05-16 | $206.85 | $206.85 | $204.37 | $205.59 |\n| 2025-05-15 | $206.45 | $206.88 | $202.67 | $205.17 |\n| 2025-05-14 | $211.45 | $211.93 | $208.85 | $210.25 |\n| 2025-05-13 | $211.08 | $214.84 | $210.10 | $211.37 |\n| 2025-05-12 | $210.71 | $211.66 | $205.75 | $208.64 |\n\n**Important Notes:**\n\n*   **Data Limitations:** I am limited in my ability to access real-time or complete historical data. This information is based on the most recent data I could retrieve.\n*   **Date Range:** The data covers from May 12, 2025 to June 18, 2025.\n*   **Source:** The data is aggregated from publicly available sources.\n"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe second caveat is a lack of access to realtime data. Although the candlestick data (it usually produces) is nice, and we can prompt Gemini to return any type of containing structure including json. It also produces non-deterministic output for all stock symbols. Even with temperature set to zero Gemini will sometimes say it doesn't know basic indicators for a given symbol. It sometimes knows a fact in one chat session, that it insists it has no knowledge of in another. Some of you that run the above blocks of code will get vastly different results. Sometimes including the whole month of candlestick data.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Enter StockChat\n\n<span style=\"font-size:18px;\">\nStill, with a total of four prompts Gemini replaces all past effort on wrapping finance api's. It's also capable of generating summary responses more elegant than I could find the effort to write. Enter StockChat, the assistant that knows finance data. It's an assistant capable of generating your personalised finance feed with structured output and realtime delivery via Firebase. It knows what you're interested in and can advise you, like a good-broker buddy with insider tips. It has the spreadsheets but knows you don't want to see them. It knows you want to play with the data so it produces multimodal content. \n<hr>\nIn order to solve these problems we'll need to move beyond a basic chat session to a multi-tool approach. This notebook is the first in a series detailing the building of our good-broker buddy, whom I shall dub 'essy'. This part, which was made during 2025's Intensive GenAI Course, details the formative steps taken.\n</span> ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe main problem to address before starting is the state of multi-tool support in Gemini-2.0. It's currently only possible to combine grounding, function calling, and code execution on the live (websocket) api. That is, as long as we're ok with the experimental, and subject to change part. Clearly that's not an option for our Essy. We'll start with a multi-model approach. Each expert can be good at different parts of the problem. One such expert will use function calling to chain the models together. One expert to rule them all. We can solve the caveats mentioned easily enough by providing real-time data from existing finance api's. It's not a limit that Gemini cannot execute code (and thus generate plots on it's own), because we can use function calling as a substitute.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nWe can't have a knowledgeable Essy without a vector database to store our knowledge. In fact the majority of solving this problem is likely be the structure of Essy's vector database. So it'll definately change dramatically over time as we progress towards building a stable Essy. We'll use the popular Chroma and build a RAG expert to begin. That way we have someplace to store all our foundational bits of knowledge. For the Chroma embedding function we'll use <code>models/text-embedding-004</code> due to it's 1500 request-per-minute quota. We'll need to be mindful of the smaller 2,048 token input. Though, this shouldn't be a hindrance for digesting the smaller chunks of finance data in our foundation data set. For the augmented generation phase we'll use <code>models/gemini-2.0-flash</code> variants due to it's 1500 request-per-day quota.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## BaseModels","metadata":{}},{"cell_type":"code","source":"# Declare BaseModels using pydantic schema.\nclass RestStatus(Enum):\n    OK = \"OK\"\n    DELAY = \"DELAYED\"\n    NONE = \"NOT_FOUND\"\n    AUTH = \"NOT_AUTHORIZED\"\n\nclass StopGeneration(BaseModel):\n    result: str = Gemini.Const.Stop()\n\nclass RestResultPoly(BaseModel):\n    request_id: Optional[str] = None\n    count: Optional[int] = None\n    next_url: Optional[str] = None\n    status: RestStatus  \n\nclass MarketSession(Enum):\n    PRE = \"pre-market\"\n    REG = \"regular\"\n    POST = \"post-market\"\n    CLOSED = \"closed\"\n    NA = \"not applicable\"\n\nclass MarketEvent(Enum):\n    PRE_OPEN = 0\n    REG_OPEN = 1\n    REG_CLOSE = 2\n    POST_CLOSE = 3\n    LAST_CLOSE = 4\n\nclass AssetClass(Enum):\n    STOCKS = \"stocks\"\n    OPTION = \"options\"\n    CRYPTO = \"crypto\"\n    FOREX = \"fx\"\n    INDEX = \"indices\"\n    OTC = \"otc\"\n\nclass SymbolType(Enum):\n    COMMON = \"Common Stock\"\n    ETP = \"ETP\"\n    ADR = \"ADR\"\n    REIT = \"REIT\"\n    DELISTED = \"\"\n    CEF = \"Closed-End Fund\"\n    UNIT = \"Unit\"\n    RIGHT = \"Right\"\n    EQUITY = \"Equity WRT\"\n    GDR = \"GDR\"\n    PREF = \"Preference\"\n    CDI = \"CDI\"\n    NVDR = \"NVDR\"\n    REG = \"NY Reg Shrs\"\n    MLP = \"MLP\"\n    MUTUAL = \"Mutual Fund\"\n\nclass Locale(Enum):\n    US = \"us\"\n    GLOBAL = \"global\"\n\nclass Sentiment(Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    MIXED = \"mixed\"\n    NEGATIVE = \"negative\"\n\nclass Trend(Enum):\n    S_BUY = \"strong-buy\"\n    BUY = \"buy\"\n    HOLD = \"hold\"\n    SELL = \"sell\"\n    S_SELL = \"strong-sell\"\n\nclass MarketCondition(Enum):\n    BULL = \"bullish\"\n    HOLD = \"hold\"\n    BEAR = \"bearish\"\n\nclass GeneratedEvent(BaseModel):\n    last_close: str\n    pre_open: str\n    reg_open: str\n    reg_close: str\n    post_close: str\n    timestamp: Optional[str] = None\n    is_holiday: Optional[bool] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.timestamp is None:\n            self.timestamp = datetime.now(self.tz()).strftime('%c')\n        if self.is_holiday is None:\n            self.is_holiday = False\n\n    def session(self, with_date: Optional[str] = None) -> MarketSession:\n        if with_date is None:\n            with_date = datetime.now(self.tz()).strftime('%c')\n        compare = parse(with_date)\n        if self.is_holiday or compare.weekday() > 4: # weekend\n            return MarketSession.CLOSED\n        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n        if compare.time() < events[0]:\n            return MarketSession.CLOSED\n        else:\n            session = MarketSession.NA\n            if compare.time() >= events[0]:\n                session = MarketSession.PRE\n            if compare.time() >= events[1]:\n                session = MarketSession.REG\n            if compare.time() >= events[2]:\n                session = MarketSession.POST\n            if compare.time() >= events[3]:\n                session = MarketSession.CLOSED\n        return session\n\n    def is_open(self) -> bool:\n        return self.session() != MarketSession.CLOSED\n\n    def has_update(self) -> bool:\n        if datetime.now(self.tz()).day > parse(self.timestamp).day:\n            return True\n        return False\n\n    @classmethod\n    def tz(cls):\n        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    \n    @classmethod\n    def apply_fix(cls, value, fix: datetime) -> tuple[str, datetime]:\n        api.validation_fail()\n        value = fix.strftime('%c')\n        return value, fix\n    \n    @field_validator(\"last_close\")\n    def valid_close(cls, value):\n        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n        # Soft-pass: when actual session is closed after post-market\n        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n            date_fix = date_gen.replace(day=date_now.day)\n            if date_fix.timestamp() < date_now.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n        # Soft-pass: when actual session is open post-market\n        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n            if date_now.weekday() > 0:\n                date_fix = date_gen.replace(day=date_now.day-1)\n            else:\n                date_fix = date_gen.replace(day=date_now.day-3)\n            if date_now.timestamp() > date_fix.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n        if date_now.weekday() == 0 and date_gen.weekday() == 4: # 0=monday, 4=friday\n            return value # pass: generated friday on a monday\n        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() == date_now.weekday()-1:\n            return value # pass: generated yesterday on a tues-fri\n        elif date_now.weekday() > 4 and date_gen.weekday() == 4:\n            return value # pass: generated friday on a weekend\n        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n            return value # pass: generated today after closed\n        elif date_now.timestamp() < date_gen.timestamp():\n            raise ValueError(\"last close cannot be a future value\")\n        else:\n            raise ValueError(\"generated invalid last close\")\n        api.validation_fail()\n\nclass VectorStoreResult(BaseModel):\n    docs: str\n    dist: Optional[float] # requires query\n    meta: Optional[dict]  # requires get or query\n    store_id: str\n\nclass Aggregate(RestResultPoly):\n    symbol: str\n    open: float\n    high: float\n    low: float\n    close: float\n    volume: int\n    otc: Optional[bool] = None\n    preMarket: Optional[float] = None\n    afterHours: Optional[float] = None\n\nclass DailyCandle(Aggregate):\n    from_date: str\n\nclass AggregateWindow(BaseModel):\n    o: float\n    h: float\n    l: float\n    c: float\n    v: int # traded volume\n    n: Optional[int] = None # transaction count\n    vw: Optional[float] = None # volume weighted average price\n    otc: Optional[bool] = None\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        if len(str(value)) == 13:\n            return int(value/1000)\n        return value\n\nclass CustomCandle(RestResultPoly): \n    ticker: str\n    adjusted: bool\n    queryCount: int\n    resultsCount: int\n    results: list[AggregateWindow]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[AggregateWindow]:\n        return self.results\n    \nclass MarketStatus(BaseModel):\n    exchange: str\n    holiday: Optional[str] = None\n    isOpen: bool\n    session: Optional[MarketSession] = None\n    t: int\n    timezone: str\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.session is None:\n            self.session = MarketSession.CLOSED\n        if self.holiday is None:\n            self.holiday = MarketSession.NA.value\n\nclass MarketStatusResult(BaseModel):\n    results: MarketStatus\n\n    def get(self) -> MarketStatus:\n        return self.results\n\nclass Symbol(BaseModel):\n    description: str\n    displaySymbol: str\n    symbol: str\n    type: SymbolType\n\nclass SymbolResult(BaseModel):\n    count: int\n    result: list[Symbol]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.result)\n\n    def get(self) -> list[Symbol]:\n        return self.result\n\nclass Quote(BaseModel):\n    c: float\n    d: float\n    dp: float\n    h: float\n    l: float\n    o: float\n    pc: float\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        return value\n\nclass PeersResult(BaseModel):\n    results: list[str]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[str]:\n        return self.results\n\nclass BasicFinancials(BaseModel):\n    metric: dict\n    metricType: str\n    series: dict\n    symbol: str\n\nclass Insight(BaseModel):\n    sentiment: Sentiment|MarketCondition\n    sentiment_reasoning: str\n    ticker: str\n\nclass Publisher(BaseModel):\n    favicon_url: Optional[str]\n    homepage_url: str\n    logo_url: str\n    name: str\n\nclass NewsSummary(BaseModel):\n    title: str\n    summary: Optional[str]\n    insights: Optional[list[Insight]]\n    published_utc: str\n\nclass NewsTypePoly(BaseModel):\n    amp_url: Optional[str] = None\n    article_url: str\n    title: str\n    author: str\n    description: Optional[str] = None\n    id: str\n    image_url: Optional[str] = None\n    insights: Optional[list[Insight]] = None\n    keywords: Optional[list[str]] = None\n    published_utc: str\n    publisher: Publisher\n    tickers: list[str]\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.description,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass NewsResultPoly(RestResultPoly):\n    results: list[NewsTypePoly]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypePoly]:\n        return self.results\n\nclass NewsTypeFinn(BaseModel):\n    category: str\n    datetime: int\n    headline: str\n    id: int\n    image: str\n    related: str # symbol\n    source: str\n    summary: str\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.headline,\n                           summary=self.summary,\n                           insights=None,\n                           published_utc=self.datetime)\n\nclass NewsResultFinn(BaseModel):\n    results: list[NewsTypeFinn]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypeFinn]:\n        return self.results\n\nclass NewsTypeGenerated(BaseModel):\n    title: str\n    summary: str\n    insights: list[Insight]\n    keywords: list[str]\n    source: Publisher\n    published_utc: str\n    tickers: list[str]\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.summary,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass TickerOverview(BaseModel):\n    ticker: str\n    name: str\n    market: AssetClass\n    locale: Locale\n    primary_exchange: Optional[str] = None\n    active: bool\n    currency_name: str\n    cik: Optional[str] = None\n    composite_figi: Optional[str] = None\n    share_class_figi: Optional[str] = None\n    market_cap: Optional[int|float] = None\n    phone_number: Optional[str] = None\n    address: Optional[dict] = None\n    description: Optional[str] = None\n    sic_code: Optional[str] = None\n    sic_description: Optional[str] = None\n    ticker_root: Optional[str] = None\n    homepage_url: Optional[str] = None\n    total_employees: Optional[int] = None\n    list_date: Optional[str] = None\n    branding: Optional[dict] = None\n    share_class_shares_outstanding: Optional[int] = None\n    weighted_shares_outstanding: Optional[int] = None\n    round_lot: Optional[int] = None\n\nclass OverviewResult(RestResultPoly):\n    results: TickerOverview\n\n    def get(self) -> TickerOverview:\n        return self.results\n\nclass RecommendationTrend(BaseModel):\n    buy: int\n    hold: int\n    period: str\n    sell: int\n    strongBuy: int\n    strongSell: int\n    symbol: str\n\nclass TrendsResult(BaseModel):\n    results: list[RecommendationTrend]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[RecommendationTrend]:\n        return self.results","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:16.515002Z","iopub.execute_input":"2025-06-20T04:33:16.515191Z","iopub.status.idle":"2025-06-20T04:33:16.583001Z","shell.execute_reply.started":"2025-06-20T04:33:16.515174Z","shell.execute_reply":"2025-06-20T04:33:16.58216Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Retrieval-Augmented Generation Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Retrieval-Augmented Generation.\n# - using Chroma and text-embedding-004 for storage and retrieval\n# - using gemini-2.0-flash for augmented generation\nclass RetrievalAugmentedGenerator:\n    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n    exchange_codes: Optional[dict] = None\n    exchange_lists: dict = {}\n    events: dict = {}\n\n    def __init__(self, genai_client, collection_name):\n        self.client = genai_client\n        self.embed_fn = GeminiEmbedFunction(genai_client)\n        self.db = self.chroma_client.get_or_create_collection(\n            name=collection_name, \n            embedding_function=self.embed_fn, \n            metadata={\"hnsw:space\": \"cosine\"})\n        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n\n    def get_exchange_codes(self, with_query: Optional[str] = None):\n        gen = None\n        if with_query and with_query not in self.exchange_lists.keys():\n            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n            data = self.get_exchanges_csv(\n                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n                as a list in string form. Just the list string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\")\n            self.exchange_list[with_query] = ast.literal_eval(data.text)\n        elif with_query is None and self.exchange_codes is None:\n            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n            data = self.get_exchanges_csv(\n                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n                mapping exchange code to name. Just the dictionary string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\")\n            self.exchange_codes = ast.literal_eval(data.text.strip(r\"\\`\"))\n        if gen:\n            gen.update(1)\n        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n\n    def generate_event(self, exchange_code: str, event: MarketEvent = MarketEvent.LAST_CLOSE):\n        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n        if event is MarketEvent.LAST_CLOSE:\n            prompt = f\"\"\"Provide the most recent weekday's close including post_market hours.\"\"\"\n        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n            prompt = f\"\"\"Provide the next weekday's open {is_pre} pre_market hours.\"\"\"\n        elif event is MarketEvent.POST_CLOSE or event is MarketEvent.REG_CLOSE:\n            is_post = \"including\" if event is MarketEvent.POST_CLOSE else \"excluding\"\n            prompt = f\"\"\"Provide the next weekday's close {is_post} post_market hours.\"\"\"\n        response = self.get_exchanges_csv(\n            f\"\"\"Answer based on your knowledge of exchange operating hours.\n            Do not answer in full sentences. Omit all chat and provide the answer only.\n            The fields pre_market and post_market both represent extended operating hours.\n\n            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n\n            Weekdays are: Mon, Tue, Wed, Thu, Fri.\n            On weekdays all exchanges open after pre-market and regular hours.\n            On weekdays all exchanges close after regular and post-market hours.\n            \n            Weekends are: Sat, Sun.\n            Always exclude weekends from exchange operating hours.\n            Always exclude holidays from exchange operating hours.\n            \n            Consider the {exchange_code} exchange's operating hours.\n            {prompt}\n            \n            Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\").text\n        progress.update(1)\n        return response\n\n    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n            del self.events[exchange_code]\n            return self.generated_events(exchange_code)\n        elif exchange_code not in self.events.keys():\n            self.events[exchange_code] = GeneratedEvent(\n                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE)) \n        return self.events[exchange_code]\n\n    def set_holiday_event(self, exchange_code: str):\n        self.generated_events(exchange_code).is_holiday = True\n\n    def last_market_close(self, exchange_code: str):\n        return self.generated_events(exchange_code).last_close\n\n    def add_documents_list(self, docs: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n        content=[doc.page_content for doc in docs]\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n\n    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        splitter = RecursiveJsonSplitter(max_chunk_size=Gemini.Const.ChunkMax())\n        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        content = [json.dumps(doc.page_content) for doc in docs]\n        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n\n    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        peers = {\"symbol\": topic, \"peers\": names}\n        tqdm(self.db.add(ids=str(self.db.count()),\n                         documents=[json.dumps(peers)],\n                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n             desc=\"Generate peers embedding\")\n\n    def get_peers_document(self, query: str, topic: str, group: str):\n        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n\n    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n        self.embed_fn.document_mode = True # Switch to document mode\n        if ids is None:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n        if isinstance(chunks[0], BaseModel):\n            docs = [model.model_dump_json() for model in chunks]\n        else:\n            docs = [json.dumps(obj) for obj in chunks]\n        meta_base = {\"source\": source, \"topic\": topic}\n        if meta_opt is not None:\n            for m in meta_opt:\n                m.update(meta_base)\n        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n        if is_update:\n            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n        else:\n            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n\n    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n        self.embed_fn.document_mode = False # Switch to query mode.\n        stored = self.stored_result(self.db.get(where={\n            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n        if len(stored) == 0:\n            return stored, True\n        # Check for a daily market status update.\n        status = json.loads(stored[0].docs)\n        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n        store_day = parse(stored[0].meta['timestamp']).day\n        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n            return stored, False\n        elif gen_day > store_day:\n            return stored, True\n        # Update with generated events to avoid rest api requests.\n        status[\"session\"] = self.generated_events(exchange_code).session().value\n        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n        stored[0].docs = json.dumps(status)\n        return stored, False\n\n    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n        return self.get_documents_list(\n            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=[quote], \n                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n             desc=\"Generate quote embedding\")\n\n    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n                          meta_opt: Optional[list[dict]] = None):\n        where = [{\"source\": source}, {\"topic\": topic}]\n        if meta_opt is None:\n            return self.get_documents_list(query, where={\"$and\": where})\n        else:\n            for meta in meta_opt:\n                for k,v in meta.items():\n                    where.append({k: v})\n            return self.get_documents_list(query, where={\"$and\": where})\n\n    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_grounded_document(self, query: str, topic: str, result):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n        supports = result.candidates[0].grounding_metadata.grounding_supports\n        if supports is not None: # Only add grounded documents which have supports\n            grounded_text = [f\"{s.segment.text}\" for s in supports]\n            source = [f\"{c.web.title}\" for c in chunks]\n            score = [f\"{s.confidence_scores}\" for s in supports]\n            tqdm(self.db.add(ids=str(self.db.count()),\n                             documents=json.dumps(grounded_text),\n                             metadatas=[{\"source\": \", \".join(source),\n                                         \"confidence_score\": \", \".join(score),\n                                         \"topic\": topic,\n                                         \"question\": query}]),\n                 desc=\"Generate grounding embedding\")\n\n    def get_grounding_documents(self, query: str, topic: str):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n            \n    def add_wiki_documents(self, title: str, wiki_chunks: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        result = self.get_wiki_documents(title)\n        if len(result) == 0:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n    \n    def get_wiki_documents(self, title: Optional[str] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        if title is None:\n            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n        else:\n            return self.stored_result(self.db.get(where={\"title\": title}))\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(\n            self.db.query(query_texts=[query], \n                          n_results=max_sources, \n                          where=where), \n            is_query = True)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_exchanges_csv(self, query: str):\n        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_answer(self, query: str, max_sources: int = 10, \n                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n        stored = self.get_documents_list(query, max_sources, where)\n        query_oneline = query.replace(\"\\n\", \" \")\n        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n\n        QUESTION: {query_oneline}\n        \n        \"\"\"\n        # Add the retrieved documents to the prompt.\n        stored_docs = [passage.docs for passage in stored]\n        for passage in stored_docs if passages is None else stored_docs + passages:\n            passage_oneline = passage.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n    \n        return api.retriable(self.client.models.generate_content, \n                             model=api(Gemini.Model.GEN), \n                             config=self.config_temp, \n                             contents=prompt)\n\n    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n        try:\n            results = []\n            if len(result[\"documents\"]) == 0:\n                return results\n            if isinstance(result[\"documents\"][0], list):\n                for i in range(len(result[\"documents\"][0])):\n                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n                                            dist=result[\"distances\"][0][i] if is_query else None,\n                                            meta=result[\"metadatas\"][0][i],\n                                            store_id=result[\"ids\"][0][i])\n                    results.append(obj)\n            else:\n                results.append(\n                    VectorStoreResult(docs=result[\"documents\"][0],\n                                      dist=result[\"distances\"][0] if is_query else None,\n                                      meta=result[\"metadatas\"][0],\n                                      store_id=result[\"ids\"][0]))\n            return results\n        except Exception as e:\n            raise e","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:16.58401Z","iopub.execute_input":"2025-06-20T04:33:16.584322Z","iopub.status.idle":"2025-06-20T04:33:17.325768Z","shell.execute_reply.started":"2025-06-20T04:33:16.584299Z","shell.execute_reply":"2025-06-20T04:33:17.324915Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Wikipedia Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Wiki-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by similarity to topic\n# - retrieve existing groundings by similarity to topic\nclass WikiGroundingGenerator:   \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\") # suppress beta-warning\n            self.splitter = HTMLSemanticPreservingSplitter(\n                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n                max_chunk_size=Gemini.Const.ChunkMax(),\n                chunk_overlap=50,\n                preserve_links=True,\n                preserve_images=True,\n                preserve_videos=True,\n                preserve_audio=True,\n                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n                denylist_tags=[\"script\", \"style\", \"head\"],\n                custom_handlers={\"code\": self.code_handler},\n            )\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_wiki_documents(topic)\n        if len(stored) > 0:\n            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n        else:\n            pages = wikipedia.search(topic + \" company\")\n            if len(pages) > 0:\n                p_topic_match = 0.80\n                for i in range(len(pages)):\n                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n                            desc= \"Score wiki search by similarity to topic\"):\n                        request = requests.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n                        chunks = [chunk.page_content for chunk in self.splitter.split_text(request.text)]\n                        self.rag.add_wiki_documents(topic, chunks)\n                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n            return StopGeneration().result\n\n    def code_handler(self, element: Tag) -> str:\n        data_lang = element.get(\"data-lang\")\n        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n        return code_format","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:17.326783Z","iopub.execute_input":"2025-06-20T04:33:17.32704Z","iopub.status.idle":"2025-06-20T04:33:17.335641Z","shell.execute_reply.started":"2025-06-20T04:33:17.32702Z","shell.execute_reply":"2025-06-20T04:33:17.334756Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Google Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Search-Grounding Generation.\n# - using gemini-2.0-flash with GoogleSearch tool for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by exact match to topic\n# - retrieve existing groundings by similarity to topic\nclass SearchGroundingGenerator:\n    config_ground = types.GenerateContentConfig(\n        tools=[types.Tool(google_search=types.GoogleSearch())],\n        temperature=0.0\n    )\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_grounding_documents(query, topic)\n        if len(stored) > 0:\n            for i in range(len(stored)):\n                meta_q = stored[i].meta[\"question\"]\n                p_ground_match = 0.95 # This can be really high ~ 95-97%\n                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n                        desc=\"Score similarity to stored grounding\"):\n                    return ast.literal_eval(stored[i].docs)\n        return self.get_grounding(query, topic)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_grounding(self, query: str, topic: str):\n        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n        contents += f\"\"\"\n        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n        If an answer is not possible respond with: I don't know.\"\"\"\n        response = api.retriable(self.client.models.generate_content, \n                                 model=api(Gemini.Model.GEN), \n                                 config=self.config_ground, \n                                 contents=contents)\n        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n            if self.is_consistent(query, topic, response.text):\n                self.rag.add_grounded_document(query, topic, response)\n                return response.text \n        return StopGeneration().result # Empty grounding supports or not consistent in response\n\n    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n        topic = topic.replace(\"'\", \"\")\n        id_strs = topic.split()\n        if len(id_strs) == 1:\n            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n            if len(matches) > 0:\n                topic = matches\n        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n        model_response = model_response.replace(\"'\", \"\")\n        if len(compound_match) == 0 and topic in model_response:\n            return True # not a compound topic id and exact topic match\n        for match in compound_match:\n            if topic not in match:\n                return False\n        return True # all prefix matches contained topic","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:17.336657Z","iopub.execute_input":"2025-06-20T04:33:17.336989Z","iopub.status.idle":"2025-06-20T04:33:17.476889Z","shell.execute_reply.started":"2025-06-20T04:33:17.336962Z","shell.execute_reply":"2025-06-20T04:33:17.476116Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Rest API Tool and Helpers","metadata":{}},{"cell_type":"code","source":"# Rest api-helpers to manage request-per-minute limits.\n# - define an entry for each endpoint limit\n# - init rest tool with limits to create blocking queues\n# - apply a limit to requests with rest_tool.try_url\nclass ApiLimit(Enum):\n    FINN = \"finnhub.io\",60\n    POLY = \"polygon.io\",5 # (id_url,rpm)\n\nclass BlockingUrlQueue:\n    on_cooldown = False\n    cooldown = None\n    cooldown_start = None\n    \n    def __init__(self, rest_fn: Callable, per_minute: int):\n        self.per_minute_max = per_minute\n        self.quota = per_minute\n        self.rest_fn = rest_fn\n\n    def push(self, rest_url: str):\n        if not self.on_cooldown:\n            self.cooldown = Timer(60, self.reset_quota)\n            self.cooldown.start()\n            self.cooldown_start = time.time()\n            self.on_cooldown = True\n        if self.quota > 0:\n            self.quota -= 1\n            time.sleep(0.034) # ~30 requests per second\n            return self.rest_fn(rest_url)\n        else:\n            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n            time.sleep(max(self.limit_expiry(),0.5))\n            return self.push(rest_url)\n\n    def reset_quota(self):\n        self.quota = self.per_minute_max\n        self.on_cooldown = False\n        self.cooldown_start = None\n\n    def limit_expiry(self):\n        if self.cooldown_start:\n            return max(60-(time.time()-self.cooldown_start),0)\n        return 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:33:17.477851Z","iopub.execute_input":"2025-06-20T04:33:17.478163Z","iopub.status.idle":"2025-06-20T04:33:17.496436Z","shell.execute_reply.started":"2025-06-20T04:33:17.47814Z","shell.execute_reply":"2025-06-20T04:33:17.495641Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# An implementation of Rest-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - reduce long-context by chunked pre-processing\nclass RestGroundingGenerator:    \n    limits = None\n\n    def __init__(self, rag_impl, with_limits: bool):\n        self.rag = rag_impl\n        if with_limits:\n            self.limits = {}\n            for rest_api in ApiLimit:\n                self.limits[rest_api.value[0]] = BlockingUrlQueue(self.get, rest_api.value[1])\n\n    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n        return self.limits[rest_api.value[0]] if self.limits else None\n\n    def get(self, url: str) -> Optional[str]:\n        try:\n            request = requests.get(url)\n            if request.status_code != requests.codes.ok:\n                print(f\"the endpoint returned status {request.status_code}\")\n            return request.text\n        except Exception as e:\n            raise e\n\n    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n        try:\n            if from_lambda:\n                return schema(results=json.loads(data))\n            return schema.model_validate_json(data)\n        except Exception as e:\n            raise e\n\n    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n        try:\n            candle = json.loads(data)\n            if \"from\" not in candle:\n                raise ValueError(\"not a dailycandle / missing value for date\")\n            agg = self.basemodel(data, Aggregate)\n            return DailyCandle(from_date=candle[\"from\"], \n                               status=agg.status.value, \n                               symbol=agg.symbol, \n                               open=agg.open, \n                               high=agg.high, \n                               low=agg.low, \n                               close=agg.close, \n                               volume=agg.volume, \n                               otc=agg.otc, \n                               preMarket=agg.preMarket, \n                               afterHours=agg.afterHours)\n        except Exception as e:\n            raise e\n\n    @retry.Retry(timeout=600)\n    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n                success_fn: Callable, *args, **kwargs):\n        try:\n            if self.limits is None:\n                data = self.get(url)\n            elif with_limit:\n                data = with_limit.push(url)\n            if schema is DailyCandle:\n                model = self.dailycandle(data)\n            else:\n                model = self.basemodel(data, schema, as_lambda)\n        except Exception as e:\n            try:\n                print(f\"try_url exception: {e}\")\n                if issubclass(schema, RestResultPoly):\n                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n            except Exception as not_a_result:\n                print(not_a_result)\n            return StopGeneration()\n        else:\n            return success_fn(*args, **kwargs, model=model)\n\n    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n        matches = []\n        max_failed_match = model.count if not by_name else 3\n        p_desc_match = 0.80\n        p_symb_match = 0.95\n        if model.count > 0:\n            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n                if max_failed_match > 0:\n                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n                    symb = [with_content[\"q\"].upper(), obj.symbol]\n                    if by_name and api.similarity(desc) > p_desc_match: \n                        matches.append(obj.symbol)\n                    elif not by_name and api.similarity(symb) > p_symb_match:\n                        matches.append(obj.description)\n                        max_failed_match = 0\n                    else:\n                        max_failed_match -= 1\n        if len(matches) > 0:\n            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n            return matches\n        return StopGeneration().result\n\n    def get_quote(self, with_content, model: Quote):\n        quote = model.model_dump_json()\n        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n        return quote\n\n    def parse_financials(self, with_content, model: BasicFinancials):\n        metric = list(model.metric.items())\n        chunks = []\n        # Chunk the metric data.\n        for i in range(0, len(metric), Gemini.Const.MetricBatch()):\n            batch = metric[i:i + Gemini.Const.MetricBatch()]\n            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n        # Chunk the series data.\n        for key in model.series.keys():\n            series = list(model.series[key].items())\n            for s in series:\n                if api.token_count(s) <= Gemini.Const.ChunkMax():\n                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n                else:\n                    k = s[0]\n                    v = s[1]\n                    for i in range(0, len(v), Gemini.Const.SeriesBatch()):\n                        batch = v[i:i + Gemini.Const.SeriesBatch()]\n                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n        return chunks\n\n    def parse_news(self, with_content, model: NewsResultFinn):\n        if model.count > 0:\n            metas = []\n            for digest in model.get():\n                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": digest.source,\n                              \"published_est\": parse(pub_date).timestamp(),\n                              \"news_id\": digest.id,\n                              \"related\": digest.related})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [digest.summary().model_dump_json() for digest in model.get()]\n        return StopGeneration().result\n\n    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = []\n            for news in model.get():\n                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": news.publisher.name,\n                              \"published_utc\": parse(pub_date).timestamp(),\n                              \"news_id\": news.id,\n                              \"related\": json.dumps(news.tickers),\n                              \"keywords\": json.dumps(news.keywords)})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n                                     ids=[news.id for news in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n        elif result:\n            return result.model_dump_json()\n\n    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n                           result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            self.rag.add_rest_chunks(\n                chunks=[model],\n                topic=with_content[\"stocksTicker\"],\n                source=\"daily_candle_2\",\n                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n            return model\n        elif result:\n            return result\n\n    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n                            result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = [{\n                \"timespan\": with_content[\"timespan\"],\n                \"adjusted\": with_content[\"adjusted\"],\n                \"from\": with_content[\"from\"],\n                \"to\": with_content[\"to\"]}]*model.count\n            candles = [candle.model_dump_json() for candle in model.get()]\n            self.rag.add_rest_chunks(\n                chunks=candles,\n                topic=with_content[\"stocksTicker\"],\n                source=\"custom_candle_2\",\n                meta_opt=metas)\n            return candles\n        elif result:\n            return result.model_dump_json()\n\n    def parse_overview(self, with_content, model: OverviewResult):\n        overview = [model.get().model_dump_json()]\n        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n        return overview\n\n    def parse_trends(self, with_content, model: TrendsResult):\n        if model.count > 0:\n            metas = [{\"period\": trend.period} for trend in model.get()]\n            trends = [trend.model_dump_json() for trend in model.get()]\n            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n            return trends\n        return StopGeneration().result\n\n    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n        if model.get().holiday != MarketSession.NA.value:\n            self.rag.set_holiday_event(model.get().exchange)\n        events = self.rag.generated_events(model.get().exchange)\n        model.get().session = events.session()\n        model.get().isOpen = events.is_open()\n        meta = {\"exchange\": model.get().exchange,\n                \"last_close\": events.last_close,\n                \"pre_open\": events.pre_open,\n                \"reg_open\": events.reg_open,\n                \"reg_close\": events.reg_close,\n                \"post_close\": events.post_close,\n                \"timestamp\": events.timestamp }\n        self.rag.add_rest_chunks([model.get()],\n                                 topic=\"market_status\",\n                                 source=\"get_market_status_1\",\n                                 ids=[with_id] if with_id else None,\n                                 meta_opt=[meta])\n        return model.get().model_dump_json()\n\n    def get_symbol(self, content, by_name: bool = True):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=SymbolResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_symbol_matches,\n            with_content=content,\n            by_name=by_name)\n\n    def get_current_price(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=Quote,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_quote,\n            with_content=content)\n\n    def get_market_status(self, content, store_id: Optional[str] = None):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=MarketStatusResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.augment_market_status,\n            with_id=store_id)\n\n    def get_peers(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n            schema=PeersResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=lambda model: model)\n\n    def get_basic_financials(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n            schema=BasicFinancials,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_financials,\n            with_content=content)\n\n    def get_news_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n            schema=NewsResultFinn,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_news,\n            with_content=content)\n\n    def get_news_tagged(self, content):\n        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n        news = []\n        while True:\n            news_list, next_url = self.try_url(\n                next_url,\n                schema=NewsResultPoly,\n                as_lambda=False,\n                with_limit=self.get_limit(ApiLimit.POLY),\n                success_fn=self.parse_news,\n                with_content=content)\n            news += news_list\n            if next_url is None:\n                break\n            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n        return news\n\n    def get_daily_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n            schema=DailyCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_daily_candle,\n            with_content=content)\n\n    def get_custom_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n            schema=CustomCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_custom_candle,\n            with_content=content)\n\n    def get_overview(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n            schema=OverviewResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_overview,\n            with_content=content)\n\n    def get_trends_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=TrendsResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_trends,\n            with_content=content)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:17.497342Z","iopub.execute_input":"2025-06-20T04:33:17.497651Z","iopub.status.idle":"2025-06-20T04:33:17.536479Z","shell.execute_reply.started":"2025-06-20T04:33:17.49763Z","shell.execute_reply":"2025-06-20T04:33:17.535605Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# Instantiate the Tools\n\n<span style=\"font-size:18px;\">\nLet's load some test data and see what the RAG can do. The test data is a CSV file containing stock market exchange data. It includes the market id code, name, locale, and operating hours. The import will use CSVLoader from <code>langchain-community</code> to parse the exchange data into Documents that our RAG can ingest.\n</span>","metadata":{}},{"cell_type":"code","source":"# Instantiate tools and load the exchange data from source csv.\n# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n# - Also maps the exchange code to exchange details.\ntry:\n    df = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\")\nexcept FileNotFoundError as e:\n    df = pandas.read_csv(\"exchanges_src.csv\") # local run\ndf = df.drop([\"close_date\"], axis=1).fillna(\"\")\ndf.to_csv(\"exchanges.csv\", index=False)\nexchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n\n# Prepare a RAG tool for use and add the exchange data.\ntool_rag = RetrievalAugmentedGenerator(api.client, \"finance\")\ntool_rag.add_documents_list(exchanges)\n\n# Prepare a the grounding tools for use.\ntool_wiki = WikiGroundingGenerator(api.client, tool_rag)\ntool_ground = SearchGroundingGenerator(api.client, tool_rag)\ntool_rest = RestGroundingGenerator(tool_rag, with_limits=True)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:17.53725Z","iopub.execute_input":"2025-06-20T04:33:17.537495Z","iopub.status.idle":"2025-06-20T04:33:18.509164Z","shell.execute_reply.started":"2025-06-20T04:33:17.537475Z","shell.execute_reply":"2025-06-20T04:33:18.508446Z"}},"outputs":[{"name":"stderr","text":"Generate document embedding: 0it [00:00, ?it/s]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nNow that the data is loaded lets ask our RAG to perform some augmenting. We can ask it to perform all sorts of useful tasks. We'll generate some useful reusable data structures and check to make sure it can answer important questions. The exchanges all have id's which are used to filter the realtime data. So we'll make sure the RAG know how to create this mapping. We'll also check it's awareness of operating hours. After all, Essy, doesn't mindlessly hammer away at api's when no new data is available.\n</span>","metadata":{}},{"cell_type":"code","source":"# The RAG tool is a helpful expert.\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n    exchange code to name. Just the dictionary string in pretty form.\"\"\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n    comma separated value that I can copy.\"\"\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\nprint(response.text)\n\nresponse = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\n    f\"\"\"Answer based on your knowledge of exchange operating hours.\n    Do not answer in full sentences. Omit all chat and provide the answer only.\n    All exchanges are open on weekdays. Weekdays are: Mon, Tue, Wed, Thu, Fri. Open/Close happens on weekdays.\n    All exchanges are closed on weekends. Weekends are: Sat, Sun. No Open/Close happens on weekends.\n    The fields pre_market and post_market both represent open hours.\n    \n    The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n    \n    When was the US exchange's last operating hours? Provide the last weekday's close. Include any post-market hours.\n    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:33:18.509842Z","iopub.execute_input":"2025-06-20T04:33:18.510096Z","iopub.status.idle":"2025-06-20T04:33:28.568315Z","shell.execute_reply.started":"2025-06-20T04:33:18.51008Z","shell.execute_reply":"2025-06-20T04:33:28.567558Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"```\n{\n    \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n    \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n    \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n    \"DB\": \"DUBAI FINANCIAL MARKET\",\n    \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n    \"QA\": \"QATAR EXCHANGE\",\n    \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n    \"SW\": \"SWISS EXCHANGE\",\n    \"DU\": \"BOERSE DUESSELDORF\",\n    \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n    \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n    \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n    \"SI\": \"SINGAPORE EXCHANGE\",\n    \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n    \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n    \"L\": \"LONDON STOCK EXCHANGE\",\n    \"ME\": \"MOSCOW EXCHANGE\",\n    \"TO\": \"TORONTO STOCK EXCHANGE\",\n    \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n    \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n    \"US\": \"US exchanges (NYSE, Nasdaq)\",\n    \"TW\": \"TAIWAN STOCK EXCHANGE\",\n    \"JK\": \"INDONESIA STOCK EXCHANGE\",\n    \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n    \"VS\": \"NASDAQ OMX VILNIUS\",\n    \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n    \"DE\": \"XETRA\",\n    \"PR\": \"PRAGUE STOCK EXCHANGE\",\n    \"BK\": \"STOCK EXCHANGE OF THAILAND\",\n    \"VI\": \"Vienna Stock Exchange\",\n    \"MU\": \"BOERSE MUENCHEN\",\n    \"KL\": \"BURSA MALAYSIA\",\n    \"BE\": \"BOERSE BERLIN\",\n    \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n    \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n    \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n    \"PM\": \"Philippine Stock Exchange\",\n    \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n    \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n    \"IC\": \"NASDAQ OMX ICELAND\",\n    \"SG\": \"BOERSE STUTTGART\",\n    \"MC\": \"BOLSA DE MADRID\",\n    \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n    \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n    \"CR\": \"CARACAS STOCK EXCHANGE\",\n    \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n    \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n    \"IS\": \"BORSA ISTANBUL\",\n    \"AX\": \"ASX - ALL MARKETS\",\n    \"KW\": \"Kuwait Stock Exchange\",\n    \"NE\": \"AEQUITAS NEO EXCHANGE\",\n    \"SR\": \"SAUDI STOCK EXCHANGE\",\n    \"F\": \"DEUTSCHE BOERSE AG\",\n    \"SA\": \"Brazil Bolsa - Sao Paolo\",\n    \"CA\": \"Egyptian Stock Exchange\",\n    \"MT\": \"MALTA STOCK EXCHANGE\",\n    \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n    \"HA\": \"Hanover Stock Exchange\",\n    \"BH\": \"BAHRAIN BOURSE\",\n    \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n    \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n    \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n    \"MI\": \"Italian Stock Exchange\",\n    \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n    \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n    \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n    \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n    \"OL\": \"OSLO BORS ASA\",\n    \"TL\": \"NASDAQ OMX TALLINN\",\n    \"TWO\": \"TPEx\",\n    \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n    \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n    \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n    \"BO\": \"BSE LTD\",\n    \"RG\": \"NASDAQ OMX RIGA\",\n    \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n    \"NL\": \"Nigerian Stock Exchange\"\n}\n```\nBE, SX, TG, DE, DU, F, MU, SG, SC, HM, HA\n \n\nThe Germany exchanges and their corresponding codes are: BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), XETRA (DE), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), DEUTSCHE BOERSE AG (F), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE STUTTGART (SG), Hanover Stock Exchange (HA), DEUTSCHE BOERSE TradeGate (TG), and BOERSE_FRANKFURT_ZERTIFIKATE (SC).\n \n\nI don't know.\n\nI don't know.\n\nIn the United States, pre-market trading hours are from 04:00 to 09:30, regular trading hours are from 09:30 to 16:00, and post-market trading hours are from 16:00 to 20:00, all in the America/New_York time zone. These hours apply to exchanges such as NYSE and Nasdaq.\n \n\nThu Jun 19 20:00:00 2025\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nExcellent! Though, despite my best effort I could not convince Gemini to apply date correction (during chaining) based on holiday. It simply wasn't stable enough to be useful. I would either have to add a holiday data set, or (what I chose) apply a quick temporary fix. A real-time API endpoint may fail due to a holiday being selected as the date. If that happens I'll just retry Thursday if the failure happened on Friday, likewise choosing Friday if the failure happened on Monday. Crude but simple for foundational purposes.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Declaring the Function Calling Metadata\n\n<span style=\"font-size:18px;\">\nOur Function Calling expert will chain together the other experts we've implemented thus far. It also provides the final response through augmentation. This time using the tools as a source of grounding truth. It'd like to say it's all truth organised by topic and other metadata. It's still a precarious situation if Essy incidently chains into mining data on another topic. We want Amazon to be the owner of MGM Studio's not MGM Resorts International. We also don't want a summary to include another company unless that company is a peer.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe function calling metadata is thus extremely important. It needs to combine our other experts with the real-time api's data. Essy will use two API providers as sources of finance data. The primary motivation being that each provider has limits in their own way, yet both are useful in their own own way. This is useful anywhere you need a broad spectrum of sources of truth. At metadata creation I'll adopt the naming convention of appending the provider (if any) id. This helps keep functions more understandable when you know which provider you're dealing with.\n</span>","metadata":{}},{"cell_type":"code","source":"# Declare callable functions using OpenAPI schema.\ndecl_get_symbol_1 = types.FunctionDeclaration(\n    name=\"get_symbol_1\",\n    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n                   calling get_wiki_tool_response next.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_symbols_1 = types.FunctionDeclaration(\n    name=\"get_symbols_1\",\n    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"exchange\", \"query\"]\n    }\n)\n\ndecl_get_name_1 = types.FunctionDeclaration(\n    name=\"get_name_1\",\n    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"company\": {\n                \"type\": \"string\",\n                \"description\": \"The company you're searching for.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n    }\n)\n\ndecl_get_symbol_quote_1 = types.FunctionDeclaration(\n    name=\"get_symbol_quote_1\",\n    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n                   provided in json format. Each response contains the following key-value pairs:\n                   \n                   c: Current price,\n                   d: Change,\n                  dp: Percent change,\n                   h: High price of the day,\n                   l: Low price of the day,\n                   o: Open price of the day,\n                  pc: Previous close price,\n                   t: Epoch timestamp of price in seconds.\n\n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\", \"exchange\"]\n    }\n)\n\ndecl_get_local_datetime = types.FunctionDeclaration(\n    name=\"get_local_datetime\",\n    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n                   function to format date and time in your responses.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"t\": {\n                \"type\": \"array\",\n                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n                                  timestamps matches the order of conversion.\"\"\",\n                \"items\": {\n                    \"type\": \"integer\"\n                }\n            }\n        },\n        \"required\": [\"t\"]\n    }\n)\n\ndecl_get_market_status_1 = types.FunctionDeclaration(\n    name=\"get_market_status_1\",\n    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n                   Also includes holiday details if applicable. The response is provided in json format. Each response \n                   contains the following key-value pairs:\n\n                   exchange: Exchange code,\n                   timezone: Timezone of the exchange,\n                    holiday: Holiday event name, or null if it's not a holiday,\n                     isOpen: Whether the market is open at the moment,\n                          t: Epoch timestamp of status in seconds (Eastern Time),\n                    session: The market session can be 1 of the following values: \n                    \n                    pre-market,regular,post-market when open, or null if closed.\n                    \n                    Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_market_session_1 = types.FunctionDeclaration(\n    name=\"get_market_session_1\",\n    description=\"Get the current market session of global exchanges.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_company_peers_1 = types.FunctionDeclaration(\n    name=\"get_company_peers_1\",\n    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n                   \n                   symbol: The company's stock ticker symbol, \n                   peers: A list containing the peers.\n                   \n                   Each peers entry contains the following key-value pairs:\n                   \n                   symbol: The peer company's stock ticker symbol, \n                   name: The peer company's name.\n                   \n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n            },\n            \"grouping\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n                                  Always use subIndustry unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_exchange_codes_1 = types.FunctionDeclaration(\n    name=\"get_exchange_codes_1\",\n    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n)\n\ndecl_get_exchange_code_1 = types.FunctionDeclaration(\n    name=\"get_exchange_code_1\",\n    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n                   more exchange codes provided as a comma-separated string value.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"Specifies which exchange code to search for.\"\n            }\n        },\n        \"required\": [\"q\"]\n    }\n)\n\ndecl_get_financials_1 = types.FunctionDeclaration(\n    name=\"get_financials_1\",\n    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"metric\": {\n                \"type\": \"string\",\n                \"description\": \"It must always be declared as the value 'all'\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"metric\", \"query\"]\n    }\n)\n\ndecl_get_daily_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_daily_candlestick_2\",\n    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n                   volume and pre-market/after-hours trade prices. It does not provide today's data until after \n                   11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"date\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n    },\n)\n\ndecl_get_company_news_1 = types.FunctionDeclaration(\n    name=\"get_company_news_1\",\n    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\",\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n                                  default value is today's date.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n    },\n)\n\ndecl_get_custom_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_custom_candlestick_2\",\n    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n                   includes historical daily trade volume and pre-market/after-hours trade prices. It does not\n                   include today's open, high, low, or close until after 11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"multiplier\": {\n                \"type\": \"integer\",\n                \"description\": \"This must be 1 unless told otherwise.\"\n            },\n            \"timespan\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n                                  default is one weekday before get_last_market_close.\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be one of asc or desc. asc will sort by timestmap in ascending order. desc will\n                                  sort by timestamp in descending order.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n                                  unless told to limit base aggregates to something else.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n    },\n)\n\ndecl_get_last_market_close = types.FunctionDeclaration(\n    name=\"get_last_market_close\",\n    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_ticker_overview_2 = types.FunctionDeclaration(\n    name=\"get_ticker_overview_2\",\n    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a company’s \n    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n    the form of icons and logos.\n    \"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol of a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"query\"]\n    }\n)\n\ndecl_get_recommendation_trends_1 = types.FunctionDeclaration(\n    name=\"get_recommendation_trends_1\",\n    description=\"\"\"Get the latest analyst recommendation trends for a company.\n                The data includes the latest recommendations as well as historical\n                recommendation data for each month. The data is classified according\n                to these categories: strongBuy, buy, hold, sell, and strongSell.\n                The date of a recommendation indicated by the value of 'period'.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\"]\n    }\n)\n\ndecl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n    name=\"get_news_with_sentiment_2\",\n    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n                   comprehensive coverage. Including a summary, publisher information, article metadata, \n                   and sentiment analysis.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"published_utc.gte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n                                  The default value is one-month ago from today's date.\"\"\"\n            },\n            \"published_utc.lte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"order\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n                                  When order is not specified the default is descending order.\n                                  Ordering will be based on the parameter 'sort'.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"This must be 1000 unless told to limit news results to something else.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The sort field used for ordering. This value must\n                                  always be published_utc.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"limit\", \"sort\", \"query\"]\n    }\n)\n\ndecl_get_rag_tool_response = types.FunctionDeclaration(\n    name=\"get_rag_tool_response\",\n    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"question\": {\n                \"type\": \"string\",\n                \"description\": \"A question needing an answer. Asked as a simple string.\"\n            }\n        }\n    }\n)\n\ndecl_get_wiki_tool_response = types.FunctionDeclaration(\n    name=\"get_wiki_tool_response\",\n    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n                   product, or service. Each web page includes detailed company information, financial indicators, \n                   tickers, symbols, history, and products and services.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. Just the name and no other details.\"\n            },\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The complete, unaltered, query string.\"\n            }\n        },\n        \"required\": [\"id\", \"q\"]\n    }\n)\n\ndecl_get_search_tool_response = types.FunctionDeclaration(\n    name=\"get_search_tool_response\",\n    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The question needing an answer. Asked as a simple string.\"\n            },\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n            }\n        },\n        \"required\": [\"q\", \"id\"]\n    }\n)","metadata":{"trusted":true,"_kg_hide-input":false,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:28.56941Z","iopub.execute_input":"2025-06-20T04:33:28.569661Z","iopub.status.idle":"2025-06-20T04:33:28.597987Z","shell.execute_reply.started":"2025-06-20T04:33:28.569645Z","shell.execute_reply":"2025-06-20T04:33:28.597215Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Implementing the Function Calling Expert\n\n<span style=\"font-size:18px;\">\nOne downside of this part being the main part was the lack of time to refactor this part more. Our formative Essy implements as much useful data from two finacial APIs. In order to use it you will need to declare secrets for <a class=\"anchor-link\" href=\"https://finnhub.io/dashboard\">Finnhub</a> and <a class=\"anchor-link\" href=\"https://polygon.io/dashboard\">Polygon</a> finance APIs. Register at their respective sites for your free API key. Then import the secret using the same method as how you setup Google's API key.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## Callable Functions and Handler","metadata":{}},{"cell_type":"code","source":"# Implement the callable functions and the function handler.\n\ndef ask_rag_tool(content):\n    return tool_rag.generate_answer(content[\"question\"]).text\n\ndef ask_wiki_tool(content):\n    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n\ndef ask_search_tool(content):\n    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n\ndef get_exchange_codes_1(content):\n    return tool_rag.get_exchange_codes()\n\ndef get_exchange_code_1(content):\n    return tool_rag.get_exchange_codes(with_query=content)\n    \ndef last_market_close(content):\n    return tool_rag.last_market_close(content[\"exchange\"])\n    \ndef get_symbol_1(content, by_name: bool = True):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n    if len(stored) == 0:\n        return tool_rest.get_symbol(content, by_name)\n    return json.loads(stored[0].docs)\n\ndef get_symbols_1(content):\n    return None # todo\n\ndef get_name_1(content):\n    return get_symbol_1(content, by_name = False)\n\ndef get_quote_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n        return get_current_price_1(content)\n    elif len(stored) > 0:\n        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n        for quote in stored:\n            if quote.meta[\"timestamp\"] >= last_close:\n                return [quote.docs for quote in stored]\n    return get_current_price_1(content)\n\ndef get_current_price_1(content):\n    return tool_rest.get_current_price(content)\n\ndef get_market_status_1(content):\n    stored, has_update = tool_rag.get_market_status(content['exchange'])\n    if has_update:\n        with_id = stored[0].store_id if len(stored) > 0 else None\n        return tool_rest.get_market_status(content, with_id)\n    return stored[0].docs\n\ndef get_session_1(content):\n    return json.loads(get_market_status_1(content))[\"session\"]\n\ndef get_peers_1(content):\n    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n    if len(stored) == 0:\n        peers = tool_rest.get_peers(content)\n        if peers.count > 0:\n            names = []\n            for peer in peers.get():\n                if peer == content[\"symbol\"]:\n                    continue # skip including the query symbol in peers\n                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n                if name != StopGeneration().result:\n                    data = {\"symbol\": peer, \"name\": name}\n                    names.append(data)\n            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n            return names\n        return StopGeneration().result\n    return json.loads(stored[0].docs)[\"peers\"]\n\ndef local_datetime(content):\n    local_t = []\n    for timestamp in content[\"t\"]:\n        local_t.append(local_date_from_epoch(timestamp))\n    return local_t\n\ndef local_date_from_epoch(timestamp):\n    if len(str(timestamp)) == 13:\n        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n    else:\n        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n\ndef get_financials_1(content):\n    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n    if len(stored) == 0:\n        return tool_rest.get_basic_financials(content)\n    return [chunk.docs for chunk in stored]\n\ndef get_news_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n    if len(stored) == 0:\n        return tool_rest.get_news_simple(content)\n    return [NewsTypeFinn.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n\ndef get_daily_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n    if len(stored) == 0:\n        candle = tool_rest.get_daily_candle(content)\n        # Attempt to recover from choosing a holiday.\n        candle_date = parse(content[\"date\"])\n        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n            else:\n                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n            return get_daily_candle_2(content)\n        return candle.model_dump_json()\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_custom_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n        meta_opt=[{\n            \"timespan\": content[\"timespan\"],\n            \"adjusted\": content[\"adjusted\"],\n            \"from\": content[\"from\"],\n            \"to\": content[\"to\"]}])\n    if len(stored) == 0:\n        return tool_rest.get_custom_candle(content)\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_overview_2(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n    if len(stored) == 0:\n        return tool_rest.get_overview(content)\n    return json.loads(stored[0].docs)\n\ndef get_trends_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n    if len(stored) == 0:\n        return tool_rest.get_trends_simple(content)\n    return [json.loads(trend.docs) for trend in stored]\n\ndef get_news_2(content):\n    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n    news_from = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n    news_to = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n    if len(news_from) > 0 and len(news_to) > 0:\n        stored = tool_rag.get_api_documents(\n            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n            [{\"published_utc\": {\"$gte\": timestamp_from}},\n             {\"published_utc\": {\"$lte\": timestamp_to}}])\n        return [NewsTypePoly.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n    return tool_rest.get_news_tagged(content)\n        \nfinance_tool = types.Tool(\n    function_declarations=[\n        decl_get_symbol_1,\n        decl_get_symbols_1,\n        decl_get_name_1,\n        decl_get_symbol_quote_1,\n        decl_get_market_status_1,\n        decl_get_market_session_1,\n        decl_get_company_peers_1,\n        decl_get_local_datetime,\n        decl_get_last_market_close,\n        decl_get_exchange_codes_1,\n        decl_get_exchange_code_1,\n        decl_get_financials_1,\n        decl_get_daily_candlestick_2,\n        decl_get_custom_candlestick_2,\n        decl_get_ticker_overview_2,\n        decl_get_recommendation_trends_1,\n        decl_get_news_with_sentiment_2,\n        decl_get_rag_tool_response,\n        decl_get_wiki_tool_response,\n        decl_get_search_tool_response\n    ]\n)\n\nfunction_handler = {\n    \"get_symbol_1\": get_symbol_1,\n    \"get_symbols_1\": get_symbols_1,\n    \"get_name_1\": get_name_1,\n    \"get_symbol_quote_1\": get_quote_1,\n    \"get_market_status_1\": get_market_status_1,\n    \"get_market_session_1\": get_session_1,\n    \"get_company_peers_1\": get_peers_1,\n    \"get_local_datetime\": local_datetime,\n    \"get_last_market_close\": last_market_close,\n    \"get_exchange_codes_1\": get_exchange_codes_1,\n    \"get_exchange_code_1\": get_exchange_code_1,\n    \"get_financials_1\": get_financials_1,\n    \"get_daily_candlestick_2\": get_daily_candle_2,\n    \"get_custom_candlestick_2\": get_custom_candle_2,\n    \"get_ticker_overview_2\": get_overview_2,\n    \"get_recommendation_trends_1\": get_trends_1,\n    \"get_news_with_sentiment_2\": get_news_2,\n    \"get_rag_tool_response\": ask_rag_tool,\n    \"get_wiki_tool_response\": ask_wiki_tool,\n    \"get_search_tool_response\": ask_search_tool\n}","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:28.598975Z","iopub.execute_input":"2025-06-20T04:33:28.599193Z","iopub.status.idle":"2025-06-20T04:33:28.625842Z","shell.execute_reply.started":"2025-06-20T04:33:28.599172Z","shell.execute_reply":"2025-06-20T04:33:28.624903Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Define the System Prompt","metadata":{}},{"cell_type":"code","source":"# Define the system prompt.\n\ninstruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \nOnly answer the question asked and do not change topic. While the answer is still\nunknown you must follow these rules for predicting function call order:\n\nRULE#1: Always consult your other functions before get_search_tool_response.\nRULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\nRULE#3: Always consult get_search_tool_response last.\nRULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\nRULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:28.627299Z","iopub.execute_input":"2025-06-20T04:33:28.627648Z","iopub.status.idle":"2025-06-20T04:33:28.645018Z","shell.execute_reply.started":"2025-06-20T04:33:28.627616Z","shell.execute_reply":"2025-06-20T04:33:28.6441Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## Import the Rest API Keys","metadata":{}},{"cell_type":"code","source":"# Import the finance api secret keys.\n\nPOLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\nFINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:28.645881Z","iopub.execute_input":"2025-06-20T04:33:28.646219Z","iopub.status.idle":"2025-06-20T04:33:28.976071Z","shell.execute_reply.started":"2025-06-20T04:33:28.646157Z","shell.execute_reply":"2025-06-20T04:33:28.975274Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## The Function Caller","metadata":{}},{"cell_type":"code","source":"# Implement the function calling expert.\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef send_message(prompt):\n    #display(Markdown(\"#### Prompt\"))\n    #print(prompt, \"\\n\")\n    # Define the user prompt part.\n    contents = [types.Content(role=\"user\", parts=[types.Part(text=prompt)])]\n\n    # Gemini's innate notion of current date and time is unstable.\n    contents += f\"\"\"\n    The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n    \n    Give a concise, and detailed summary. Use information that you learn from the API responses.\n    Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n    to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n    Convert timestamps according to the rules before including them. Think step by step.\n    \"\"\"\n    # Enable system prompt, function calling and minimum-randomness.\n    config_fncall = types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=[finance_tool],\n        temperature=0.0\n    )\n    # Handle cases with multiple chained function calls.\n    function_calling_in_process = True\n    # Send the initial user prompt and function declarations.\n    response = api.retriable(api.client.models.generate_content,\n                             model=api(Gemini.Model.GEN),\n                             config=config_fncall,\n                             contents=contents)\n    while function_calling_in_process:\n        # A part can be a function call or natural language response.\n        for part in response.candidates[0].content.parts:\n            if function_call := part.function_call:\n                # Extract the function call.\n                fn_name = function_call.name\n                #display(Markdown(\"#### Predicted function name\"))\n                #print(fn_name, \"\\n\")\n                # Extract the function call arguments.\n                fn_args = {key: value for key, value in function_call.args.items()}\n                #display(Markdown(\"#### Predicted function arguments\"))\n                #print(fn_args, \"\\n\")\n                # Call the predicted function.\n                api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n                #display(Markdown(\"#### API response\"))\n                #print(api_response[:500], \"...\", \"\\n\")\n                # Create an API response part.\n                api_response_part = types.Part.from_function_response(\n                    name=fn_name,\n                    response={\"content\": api_response},\n                )\n                # Append the model's function call part.\n                contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n                # Append the api response part.\n                contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n                # Send the updated prompt.\n                response = api.retriable(api.client.models.generate_content,\n                                         model=api(Gemini.Model.GEN),\n                                         config=config_fncall,\n                                         contents=contents)\n            else:\n                # Response may be a summary or reasoning step.\n                if len(response.candidates[0].content.parts) == 1:\n                    function_calling_in_process = False\n                    break # No more parts in response.\n                else:\n                    #display(Markdown(\"#### Natural language reasoning step\"))\n                    #print(response)\n                    continue # Next part contains a function call.\n        if not function_calling_in_process:\n            break # The function calling chain is complete.\n            \n    # Show the final natural language summary.\n    display(Markdown(\"#### Natural language response\"))\n    display(Markdown(response.text.replace(\"$\", \"\\\\$\")))","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-20T04:33:28.976791Z","iopub.execute_input":"2025-06-20T04:33:28.976999Z","iopub.status.idle":"2025-06-20T04:33:28.986472Z","shell.execute_reply.started":"2025-06-20T04:33:28.976984Z","shell.execute_reply":"2025-06-20T04:33:28.985713Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  15\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# Ask a question\n\n<span style=\"font-size:18px;\">\n    If you're on free-tier of Gemini you probably want to Run-before here. Your usage tier can be configured in the api-helper at the top of the notebook.\n</span>","metadata":{}},{"cell_type":"code","source":"send_message(\"What is the current session for US exchanges?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:36:07.566318Z","iopub.execute_input":"2025-06-20T04:36:07.566585Z","iopub.status.idle":"2025-06-20T04:36:13.044597Z","shell.execute_reply.started":"2025-06-20T04:36:07.566566Z","shell.execute_reply":"2025-06-20T04:36:13.043806Z"}},"outputs":[{"name":"stderr","text":"Generate US->MarketEvent.LAST_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\nGenerate US->MarketEvent.PRE_OPEN: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\nGenerate US->MarketEvent.REG_OPEN: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\nGenerate US->MarketEvent.REG_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\nGenerate US->MarketEvent.POST_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current market session for US exchanges is closed.\n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"send_message(\"What is the US market status?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:36:17.379119Z","iopub.execute_input":"2025-06-20T04:36:17.37975Z","iopub.status.idle":"2025-06-20T04:36:19.089123Z","shell.execute_reply.started":"2025-06-20T04:36:17.379723Z","shell.execute_reply":"2025-06-20T04:36:19.088434Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The U.S. market is currently closed. The timestamp for the market status is Fri Jun 20 00:36:05 2025 America/New_York time. There is no holiday today. The market session is closed.\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"send_message(\"When was the last US market close?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:37:16.295262Z","iopub.execute_input":"2025-06-20T04:37:16.295512Z","iopub.status.idle":"2025-06-20T04:37:17.593855Z","shell.execute_reply.started":"2025-06-20T04:37:16.295496Z","shell.execute_reply":"2025-06-20T04:37:17.593223Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The last market close in the United States was on Thursday, June 19, 2025, at 8:00 PM.\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"send_message(\"What is Apple's stock ticker?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:37:38.815379Z","iopub.execute_input":"2025-06-20T04:37:38.815683Z","iopub.status.idle":"2025-06-20T04:37:40.412243Z","shell.execute_reply.started":"2025-06-20T04:37:38.815666Z","shell.execute_reply":"2025-06-20T04:37:40.411319Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker for Apple is AAPL.\n"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"send_message(\"What is the current price of Amazon stock? Use markdown formatting.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:38:48.145758Z","iopub.execute_input":"2025-06-20T04:38:48.14659Z","iopub.status.idle":"2025-06-20T04:38:50.533384Z","shell.execute_reply.started":"2025-06-20T04:38:48.146562Z","shell.execute_reply":"2025-06-20T04:38:50.532762Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current price of Amazon (AMZN) stock is \\$212.52. This information was last updated on Thu Jun 19 2025 at 16:00:00.\n\n*   **Current Price:** \\$212.52\n*   **Change:** \\-2.3\n*   **Percent Change:** \\-1.0707%\n*   **High Price of the Day:** \\$217.96\n*   **Low Price of the Day:** \\$212.34\n*   **Open Price of the Day:** \\$215.09\n*   **Previous Close Price:** \\$214.82\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  15\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"send_message(\"Show me Apple's basic financials. How has the stock performed?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:40:13.120664Z","iopub.execute_input":"2025-06-20T04:40:13.121056Z","iopub.status.idle":"2025-06-20T04:40:23.877149Z","shell.execute_reply.started":"2025-06-20T04:40:13.121028Z","shell.execute_reply":"2025-06-20T04:40:23.876093Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of Apple's (AAPL) basic financials and stock performance:\n\n**Financial Highlights:**\n\n*   **Profitability:** Apple has a trailing twelve month net profit margin of 24.3%.\n*   **Gross Margin:** Apple's gross margin is 46.63% for the trailing twelve months.\n*   **Revenue Growth:** Apple's revenue has grown 4.91% year-over-year for the trailing twelve months.\n*   **Earnings per Share (EPS):** Apple's EPS is \\$6.4078 for the trailing twelve months.\n*   **Debt:** The Long Term Debt to Equity Annual is 1.5057.\n*   **Dividends:** Apple's current dividend yield is 0.5215% (TTM), with a dividend per share of \\$1.0115 (TTM).\n*   **Valuation:**\n    *   The price-to-earnings ratio is 30.1774 (TTM).\n    *   The price-to-book ratio is 43.956.\n    *   The price-to-sales ratio is 7.3335 (TTM).\n*   **Return on Equity (ROE):** Apple's ROE is 151.31% for the trailing twelve months.\n*   **52 Week Performance:**\n    *   52-week high: \\$260.1 on 2024-12-26\n    *   52-week low: \\$169.2101 on 2025-04-08\n*   **Trading Volume:** The 10-day average trading volume is 51.26078, and the 3-month average is 57.68244.\n*   **Stock Performance:**\n    *   5-day price return: -1.3153%\n    *   13-week price return: -7.5744%\n    *   26-week price return: -20.6603%\n    *   52-week price return: -9.2722%\n    *   Year-to-date price return: -21.4999%\n    *   Month-to-date price return: -2.126%\n\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"send_message(\"I need Apple's daily candlestick from 2025-05-05\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:40:33.438805Z","iopub.execute_input":"2025-06-20T04:40:33.43964Z","iopub.status.idle":"2025-06-20T04:40:36.51149Z","shell.execute_reply.started":"2025-06-20T04:40:33.439608Z","shell.execute_reply":"2025-06-20T04:40:36.51076Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is a summary of Apple's daily candlestick data from May 5th, 2025:\n\n*   **Symbol:** AAPL\n*   **Open Price:** 203.1\n*   **High Price:** 204.1\n*   **Low Price:** 198.21\n*   **Close Price:** 198.89\n*   **Volume:** 69018452\n*   **Pre-Market Price:** 205.0\n*   **After-Hours Price:** 198.6\n*   **Date:** 2025-05-05"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"send_message(\"Tell me who are Apple's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:41:06.650501Z","iopub.execute_input":"2025-06-20T04:41:06.650801Z","iopub.status.idle":"2025-06-20T04:41:09.527194Z","shell.execute_reply.started":"2025-06-20T04:41:06.650781Z","shell.execute_reply":"2025-06-20T04:41:09.52641Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The peers of Apple, with ticker symbol AAPL, include Dell Technologies -C (DELL), Super Micro Computer Inc (SMCI), Hewlett Packard Enterprise (HPE), HP Inc (HPQ), Western Digital Corp (WDC), NetApp Inc (NTAP), Pure Storage Inc - Class A (PSTG), and IonQ Inc (IONQ). These companies operate in the same country and subIndustry as Apple.\n"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"send_message(\"Tell me the recommendation trends for all of Apple's peers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:41:57.832011Z","iopub.execute_input":"2025-06-20T04:41:57.832284Z","iopub.status.idle":"2025-06-20T04:42:12.870448Z","shell.execute_reply.started":"2025-06-20T04:41:57.832266Z","shell.execute_reply":"2025-06-20T04:42:12.869641Z"}},"outputs":[{"name":"stdout","text":"api.on_error.next_model: model is now  gemini-2.0-flash-exp\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Recommendation Trends for Apple's Peers:\n\nHere's a summary of the latest analyst recommendation trends for Apple's peers, based on data up to June 2025:\n\n*   **Dell Technologies (DELL):** The recommendation trend is consistent from March to June 2025. It shows a majority of \"Buy\" recommendations. For June 2025, there are 20 \"Buy\", 4 \"Hold\", 0 \"Sell\", 6 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n*   **Super Micro Computer Inc (SMCI):** The recommendation trend is consistent from March to June 2025. For June 2025, there are 10 \"Buy\", 10 \"Hold\", 2 \"Sell\", 2 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n*   **Hewlett Packard Enterprise (HPE):** The recommendation trend is consistent from March to June 2025. For June 2025, there are 7 \"Buy\", 8 \"Hold\", 0 \"Sell\", 4 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n*   **HP Inc (HPQ):** The recommendation trend is consistent from March to June 2025. For June 2025, there are 4 \"Buy\", 13 \"Hold\", 1 \"Sell\", 2 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n*   **Western Digital Corp (WDC):** The recommendation trend shows an increase in \"Buy\" recommendations in June 2025. For June 2025, there are 19 \"Buy\", 5 \"Hold\", 0 \"Sell\", 6 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n*   **NetApp Inc (NTAP):** The recommendation trend is consistent from March to June 2025. For June 2025, there are 9 \"Buy\", 16 \"Hold\", 0 \"Sell\", 3 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n*   **Pure Storage Inc - Class A (PSTG):** The recommendation trend is consistent from March to June 2025. For June 2025, there are 13 \"Buy\", 6 \"Hold\", 1 \"Sell\", 8 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n*   **IONQ Inc (IONQ):** The recommendation trend is consistent from March to June 2025. For June 2025, there are 7 \"Buy\", 2 \"Hold\", 0 \"Sell\", 2 \"Strong Buy\", and 0 \"Strong Sell\" recommendations.\n"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"send_message(\"Tell me who are Amazon's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:43:34.191553Z","iopub.execute_input":"2025-06-20T04:43:34.19187Z","iopub.status.idle":"2025-06-20T04:43:36.859729Z","shell.execute_reply.started":"2025-06-20T04:43:34.191849Z","shell.execute_reply":"2025-06-20T04:43:36.858938Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The peers of Amazon, based on the subIndustry grouping, are Coupang Incorporated (CPNG), Ebay Incorporated (EBAY), Ollie's Bargain Outlet Holdings (OLLI), Dillards Incorporated-Class A (DDS), Etsy Incorporated (ETSY), Macy's Incorporated (M), Savers Value Village Incorporated (SVV), and Groupon Incorporated (GRPN).\n"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"api.set_default_model(1) # generate with gemini-2.0-flash-exp\nsend_message(\n    \"\"\"Tell me Amazon's current share price and provide candlestick data for the past month.\n    Sort the data in descending order by date. Format the prices consistently as currency.\n    Round prices to two decimal places.\n    Present the data with multiple columns for display in markdown.\n    Discuss and provide details about any patterns you notice in the price data.\"\"\")\napi.set_default_model(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:42:42.761876Z","iopub.execute_input":"2025-06-20T04:42:42.762177Z","iopub.status.idle":"2025-06-20T04:43:21.381397Z","shell.execute_reply.started":"2025-06-20T04:42:42.76215Z","shell.execute_reply":"2025-06-20T04:43:21.380031Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of Amazon's (AMZN) stock information:\n\n**Current Share Price:**\n\n*   The current share price is \\$212.52 as of June 19, 2025, at 04:00:00 PM Eastern Time.\n*   This represents a decrease of \\$2.30, or 1.07%, from the previous close.\n*   The high of the day was \\$217.96, and the low was \\$212.34.\n*   The opening price for the day was \\$215.09.\n*   The previous close price was \\$214.82.\n\n**Candlestick Data for the Past Month (May 19, 2025 - June 19, 2025):**\n\nI am including a table of candlestick data for Amazon (AMZN) from May 19, 2025, to June 19, 2025. The data is sorted in descending order by date.\n\n| Date       | Open    | High    | Low     | Close   | Volume      |\n| :--------- | :------ | :------ | :------ | :------ | :---------- |\n| 2025-06-19 | \\$215.09 | \\$217.96 | \\$212.34 | \\$212.52 | 44,360,509  |\n| 2025-06-18 | \\$215.20 | \\$217.41 | \\$214.56 | \\$214.82 | 32,086,262  |\n| 2025-06-17 | \\$212.31 | \\$217.06 | \\$211.60 | \\$216.10 | 33,284,158  |\n| 2025-06-13 | \\$209.96 | \\$214.05 | \\$209.62 | \\$212.10 | 29,337,763  |\n| 2025-06-12 | \\$211.78 | \\$213.58 | \\$211.33 | \\$213.24 | 27,639,991  |\n| 2025-06-11 | \\$217.41 | \\$218.40 | \\$212.89 | \\$213.20 | 39,325,981  |\n| 2025-06-10 | \\$216.78 | \\$217.69 | \\$214.15 | \\$217.61 | 31,303,317  |\n| 2025-06-09 | \\$214.75 | \\$217.85 | \\$212.88 | \\$216.98 | 38,102,502  |\n| 2025-06-04 | \\$212.40 | \\$213.87 | \\$210.50 | \\$213.57 | 39,832,500  |\n| 2025-06-03 | \\$209.55 | \\$212.81 | \\$207.56 | \\$207.91 | 51,979,243  |\n| 2025-06-02 | \\$206.55 | \\$208.18 | \\$205.18 | \\$207.23 | 29,915,592  |\n| 2025-05-30 | \\$207.11 | \\$208.95 | \\$205.03 | \\$205.71 | 33,139,121  |\n| 2025-05-29 | \\$204.98 | \\$207.00 | \\$202.68 | \\$206.65 | 29,113,319  |\n| 2025-05-28 | \\$204.84 | \\$205.99 | \\$201.70 | \\$205.01 | 51,679,406  |\n| 2025-05-27 | \\$208.03 | \\$208.81 | \\$204.23 | \\$205.70 | 34,700,005  |\n| 2025-05-23 | \\$205.92 | \\$207.66 | \\$204.41 | \\$204.72 | 28,549,753  |\n| 2025-05-22 | \\$203.09 | \\$206.69 | \\$202.19 | \\$206.02 | 34,892,044  |\n| 2025-05-21 | \\$198.90 | \\$202.37 | \\$197.85 | \\$200.99 | 33,393,545  |\n| 2025-05-20 | \\$201.38 | \\$205.76 | \\$200.16 | \\$203.10 | 38,938,882  |\n| 2025-05-19 | \\$201.61 | \\$203.46 | \\$200.06 | \\$201.12 | 42,460,924  |\n| 2025-05-16 | \\$204.63 | \\$205.59 | \\$202.65 | \\$204.07 | 29,470,373  |\n| 2025-05-15 | \\$201.65 | \\$206.62 | \\$201.26 | \\$206.16 | 34,314,810  |\n\n**Observations:**\n\n*   **Volatility:** The stock price has experienced volatility over the past month, with noticeable fluctuations in the daily high and low prices.\n*   **Downward Trend:** The closing price on June 19, 2025, is lower than the closing price a month prior on May 19, 2025, indicating a slight downward trend over the observed period.\n*   **Volume Spikes:** There are a few days with significantly higher trading volumes, which could be associated with specific news events or market sentiment changes. For example, June 3, 2025, had a volume of 51,979,243.\n*   **Recent Decline:** In the most recent days (June 17-19), the stock has shown a decline, closing at \\$212.52 on June 19, 2025.\n\n"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"send_message(\"What is Apple's ticker overview\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:43:52.951323Z","iopub.execute_input":"2025-06-20T04:43:52.9521Z","iopub.status.idle":"2025-06-20T04:43:56.340258Z","shell.execute_reply.started":"2025-06-20T04:43:52.952078Z","shell.execute_reply":"2025-06-20T04:43:56.339191Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple Incorporated (AAPL) is a major global company offering a wide range of hardware and software for consumers and businesses. The iPhone accounts for most of Apple's sales, while other products like Mac, iPad, and Watch are integrated into its software ecosystem. Apple is expanding into areas like streaming, subscriptions, and augmented reality. The company designs its own software and semiconductors, working with subcontractors such as Foxconn and TSMC for manufacturing. A little under half of Apple's sales are direct, through flagship stores, with the majority through partnerships and distribution.\n\nKey details:\n*   **Primary Exchange:** XNAS\n*   **CIK:** 0000320193\n*   **Composite FIGI:** BBG000B9XRY4\n*   **Share Class FIGI:** BBG001S5N8V8\n*   **Market Capitalization:** \\$2,975,216,539,200.0\n*   **Phone Number:** (408) 996-1010\n*   **Address:** One Apple Park Way, Cupertino, CA 95014\n*   **SIC Code:** 3571 (Electronic Computers)\n*   **Homepage URL:** <https://www.apple.com>\n*   **Total Employees:** 164,000\n*   **List Date:** 1980-12-12\n*   **Logo URL:** <https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_logo.svg>\n*   **Icon URL:** <https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_icon.png>\n*   **Weighted Shares Outstanding:** 14,935,826,000\n*   **Round Lot:** 100"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"send_message(\"Tell me about Amazon's historical and current recommendation trends\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:44:17.197538Z","iopub.execute_input":"2025-06-20T04:44:17.198209Z","iopub.status.idle":"2025-06-20T04:44:19.813272Z","shell.execute_reply.started":"2025-06-20T04:44:17.19818Z","shell.execute_reply":"2025-06-20T04:44:19.812644Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of June 1st, 2025, Amazon has 24 strong buy, 51 buy, and 6 hold recommendations. There are no sell or strong sell recommendations.\n\nHere's a summary of Amazon's recommendation trends:\n*   June 1st, 2025: 24 strong buy, 51 buy, 6 hold\n*   May 1st, 2025: 22 strong buy, 51 buy, 6 hold\n*   April 1st, 2025: 23 strong buy, 50 buy, 4 hold\n*   March 1st, 2025: 21 strong buy, 51 buy, 5 hold\n"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"send_message(\"What is Google's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:44:24.724827Z","iopub.execute_input":"2025-06-20T04:44:24.725112Z","iopub.status.idle":"2025-06-20T04:44:32.844353Z","shell.execute_reply.started":"2025-06-20T04:44:24.725092Z","shell.execute_reply":"2025-06-20T04:44:32.843395Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Google's stock ticker symbols on the NASDAQ are GoogL and Goog. It is also listed on the Frankfurt Stock Exchange under the symbol GGQ1. These symbols now represent Alphabet Inc., Google's holding company.\n"},"metadata":{}},{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"send_message(\"What is MGM Studio's stock symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:47:22.609946Z","iopub.execute_input":"2025-06-20T04:47:22.610282Z","iopub.status.idle":"2025-06-20T04:47:30.341159Z","shell.execute_reply.started":"2025-06-20T04:47:22.610257Z","shell.execute_reply":"2025-06-20T04:47:30.340347Z"}},"outputs":[{"name":"stdout","text":"api.on_error.next_model: model is now  gemini-2.0-flash-001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I was unable to find the stock symbol for Mgm Studios.\n"},"metadata":{}},{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"send_message(\"What is Amazon MGM Studio's stock symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:46:49.656857Z","iopub.execute_input":"2025-06-20T04:46:49.657181Z","iopub.status.idle":"2025-06-20T04:46:52.586615Z","shell.execute_reply.started":"2025-06-20T04:46:49.65716Z","shell.execute_reply":"2025-06-20T04:46:52.585917Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon MGM Studios is a subsidiary of Amazon, which is a publicly traded company. The stock symbol for Amazon is AMZN.\n"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"send_message(\"What is Facebook's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:47:51.145233Z","iopub.execute_input":"2025-06-20T04:47:51.145498Z","iopub.status.idle":"2025-06-20T04:47:56.01983Z","shell.execute_reply.started":"2025-06-20T04:47:51.145478Z","shell.execute_reply":"2025-06-20T04:47:56.019105Z"}},"outputs":[{"name":"stderr","text":"Score similarity to stored grounding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Facebook, now known as Meta Platforms, Inc., has the stock ticker symbol META. It was formerly FB.\n"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"send_message(\n    '''Tell me about Amazon's current bullish versus bearish predictions, and recommendation trends.\n    Include a discussion of any short-term trends, and sentiment analysis.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:48:00.355523Z","iopub.execute_input":"2025-06-20T04:48:00.355824Z","iopub.status.idle":"2025-06-20T04:48:08.31679Z","shell.execute_reply.started":"2025-06-20T04:48:00.355804Z","shell.execute_reply":"2025-06-20T04:48:08.31592Z"}},"outputs":[{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of June 20, 2025, here's a summary of Amazon's analyst recommendations and recent news sentiment:\n\n**Analyst Recommendation Trends:**\n\n*   The latest analyst recommendation trends show a strong bullish sentiment. In June 2025, out of the analysts providing recommendations, 24 rated the stock as a 'strong buy' and 51 rated it as a 'buy', with 6 analysts recommending to 'hold'. There were no 'sell' or 'strong sell' recommendations.\n\n**Recent News and Sentiment Analysis:**\n\nRecent news articles (May 20, 2025 - June 19, 2025) present a generally positive outlook for Amazon:\n\n*   **AI and Cloud Computing:** Several articles highlight Amazon's strong position in the artificial intelligence (AI) and cloud computing sectors, particularly through Amazon Web Services (AWS). Analysts predict significant growth for AWS, driven by the increasing demand for AI infrastructure.\n*   **Analyst Upgrades and Positive Ratings:** Multiple articles mention analysts reiterating bullish ratings on Amazon, with some suggesting the stock is poised for further gains.\n*   **Robotics and Automation:** Amazon's increasing use of robotics and automation in its fulfillment centers is seen as a positive factor, leading to productivity gains and margin improvement.\n*   **E-commerce Dominance:** Amazon continues to dominate the e-commerce market, with a significant market share in the U.S.\n*   **Partnerships and Expansion:** Amazon's partnership with Roku for advertising and its potential tie-up with AST SpaceMobile are viewed favorably.\n*   **Bill Ackman's Investment:** Billionaire investor Bill Ackman's Pershing Square has taken a new stake in Amazon, adding to the bullish sentiment around the stock.\n*   **Potential Risks:** Some articles mention potential risks, such as tariffs and competition, but the overall sentiment remains positive due to Amazon's strong fundamentals and growth prospects.\n\n**Overall Summary:**\n\nThe analyst recommendation trends and recent news sentiment suggest a predominantly bullish outlook for Amazon. Analysts are optimistic about the company's growth prospects, particularly in AI, cloud computing, and e-commerce. Recent news articles highlight positive developments, such as analyst upgrades, strategic partnerships, and investments in AI and automation. While potential risks exist, the overall sentiment indicates that Amazon is well-positioned for continued growth and success.\n"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"send_message(\n    '''Tell me about Google's share price from May 01 2025 until today in a markdown table.\n    How has the stock performed?\n    Perform a sentiment analysis of news during the same dates. Include trends in your analysis.''')","metadata":{"trusted":true},"outputs":[{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of Google's stock performance and news sentiment from May 1, 2025, to June 19, 2025.\n\n**Stock Performance**\n\nThe following table summarizes Google's (GOOG) share price from May 1, 2025, to June 19, 2025.\n\n| Date             | Open   | High   | Low    | Close  | Volume     |\n| :--------------- | :----- | :----- | :----- | :----- | :--------- |\n| Thu May 01 2025  | 162.52 | 163.94 | 160.93 | 162.79 | 21904291   |\n| Fri May 02 2025  | 164.955| 166.7  | 163.66 | 165.81 | 16844937   |\n| Mon May 05 2025  | 164.515| 167.1  | 164.47 | 166.05 | 15309343   |\n| Tue May 06 2025  | 163.96 | 166.74 | 163.13 | 165.2  | 10691949   |\n| Wed May 07 2025  | 166.07 | 166.99 | 149.49 | 152.8  | 78900429   |\n| Thu May 08 2025  | 155.92 | 157.41 | 154.1  | 155.75 | 38387507   |\n| Fri May 09 2025  | 155.55 | 156.43 | 153.83 | 154.38 | 22871035   |\n| Mon May 12 2025  | 159.1  | 160.44 | 157.889| 159.58 | 31884901   |\n| Tue May 13 2025  | 159.92 | 162.06 | 157.58 | 160.89 | 24944270   |\n| Wed May 14 2025  | 161.31 | 168.34 | 160.93 | 166.81 | 31769209   |\n| Thu May 15 2025  | 167.14 | 167.51 | 163.84 | 165.4  | 22717554   |\n| Fri May 16 2025  | 168.93 | 170.65 | 166.95 | 167.43 | 36271378   |\n| Mon May 19 2025  | 165.715| 167.95 | 165.415| 167.87 | 21374688   |\n| Tue May 20 2025  | 167.76 | 169.68 | 164.26 | 165.32 | 33563274   |\n| Wed May 21 2025  | 168.865| 169.8  | 166.68 | 167.71 | 25386713   |\n| Thu May 22 2025  | 169.01 | 171.062| 168.65 | 170.37 | 24742877   |\n| Fri May 23 2025  | 170.28 | 171.205| 169.26 | 169.59 | 24963648   |\n| Tue May 27 2025  | 173.35 | 178.13 | 171.88 | 171.98 | 45024081   |\n| Wed May 28 2025  | 173.98 | 176.48 | 173.014| 173.38 | 25999228   |\n| Thu May 29 2025  | 175.0  | 175.4  | 171.78 | 172.96 | 21233590   |\n| Fri May 30 2025  | 172.41 | 173.44 | 168.525| 172.85 | 36258254   |\n| Mon Jun 02 2025  | 177.28 | 177.823| 172.84 | 173.98 | 32531762   |\n| Mon Jun 02 2025  | 172.3  | 175.83 | 172.3  | 174.92 | 22258115   |\n| Tue Jun 03 2025  | 173.58 | 178.343| 173.57 | 175.88 | 20873241   |\n| Wed Jun 04 2025  | 175.87 | 177.915| 175.66 | 177.63 | 18817587   |\n| Thu Jun 05 2025  | 177.48 | 178.13 | 176.11 | 176.97 | 17345924   |\n| Fri Jun 06 2025  | 177.0  | 178.715| 175.94 | 177.23 | 17656119   |\n| Mon Jun 09 2025  | 181.23 | 181.75 | 178.0  | 178.79 | 18994398   |\n| Tue Jun 10 2025  | 177.76 | 182.445| 176.475| 180.01 | 32908000   |\n| Wed Jun 11 2025  | 171.62 | 172.36 | 169.35 | 169.81 | 25422883   |\n| Thu Jun 12 2025  | 168.28 | 169.58 | 167.795| 169.39 | 18508735   |\n| Fri Jun 13 2025  | 168.93 | 170.65 | 166.95 | 167.43 | 36271378   |\n| Mon Jun 16 2025  | 173.98 | 176.48 | 173.014| 173.38 | 25999228   |\n| Tue Jun 17 2025  | 171.3  | 174.29 | 171.21 | 173.98 | 24341333   |\n\nOverall, the stock experienced volatility during this period. It began at 162.79 on May 1, peaked at 180.01 on June 10, and closed at 173.98 on June 17.\n\n**News Sentiment Analysis**\n\nThe news sentiment surrounding Google during this period was predominantly positive, with a focus on Google's advancements and investments in artificial intelligence (AI). Key themes include:\n\n*   **AI Leadership:** Google is consistently recognized as a leader in AI, with its Gemini models and AI-powered search capabilities frequently mentioned.\n*   **Cloud Growth:** Google Cloud Platform (GCP) is experiencing significant growth, driven by AI and cloud migration trends.\n*   **Quantum Computing:** Google's Willow quantum computing chip is highlighted as a breakthrough, outperforming competitors.\n*   **Partnerships:** Google is forming strategic partnerships, particularly in the autonomous vehicle sector with companies like Uber.\n*   **Positive Analyst Ratings:** Many analysts recommend Google as a strong buy, citing its attractive valuation and growth potential.\n\nHowever, some negative sentiments also emerged:\n\n*   **Competition:** Google faces increasing competition from other tech giants in AI, cloud computing, and search.\n*   **Regulatory Concerns:** Antitrust issues and potential regulations pose challenges to Google's business model.\n*   **Tariff Impact:** Concerns about the impact of tariffs on Google's advertising revenue and supply chain are present.\n*   **Water Usage:** Concerns about the water usage of data centers operated by Google.\n\n**Concise Summary**\n\nFrom May 1, 2025, to June 19, 2025, Google's stock price experienced volatility but generally trended upwards. News sentiment was largely positive, driven by Google's leadership in AI, cloud growth, and strategic partnerships. However, concerns about competition, regulatory issues, and the impact of tariffs also surfaced. Overall, the period reflects a company with strong fundamentals and growth potential, but also facing challenges in a rapidly evolving market.\n"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"send_message(\n    '''How is the outlook for Apple based on trends and news sentiment from May 01 2025 until today?\n    Perform the same analysis on all peers by sub-industry. Then compare Apple result to it's peers.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:54:09.683083Z","iopub.execute_input":"2025-06-20T04:54:09.68335Z","iopub.status.idle":"2025-06-20T04:55:35.43319Z","shell.execute_reply.started":"2025-06-20T04:54:09.683332Z","shell.execute_reply":"2025-06-20T04:55:35.432466Z"}},"outputs":[{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.on_error.next_model: model is now  gemini-2.0-flash-exp\n","output_type":"stream"},{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"limited 5/min, waiting 3.8723161220550537s\n","output_type":"stream"},{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash\n","output_type":"stream"},{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of the outlook for Apple and its peers based on recommendation trends and news sentiment from May 1, 2025, to June 20, 2025.\n\n**Apple (AAPL):**\n\n*   **Recommendation Trends:** Analyst recommendations for Apple have remained relatively stable, with a mix of \"Buy\" and \"Hold\" ratings. In June 2025, the recommendations were 14 strong buy, 25 buy, 14 hold, 3 sell, and 1 strong sell.\n*   **News Sentiment:** The news sentiment surrounding Apple is mixed. Some articles highlight Apple's strong brand, customer loyalty, and potential in areas like AI and the smart home. However, there are also concerns about the company falling behind in the AI race, potential tariff impacts, and slowing iPhone sales growth. Several articles mention that Apple may need to acquire an AI platform to remain competitive.\n*   **Peers:** Apple's peers by sub-industry include Dell Technologies, Super Micro Computer, Hewlett Packard Enterprise, HP Inc., Western Digital, NetApp, Pure Storage, and IonQ.\n\n**Peer Analysis:**\n\nHere's a summary of the recommendation trends and news sentiment for Apple's peers:\n\n*   **Dell Technologies (DELL):** Recommendation trends are mostly positive. News sentiment is also positive, with analysts increasing price targets after recent earnings reports and strong demand for AI servers.\n*   **Super Micro Computer (SMCI):** Recommendation trends are mixed, with a combination of \"Buy\" and \"Hold\" ratings. News sentiment is also mixed, with some articles highlighting the company's strong fundamentals and potential in the AI hardware market, while others express concerns about accounting issues and declining margins.\n*   **Hewlett Packard Enterprise (HPE):** Recommendation trends are mostly \"Hold.\" News sentiment is generally positive, with the company being recognized as a key player in the AI and data center equipment markets.\n*   **HP Inc. (HPQ):** Recommendation trends are mostly \"Hold.\" News sentiment is mixed, with some articles highlighting positive developments like dividend declarations and inclusion in retail events, while others point to mixed earnings and a cut in outlook.\n*   **Western Digital (WDC):** Recommendation trends are mostly \"Buy.\" News sentiment is neutral, with the company being mentioned as a key player in the storage systems market.\n*   **NetApp (NTAP):** Recommendation trends are mostly \"Hold.\" News sentiment is neutral, with the company being mentioned as a key player in the storage systems market.\n*   **Pure Storage (PSTG):** Recommendation trends are mostly \"Buy.\" News sentiment is neutral, with the company being mentioned as a key player in the storage systems market.\n*   **IonQ (IONQ):** Recommendation trends are mostly \"Buy.\" News sentiment is mixed, with some articles highlighting the company's potential in the quantum computing market, while others express concerns about its high valuation and uncertain timeline for practical applications.\n\n**Concise Summary:**\n\nThe outlook for Apple is mixed. While the company has a strong brand and loyal customer base, there are concerns about its AI capabilities and potential tariff impacts. Apple's peers in the computer hardware sub-industry have varying outlooks, with some, like Dell, showing strong growth potential in AI, while others, like HP Inc., face challenges in certain segments. The quantum computing peer, IonQ, is considered high risk, high reward. Overall, the computer hardware sub-industry appears to be benefiting from the growth in AI and data center infrastructure, but individual company performance varies.\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  15\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"api.set_default_model(1) # generate with gemini-2.0-flash-exp\nsend_message(\n    '''What does the recent news say about Apple and the impact of tariffs? From 2025-03-01 up to today.\n    Also locate candlestick data for the same dates. \n    Discuss in detail any correlations in patterns between the candlestick and news data.\n    Ignore duplicate news entry.''')\napi.set_default_model(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T04:56:17.52458Z","iopub.execute_input":"2025-06-20T04:56:17.525208Z","iopub.status.idle":"2025-06-20T04:56:37.605707Z","shell.execute_reply.started":"2025-06-20T04:56:17.525183Z","shell.execute_reply":"2025-06-20T04:56:37.604958Z"}},"outputs":[{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of the news and candlestick data for Apple (AAPL) between March 1, 2025, and June 19, 2025, incorporating correlations between the two:\n\n**News Summary:**\n\n*   **Tariff Concerns:** Throughout the period, there were recurring concerns about potential tariffs on Apple products, particularly those manufactured in China and India. President Trump's threats to impose tariffs on iPhones manufactured outside the U.S. created uncertainty and negatively impacted the stock. Some analysts believed Apple could pass tariff costs to consumers, while others worried about increased costs and reduced competitiveness.\n*   **AI Developments:** Apple's AI strategy was a significant theme. News articles highlighted concerns that Apple was falling behind in the AI race compared to competitors like Google and Microsoft. Some analysts suggested Apple might need to acquire an AI platform like Perplexity to remain competitive. There was also discussion about Apple's potential integration of AI into its Safari search capabilities, which could challenge Google's dominance.\n*   **Market Performance & Analyst Ratings:** Apple's stock experienced volatility, with some analysts suggesting it was a buying opportunity during dips. However, other analysts expressed caution due to slowing growth, lack of innovation, and a high valuation. Several articles mentioned Apple as a top holding in various Vanguard ETFs, indicating its importance in the tech sector.\n*   **Other Factors:** Other news included discussions about Apple's dividend yield, potential new product launches (like the HomePad and AI-powered robots), and its performance in specific markets like China and India.\n\n**Candlestick Data Summary:**\n\n*   The candlestick data shows price fluctuations throughout the period. There were periods of upward and downward trends, reflecting the uncertainty and volatility surrounding Apple's stock.\n*   From March 1, 2025, to mid-March, the price generally declined.\n*   In late March and early April, the price showed a recovery.\n*   From mid-April to mid-May, the price experienced a significant decline.\n*   In late May and June, the price showed a recovery.\n\n**Correlations:**\n\n*   **Tariff Announcements and Price Drops:** News of potential or actual tariff implementations often correlated with price drops in Apple's stock. For example, the announcement of a 25% tariff on iPhones manufactured in India on May 27, 2025, was followed by a price decrease.\n*   **AI News and Market Sentiment:** Negative news regarding Apple's AI efforts or competitive positioning seemed to coincide with periods of market uncertainty or downward trends in the stock price. Conversely, positive news about potential AI partnerships or product innovations may have contributed to price stability or slight increases.\n*   **Broader Market Trends:** Apple's stock performance was also influenced by broader market trends and investor sentiment. For example, the overall market sell-off in early May 2025, driven by concerns about rising interest rates and economic growth, impacted Apple's stock price along with other tech companies.\n*   **Analyst Ratings:** Positive analyst ratings and price target increases may have provided some support to the stock price during periods of uncertainty.\n\n**Concise Summary:**\n\nBetween March and June 2025, Apple's stock was significantly influenced by tariff-related news and its perceived position in the AI race. Negative tariff announcements and concerns about Apple's AI progress often correlated with price declines, while positive news or analyst ratings could provide some support. Broader market trends and investor sentiment also played a role in Apple's stock performance during this period.\n\n**Disclaimer:** I am an AI chatbot and cannot provide financial advice. This information is for informational purposes only and should not be considered investment advice.\n"},"metadata":{}}],"execution_count":66},{"cell_type":"markdown","source":"# Conclusion\n\n<span style=\"font-size:18px;\">\nFor now that will have to do. Our Essy has a solid foundation but more could be done to organise metadata. No evaluation or validation has been performed (except fuzzing the prompt). Next steps include restructuring the vector database based on lessons learned. That'll be followed by plotting, multi-modal, and structured output. The last close date (generative) function can be temperamental. In the same way Gemini always feels regarding dates. I've learnt so much. I'm happy I decided to participate in the event! It really has been a joy to see Essy grow from random chat with Gemini into the foundation for a good-broker buddy. I hope you enjoy playing with this edition as much as I enjoyed building it!\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Update June 7, 2025\n\n<span style=\"font-size:18px;\">\n    Bugfix version 102 finally brings Essy to a stable milestone. A month and a half late :) There's still more to be built including adding reasoning, agents, and structured output. A few unimplemented rest endpoints remain that could make Essy more self-reliant. The vector store has gotten bigger but not smarter. Essy can tell us pre-scored news has some sentiment but cannot generate it due to limited summaries. Essy can detect interesting patterns in a dataset but not between adjacent datasets. There's so much data we'll need to recruit Essy some help.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Advanced (localhost required)\n\n<span style=\"font-size:18px;\">\n    The functions demonstrated here require a locally running notebook. A dedicated GPU with at least 8GB VRAM is recommended but not required. Output is generated with Gemma 3 12B QAT, Gemma.cpp, and (later) Gemma 3n. Output on Kaggle is based on cached data.\n</span>","metadata":{}},{"cell_type":"code","source":"# soon","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null}]}