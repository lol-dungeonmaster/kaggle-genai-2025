{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-2-document-q-a-with-rag.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11376588,"sourceType":"datasetVersion","datasetId":7122584}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oswind/stockchat-towards-a-stock-market-assistant?scriptVersionId=236538152\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Prepare the notebook environment for use.\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n!pip install -qU google-genai==1.7.0 chromadb==0.6.3 langchain-community langchain-text-splitters wikipedia\n\nimport ast, chromadb, csv, json, pandas, pytz, requests, warnings, wikipedia\nfrom bs4 import Tag\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse\nfrom dateutil.tz import gettz\nfrom google import genai\nfrom google.api_core import retry\nfrom google.genai import types\nfrom IPython.display import HTML, Markdown, display\nfrom kaggle_secrets import UserSecretsClient\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain_text_splitters.character import RecursiveCharacterTextSplitter\nfrom langchain_text_splitters.html import HTMLSemanticPreservingSplitter\nfrom langchain_text_splitters.json import RecursiveJsonSplitter\nfrom tqdm import tqdm\nfrom typing import Optional\nfrom wikipedia.exceptions import DisambiguationError, PageError","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:53:30.099927Z","iopub.execute_input":"2025-04-28T04:53:30.100254Z","iopub.status.idle":"2025-04-28T04:54:43.295663Z","shell.execute_reply.started":"2025-04-28T04:53:30.100222Z","shell.execute_reply":"2025-04-28T04:54:43.294521Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Prepare the gemini client for use.\n# Setup a retry helper in case we hit the RPM limit on generate_content or embed_content.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\ngenai.models.Models.embed_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.embed_content)\n\n# Import the secret api keys.\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\n# Rate-limits vary by generative model, flash variants have a 1500 RPD limit per project. \nproject_model_1 = \"models/gemini-2.0-flash\"\nproject_model_2 = \"models/gemini-2.0-flash-exp\"\nproject_model = project_model_1 # Update this if you hit api usage limits.\n\n# Create the genai client.\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:54:43.297593Z","iopub.execute_input":"2025-04-28T04:54:43.298133Z","iopub.status.idle":"2025-04-28T04:54:43.628577Z","shell.execute_reply.started":"2025-04-28T04:54:43.298098Z","shell.execute_reply":"2025-04-28T04:54:43.627539Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Laying the foundation with Gemini 2.0\n\n<span style=\"font-size:18px;\">\nA programming instructor once suggested the idea of a Stock Market application for final project topics. They did this knowing good investing app UX is challenging. The idea has stuck with me since because it's true. In the past I've worked with some REST api's building toys. None of them could ever reach my expectations because of API limits. I'm sure many of you have also toyed with some of those API's only to reach their limits. I always knew the secret to great finance UX is a great AI to help out. When posed with so many topics for 2025's 5-Day GenAI Course, I first tinkered with many of the other capabilities of Gemini until I posed Gemini the question:\n</span> ","metadata":{}},{"cell_type":"code","source":"# This is an accurate retelling of events. \nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0\n)\nchat = client.chats.create(\n    model=project_model, config=config_with_search, history=[]) # Ignoring the part about dark elves, and tengwar.\n\nresponse = chat.send_message('Do you know anything about the stock market?')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:54:43.629747Z","iopub.execute_input":"2025-04-28T04:54:43.630078Z","iopub.status.idle":"2025-04-28T04:54:48.278235Z","shell.execute_reply.started":"2025-04-28T04:54:43.630047Z","shell.execute_reply":"2025-04-28T04:54:48.27725Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Yes, I do. Here's some information about the stock market:\n\n**What it is:**\n\n*   The stock market is a place where buyers and sellers trade stocks (also called shares). These stocks represent ownership in a company.\n*   It's essentially a collection of marketplaces where investors buy and sell shares of publicly traded companies.\n*   The stock market can be both physical (like the New York Stock Exchange) and virtual, with trades happening electronically.\n\n**How it works:**\n\n*   **Companies issue stock:** Companies sell shares of their stock to raise money. This is often done through an initial public offering (IPO).\n*   **Investors buy and sell:** Investors purchase these shares, hoping the company will do well and the value of their shares will increase. They can then sell those shares to other investors at a profit.\n*   **Supply and demand:** Stock prices are determined by supply and demand. If more people want to buy a stock than sell it, the price goes up, and vice versa.\n*   **Stock Exchanges:** Stock exchanges like the New York Stock Exchange (NYSE) and the Nasdaq are platforms where stocks are bought and sold.\n*   **Stock Market Indexes:** Stock market indexes like the S&P 500 and the Dow Jones Industrial Average (DJIA) track the performance of a group of stocks, providing an overview of the market's health. The main stock market index in the United States (US500) decreased 384 points or 6.53% since the beginning of 2025.\n\n**Key Participants:**\n\n*   **Investors:** Individuals, institutions (like pension funds, insurance companies, and mutual funds), and corporations.\n*   **Stockbrokers:** Intermediaries who execute buy and sell orders on behalf of investors.\n*   **Traders:** People who buy and sell stocks frequently, often trying to profit from short-term price movements.\n*   **Companies:** The companies whose stocks are being traded.\n\n**Why it matters:**\n\n*   **Raising Capital:** It allows companies to raise capital to grow their businesses.\n*   **Wealth Creation:** It provides a way for individuals to invest and potentially grow their wealth.\n*   **Economic Indicator:** The stock market's performance is often seen as an indicator of the overall health of the economy.\n\n**Factors that influence stock prices:**\n\n*   Company performance (earnings, revenue, etc.)\n*   Economic conditions (inflation, interest rates, GDP growth, etc.)\n*   Industry trends\n*   News and events\n*   Investor sentiment\n\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# How much Gemini 2.0 knows\n\n<span style=\"font-size:18px;\">\nI thought to myself: Could grounding really make it that easy? Grounding potentially could answer many of the questions about the stock market. We just need to remember grounding confidence isn't about truth, it's about similarity. I decided to limit myself to free tier in finding out.\n</span>","metadata":{}},{"cell_type":"code","source":"# And so I asked a more challenging questions.\nresponse = chat.send_message('I have an interest in AMZN stock')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:54:48.279604Z","iopub.execute_input":"2025-04-28T04:54:48.280057Z","iopub.status.idle":"2025-04-28T04:54:55.36537Z","shell.execute_reply.started":"2025-04-28T04:54:48.280009Z","shell.execute_reply":"2025-04-28T04:54:55.364256Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, let's talk about AMZN (Amazon) stock. Here's some information that might be helpful:\n\n**What it is:**\n\n*   **Ticker Symbol:** AMZN\n*   **Company:** Amazon.com, Inc.\n*   **Industry:** Internet Retail / E-commerce, Cloud Computing, Digital Advertising, and more. Amazon is a very diverse company.\n\n**Key things to consider about AMZN:**\n\n*   **Business Overview:** Amazon is a multinational technology company focusing on e-commerce, cloud computing, digital streaming, and artificial intelligence. It's one of the \"Big Five\" technology companies.\n*   **Financial Performance:** You'll want to look at Amazon's revenue growth, profitability (or lack thereof in some segments), and cash flow. Pay attention to how its different business segments (e.g., AWS, e-commerce, advertising) are performing.\n*   **Growth Opportunities:** Consider areas like cloud computing (AWS), advertising, subscription services (Prime), and new ventures.\n*   **Competition:** Amazon faces competition from other major tech companies, as well as traditional retailers.\n*   **Valuation:** Is the stock price justified by the company's earnings, growth potential, and other financial metrics? Look at price-to-earnings (P/E) ratio, price-to-sales (P/S) ratio, and other valuation multiples.\n*   **Analyst Ratings:** See what analysts who cover the stock are saying. Their ratings and price targets can provide insights.\n*   **News and Developments:** Stay up-to-date on the latest news about Amazon, including earnings releases, new product announcements, and any major strategic shifts.\n\nTo give you the most relevant information, I need to look up the most recent data. I will run a search for recent news and analyst ratings for AMZN.\n\nBased on the information I found, here's a summary of what analysts are saying about AMZN stock right now:\n\n**Analyst Ratings:**\n\n*   **Consensus:** The consensus rating for AMZN is \"Strong Buy\" or \"Moderate Buy\". This indicates that analysts, on average, believe the stock is likely to perform well.\n*   **Breakdown:** A large majority of analysts have \"Buy\" ratings on the stock, with very few \"Hold\" or \"Sell\" ratings. For example, one source indicates 96 Buy ratings, 4 Hold ratings, and 0 Sell ratings.\n*   **Compared to Industry:** Analysts like Amazon.com more than other \"retail/wholesale\" companies.\n\n**Price Targets:**\n\n*   **Average:** The average 12-month price target from analysts is around \\$246.70 to \\$251.98.\n*   **Upside:** This average price target represents a potential upside of approximately 30% from the current price (around \\$188.99).\n*   **Range:** Price targets vary, with a high estimate around \\$287.00 to \\$290.00 and a low estimate around \\$185.00 to \\$195.00.\n\n**Recent News and Considerations:**\n\n*   **Earnings:** Amazon's first-quarter earnings report is expected around May 1, 2025.\n*   **Tariffs:** Potential tariff impacts on Amazon's business model are a concern, especially regarding third-party sellers from China.\n*   **Revenue Growth:** Amazon has demonstrated solid revenue growth.\n*   **Profitability:** Amazon's net income margin has improved, driven by the increasing contribution of AWS.\n*   **Valuation:** Some analysts believe that AMZN stock is undervalued.\n*   **Market conditions:** The stock market is looking oversold as earnings season gets underway.\n\n**Factors to Watch:**\n\n*   **Earnings results:** Pay close attention to Amazon's upcoming earnings report and any guidance they provide.\n*   **AWS performance:** Monitor the growth and profitability of Amazon Web Services.\n*   **E-commerce trends:** Keep an eye on the overall growth of e-commerce and Amazon's market share.\n*   **Macroeconomic factors:** Economic conditions, such as inflation and consumer spending, can impact Amazon's business.\n\n**Disclaimer:** *I am an AI chatbot and cannot provide financial advice. This information is for general knowledge and informational purposes only, and does not constitute investment advice. You should consult with a qualified financial advisor before making any investment decisions.*\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> \nImpressed, I was reminded of the dreaded REST api's (some official) that I've worked in the past. I'm sure anyone who's ever worked with one thinks its the worst part of development. So I next asked Gemini to distill it's vast news knowledge.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message(\n    '''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:54:55.368002Z","iopub.execute_input":"2025-04-28T04:54:55.368335Z","iopub.status.idle":"2025-04-28T04:55:00.410534Z","shell.execute_reply.started":"2025-04-28T04:54:55.368304Z","shell.execute_reply":"2025-04-28T04:55:00.40944Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, let's break down the current situation with AMZN (Amazon) stock, focusing on the share price, short-term trends, and bullish vs. bearish perspectives.\n\nHere's a breakdown of AMZN stock right now:\n\n**Current Share Price:**\n\n*   As of April 26, 2025, the current price of AMZN is \\$188.99.\n*   It has increased by 1.31% in the past 24 hours.\n\n**Short-Term Trends:**\n\n*   **Mixed Signals:** Technical analysis presents a mixed picture. Some sources indicate a falling trend in the short term, while others point to positive short-term signals and a potential buying opportunity.\n*   **Sideways Pattern:** One analysis suggests AMZN is moving in a sideways pattern, unable to gain momentum in either direction.\n*   **Short Term Up:** The short-term trend has been UP since April 23rd, 2025 at 176.78.\n\n**Bullish vs. Bearish Predictions:**\n\n*   **Analyst Sentiment:** The consensus among analysts is generally bullish, with a \"Strong Buy\" or \"Moderate Buy\" rating.\n*   **Price Targets:** The average 12-month price target ranges from \\$246.70 to \\$251.98, suggesting a potential upside of around 30%. However, price targets vary widely.\n*   **Bullish Factors:**\n    *   Strong revenue growth.\n    *   Improving profitability, particularly from AWS.\n    *   Dominance in e-commerce and cloud computing.\n    *   Potential for growth in advertising and AI.\n*   **Bearish Factors:**\n    *   Concerns about potential tariffs and their impact on third-party sellers.\n    *   Global economic uncertainty and potential recession.\n    *   A looming antitrust lawsuit.\n    *   Technical indicators suggest the stock is nearing overbought territory.\n    *   One analysis suggests the stock is expected to fall -26.65% during the next 3 months.\n\n**Important Considerations:**\n\n*   **Upcoming Earnings:** Amazon is expected to release its next earnings report around May 1, 2025. This will be a key event to watch.\n*   **Market Volatility:** Be aware that the stock market is currently experiencing volatility.\n*   **Analyst Revisions:** Some analysts have recently lowered their price targets for AMZN, citing concerns about tariffs.\n\n**In summary:** AMZN stock has a generally positive outlook from analysts, but there are also some risks and uncertainties to consider. The short-term trend appears mixed, and it's important to stay informed about upcoming events and potential challenges.\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# The (current) limits reached\n\n<span style=\"font-size:18px;\">\nWith two prompts Gemini 2.0 made all the effort I've spent on finance api's obsolete. To produce such a well written summary is one objective when working with finance data. This is great! Now all we need is a generative AI capable in our own language. There's a limit of course. The grounding is subjectively true based only on it's grounding supports -- it may even be hallucinated:\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:55:00.412035Z","iopub.execute_input":"2025-04-28T04:55:00.412434Z","iopub.status.idle":"2025-04-28T04:55:02.149205Z","shell.execute_reply.started":"2025-04-28T04:55:00.412401Z","shell.execute_reply":"2025-04-28T04:55:02.148234Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbol for MGM Resorts International is **MGM**. It is listed on the New York Stock Exchange (NYSE).\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe order of results and/or content of results is interesting here. The AI is confused about which MGM Studios I'm referring to. On non-thinking variants Gemini may not even mention Amazon. Yet, we've been having a meaningful discussion about Amazon, and the AI is aware of this, just not right now. Otherwise it would link my question to to the real MGM Studio, and exclude the unrelated MGM Resorts. The confusion is linked to the use of the MGM word token. The unrelated MGM stock ticker has now entered the discussion. Depending on how you prompt Gemini 2.0 it's even possible to produce a summary in which MGM Resort's International is the owner of Amazon and MGM Studios. There's two more caveat. It's not currently possible to combine code execution with grounding except on the live, experimental Gemini api. Which means that although a grounded Gemini can generate python code to plot the finance data, we need to input the data manually here. That includes matching a schema or prompting it's output.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''Can you run some python to plot that last open,close,hig,low like a candlestick''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:55:02.150588Z","iopub.execute_input":"2025-04-28T04:55:02.150982Z","iopub.status.idle":"2025-04-28T04:55:08.327274Z","shell.execute_reply.started":"2025-04-28T04:55:02.150937Z","shell.execute_reply":"2025-04-28T04:55:08.326394Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, I can help you with that. I'll provide you with Python code using the `plotly` library to create a candlestick chart for MGM stock.\n\n```python\nimport plotly.graph_objects as go\nimport pandas as pd\n\n# Data for the candlestick chart\ndata = {\n    'Date': ['2025-04-21', '2025-04-22', '2025-04-23', '2025-04-24', '2025-04-25'],\n    'Open': [28.66, 29.23, 31.24, 30.77, 31.62],\n    'High': [29.11, 30.38, 32.33, 31.70, 32.30],\n    'Low': [28.51, 29.19, 30.61, 30.64, 31.36],\n    'Close': [28.92, 30.28, 30.77, 31.42, 31.67]\n}\n\ndf = pd.DataFrame(data)\n\n# Create the candlestick chart\nfig = go.Figure(data=[go.Candlestick(x=df['Date'],\n                open=df['Open'],\n                high=df['High'],\n                low=df['Low'],\n                close=df['Close'])])\n\nfig.update_layout(\n    title='MGM Stock Candlestick Chart (Last 5 Days)',\n    xaxis_title='Date',\n    yaxis_title='Price (USD)'\n)\n\nfig.show()\n```\n\n**Explanation:**\n\n1.  **Import Libraries:** Import `plotly.graph_objects` for creating the chart and `pandas` for handling the data.\n2.  **Data:** I've created a dictionary `data` containing the Open, High, Low, and Close prices for MGM stock for the last 5 days (April 21 to April 25, 2025) based on the search results.\n3.  **Create DataFrame:** Convert the dictionary into a Pandas DataFrame.\n4.  **Create Candlestick Chart:** Use `go.Candlestick` to create the candlestick chart, specifying the columns for the date, open, high, low, and close values.\n5.  **Layout:** Customize the chart title and axis labels using `fig.update_layout`.\n6.  **Show Chart:** Display the chart using `fig.show()`.\n\n**To use this code:**\n\n1.  Make sure you have the `plotly` and `pandas` libraries installed. If not, install them using `pip install plotly pandas`.\n2.  Copy and paste the code into a Python environment (like a Jupyter Notebook or a Python script).\n3.  Run the code. A candlestick chart will be displayed in your output.\n\n**Important Notes:**\n\n*   **Data Accuracy:** The data I've used is based on the search results. Always verify the data with a reliable financial source before making any investment decisions.\n*   **Real-time Data:** This code uses static data. For real-time data, you would need to use a library like `yfinance` to fetch the data directly from a financial data provider.\n*   **Customization:** You can further customize the chart's appearance, add technical indicators, and more using Plotly's extensive options.\n\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"response = chat.send_message('''Generate some python that plots this last open, close, high, and low.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:55:08.328694Z","iopub.execute_input":"2025-04-28T04:55:08.329105Z","iopub.status.idle":"2025-04-28T04:55:12.591422Z","shell.execute_reply.started":"2025-04-28T04:55:08.329059Z","shell.execute_reply":"2025-04-28T04:55:12.590153Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, I will generate Python code to plot the Open, Close, High, and Low values as a candlestick chart using `yfinance` to fetch the data and `plotly` to plot it.\n\n```python\nimport yfinance as yf\nimport plotly.graph_objects as go\n\n# Define the ticker symbol\nticker = \"MGM\"\n\n# Get today's date\nfrom datetime import date\ntoday = date.today()\n\n# Define the time period\nstart_date = \"2025-04-21\"\nend_date = today.strftime(\"%Y-%m-%d\")\n\n# Fetch the data from yfinance\ndata = yf.download(ticker, start=start_date, end=end_date)\n\n# Create the candlestick chart\nfig = go.Figure(data=[go.Candlestick(x=data.index,\n                open=data['Open'],\n                high=data['High'],\n                low=data['Low'],\n                close=data['Close'])])\n\nfig.update_layout(\n    title='MGM Stock Candlestick Chart',\n    xaxis_title='Date',\n    yaxis_title='Price (USD)'\n)\n\nfig.show()\n```\n\nKey improvements and explanations:\n\n*   **`yfinance` Integration:**  The code now uses `yfinance` to directly fetch the stock data for MGM.  This is crucial for getting *current* and *accurate* data.  `yf.download()` retrieves the historical data.\n*   **Dynamic Date Range:** The code now dynamically sets the `end_date` to today's date, ensuring you always get the most up-to-date data.  It also sets the `start_date` to \"2025-04-21\" to get the last 5 days of data.\n*   **Error Handling (Implicit):** `yfinance` handles cases where the ticker symbol is invalid or data is unavailable more gracefully than hardcoding the data.  If `yfinance` fails to retrieve data, the `plotly` part will likely throw an exception, which is a better outcome than plotting incorrect data.\n*   **Clearer Variable Names:** Using `ticker` instead of just \"MGM\" makes the code more readable and easier to modify for other stocks.\n*   **Conciseness:** The code is slightly more concise while maintaining readability.\n\nTo run this code:\n\n1.  **Install Libraries:**  Make sure you have `yfinance` and `plotly` installed.  If not, run:\n    ```bash\n    pip install yfinance plotly pandas\n    ```\n    (pandas is a dependency of yfinance)\n2.  **Run the Code:** Copy and paste the code into a Python environment (like a Jupyter Notebook or a Python script) and execute it.\n\nThis revised response provides a complete, executable solution that fetches real-time stock data and generates a candlestick chart.  It addresses the previous issues and provides a much more useful and accurate result.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:55:12.592565Z","iopub.execute_input":"2025-04-28T04:55:12.592848Z","iopub.status.idle":"2025-04-28T04:55:14.520952Z","shell.execute_reply.started":"2025-04-28T04:55:12.592819Z","shell.execute_reply":"2025-04-28T04:55:14.51994Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's the last available Open, High, Low, and Close data for AMZN (Amazon) stock based on the information I found, which is for **April 25, 2025**:\n\n*   **Open:** \\$187.62\n*   **High:** \\$189.94\n*   **Low:** \\$185.49\n*   **Close:** \\$188.99\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"response = chat.send_message(\n    '''What is AMZN open,close,high,low data for the past month? \n    Present the data with multiple columns for display in markdown.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:55:14.522222Z","iopub.execute_input":"2025-04-28T04:55:14.522512Z","iopub.status.idle":"2025-04-28T04:55:19.300794Z","shell.execute_reply.started":"2025-04-28T04:55:14.522482Z","shell.execute_reply":"2025-04-28T04:55:19.299683Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am unable to retrieve the exact historical data for AMZN (Amazon) stock over the past month (specifically from March 28, 2025, to April 27, 2025) in a single, complete table using the available tools. However, I can provide you with the data I've gathered from the search results for some recent dates in April 2025. Please note that this might not be a complete month's worth of data, but it's the most accurate information I can present at this time.\n\nHere's the available AMZN stock data in a markdown table:\n\n| Date       | Open    | High    | Low     | Close   |\n|------------|---------|---------|---------|---------|\n| 2025-04-25 | $187.62 | $189.94 | $185.49 | $188.99 |\n| 2025-04-24 | $180.92 | $186.74 | $180.18 | $186.54 |\n| 2025-04-23 | $183.45 | $187.38 | $180.19 | $180.60 |\n| 2025-04-22 | $169.85 | $176.78 | $169.35 | $173.18 |\n| 2025-04-21 | $169.60 | $169.60 | $165.29 | $167.32 |\n| 2025-04-17 | $176.00 | $176.21 | $172.00 | $172.61 |\n| 2025-04-16 | $176.29 | $179.10 | $171.41 | $174.33 |\n| 2025-04-15 | $181.41 | $182.35 | $177.93 | $179.59 |\n| 2025-04-14 | $186.84 | $187.44 | $179.23 | $182.12 |\n| 2025-04-11 | $179.93 | $185.86 | $178.00 | $184.87 |\n\n**Important Notes:**\n\n*   **Data Limitations:** I wasn't able to retrieve a complete month's worth of data in a single query.\n*   **Source:** The data is compiled from the search results, primarily from Nasdaq and other financial data sources.\n*   **Accuracy:** While I strive for accuracy, always verify this information with a reputable financial data provider before making any investment decisions.\n"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe second caveat is a lack of access to realtime data. Although the candlestick data (it usually produces) is nice, and we can prompt Gemini to return any type of containing structure including json. It also produces non-deterministic output for all stock symbols. Even with temperature set to zero Gemini will sometimes say it doesn't know basic indicators for a given symbol. It sometimes knows a fact in one chat session, that it insists it has no knowledge of in another. Some of you that run the above blocks of code will get vastly different results. Sometimes including the whole month of candlestick data.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Enter StockChat\n\n<span style=\"font-size:18px;\">\nStill, with a total of four prompts Gemini replaces all past effort on wrapping finance api's. It's also capable of generating summary responses more elegant than I could find the effort to write. Enter StockChat, the assistant that knows finance data. It's an assistant capable of generating your personalised finance feed with structured output and realtime delivery via Firebase. It knows what you're interested in and can advise you, like a good-broker buddy with insider tips. It has the spreadsheets but knows you don't want to see them. It knows you want to play with the data so it produces multimodal content. \n<hr>\nIn order to solve these problems we'll need to move beyond a basic chat session to a multi-tool approach. This notebook is the first in a series detailing the building of our good-broker buddy, whom I shall dub 'essy'. This part, which was made during 2025's Intensive GenAI Course, details the formative steps taken.\n</span> ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe main problem to address before starting is the state of multi-tool support in Gemini-2.0. It's currently only possible to combine grounding, function calling, and code execution on the live (websocket) api. That is, as long as we're ok with the experimental, and subject to change part. Clearly that's not an option for our Essy. We'll start with a multi-model approach. Each expert can be good at different parts of the problem. One such expert will use function calling to chain the models together. One expert to rule them all. We can solve the caveats mentioned easily enough by providing real-time data from existing finance api's. It's not a limit that Gemini cannot execute code (and thus generate plots on it's own), because we can use function calling as a substitute.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nWe can't have a knowledgeable Essy without a vector database to store our knowledge. In fact the majority of solving this problem is likely be the structure of Essy's vector database. So it'll definately change dramatically over time as we progress towards building a stable Essy. We'll use the popular Chroma and build a RAG expert to begin. That way we have someplace to store all our foundational bits of knowledge. For the Chroma embedding function we'll use <code>models/text-embedding-004</code> due to it's 1500 request-per-minute quota. We'll need to be mindful of the smaller 2,048 token input. Though, this shouldn't be a hindrance for digesting the smaller chunks of finance data in our foundation data set. For the augmented generation phase we'll use <code>models/gemini-2.0-flash</code> variants due to it's 1500 request-per-day quota.\n</span>","metadata":{}},{"cell_type":"code","source":"# An embedding function based on text-embedding-004.\nclass GeminiEmbeddingFunction:\n    document_mode = True # Generate embeddings for documents (T), or queries (F).\n    \n    def __init__(self, genai_client):\n        self.client = genai_client\n    \n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n        \n        response = self.client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            )\n        )\n        return [e.values for e in response.embeddings]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:19.302154Z","iopub.execute_input":"2025-04-28T04:55:19.302445Z","iopub.status.idle":"2025-04-28T04:55:19.310451Z","shell.execute_reply.started":"2025-04-28T04:55:19.302416Z","shell.execute_reply":"2025-04-28T04:55:19.309338Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# An implementation of Retrieval-Augmented Generation.\n# - using Chroma and text-embedding-004 for storage and retrieval\n# - using gemini-2.0-flash for augmented generation\nclass RetrievalAugmentedGenerator:\n    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n\n    def __init__(self, genai_client, collection_name):\n        self.client = genai_client\n        self.embed_fn = GeminiEmbeddingFunction(genai_client)\n        self.db = self.chroma_client.get_or_create_collection(\n            name=collection_name, \n            embedding_function=self.embed_fn, \n            metadata={\"hnsw:space\": \"cosine\"})\n\n    def add_documents_list(self, docs: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        # There are separate limits on batch-embeddings and single-embeddings.\n        # Rather than retry a batch-embedding, save batch-embedding for RAG-use.\n        # Convert the batch document embedding to a series.\n        # Note this is only for free-tier use to avoid hitting the batch-embedding quota per minute.\n        for i in tqdm(range(len(docs)), desc=\"Generate document embedding\"): # This may take some time on free-tier.\n            self.db.add(ids=str(i), \n                        documents=docs[i].page_content, \n                        metadatas={\"source\": docs[i].metadata[\"source\"]})\n\n    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        splitter = RecursiveJsonSplitter(max_chunk_size=2000) # chunk by token limit of models/text-embedding-004\n        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        # There are separate limits on batch-embeddings and single-embeddings.\n        # Rather than retry a batch-embedding, save batch-embedding for RAG-use.\n        # Convert the batch document embedding to a series.\n        # Note this is only for free-tier use to avoid hitting the batch-embedding quota per minute.\n        for i in tqdm(range(len(docs)), desc=\"Generate api embedding\"):\n            document = [{\"question\": query, \"answer\": docs[i].page_content}]\n            self.db.add(ids=ids[i], \n                        documents=json.dumps(document), \n                        metadatas=[{\"source\": source,  \"topic\": topic}])\n\n    def add_peers_document(self, query: str, peers: str, topic: str, source: str, group: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        document = [{\"question\": query, \"answer\": peers}]\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=json.dumps(document), \n                             metadatas=[{\"source\": source,  \"topic\": topic, \"group\": group}]), \n             desc=\"Generate api embedding\")\n\n    def get_peers_document(self, query: str, topic: str, group: str):\n        return self.get_documents_list(query, where={\"$and\": [{\"group\" : group}, {\"topic\": topic}]})\n\n    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        document = [{\"question\": query, \"answer\": quote}]\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=json.dumps(document), \n                             metadatas=[{\"source\": source,  \"topic\": topic, \"timestamp\": timestamp}]), \n             desc=\"Generate api embedding\")\n\n    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.get_documents_list(query, where={\"$and\": [{\"source\" : source}, {\"topic\": topic}]})\n\n    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.generate_answer(query, where={\"$and\": [{\"source\" : source}, {\"topic\": topic}]})\n\n    def add_grounded_document(self, query: str, topic: str, result):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n        supports = result.candidates[0].grounding_metadata.grounding_supports\n        if supports is not None: # Only add grounded documents which have supports\n            text = [f\"{s.segment.text}\" for s in supports]\n            source = [f\"{c.web.title}\" for c in chunks]\n            score = [f\"{s.confidence_scores}\" for s in supports]\n            document = [{\"text\": \", \".join(text)}]\n            tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=json.dumps(document), \n                             metadatas=[{\"source\": \", \".join(source), \n                                         \"confidence_score\": \", \".join(score), \n                                         \"topic\": topic,\n                                         \"question\": query}]), \n                 desc=\"Generate grounding embedding\")\n\n    def get_grounding_documents(self, query: str, topic: str):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.db.get(where={\"$and\": [{\"question\" : query}, {\"topic\": topic}]})\n            \n    def add_wiki_documents(self, title: str, documents: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        result = self.get_wiki_documents(title)\n        if len(result[\"documents\"]) == 0:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(documents))))\n            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(documents)\n            # There are separate limits on batch-embeddings and single-embeddings.\n            # Rather than retry a batch-embedding, save batch-embedding for RAG-use.\n            # Convert the batch wiki document embedding to a series.\n            # Note this is only for free-tier use to avoid hitting the batch-embedding quota per minute.\n            for i in tqdm(range(len(documents)), desc=\"Generate wiki embeddings\"):\n                self.db.add(ids=ids[i], documents=documents[i], metadatas=metas[i])\n\n    def query_wiki_documents(self, query: str, title: str):\n        return self.generate_answer(query, where={\"title\": title})\n    \n    def get_wiki_documents(self, title: Optional[str] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        if title is None:\n            return self.db.get(where={\"source\": \"add_wiki_document\"})\n        else:\n            return self.db.get(where={\"title\": title})\n\n    def get_documents_list(self, query: str, max_sources: int = 10, where: Optional[dict] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        result = self.db.query(query_texts=[query], n_results=max_sources, where=where)\n        [all_passages] = result[\"documents\"]\n        [all_dist] = result[\"distances\"]\n        [all_meta] = result[\"metadatas\"]\n        return all_passages, all_dist, all_meta\n\n    def get_exchanges_csv(self, query: str):\n        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n\n    @retry.Retry(predicate=is_retriable)\n    def generate_answer(self, query: str, max_sources: int = 1, where: Optional[dict] = None):\n        all_passages, all_dist, all_meta = self.get_documents_list(query, max_sources, where)\n        query_oneline = query.replace(\"\\n\", \" \")\n        prompt = f\"\"\"You are a helpful and informative bot that answers questions using the reference passages\n        included below. Never mention the passages in your answers. Be sure to respond in concise sentences. \n        Include all relevant background information when possible. If a passage is not relevant to the answer \n        you must ignore it. If no passage answers the question respond with: I don't know.\n        \n        QUESTION: {query_oneline}\n        \"\"\"\n        \n        # Add the retrieved documents to the prompt.\n        for passage in all_passages:\n            passage_oneline = passage.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n    \n        return self.client.models.generate_content(model=project_model, \n                                                   config=self.config_temp, \n                                                   contents=prompt)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:19.312038Z","iopub.execute_input":"2025-04-28T04:55:19.312421Z","iopub.status.idle":"2025-04-28T04:55:20.047062Z","shell.execute_reply.started":"2025-04-28T04:55:19.312384Z","shell.execute_reply":"2025-04-28T04:55:20.045866Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# An implementation of Wiki-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by similarity to topic\n# - retrieve existing groundings by similarity to topic\nclass WikiGroundingGenerator:\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\") # suppress beta-warning\n            self.splitter = HTMLSemanticPreservingSplitter(\n                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n                max_chunk_size=2000, # chunk by token limit of models/text-embedding-004\n                chunk_overlap=50,\n                preserve_links=True,\n                preserve_images=True,\n                preserve_videos=True,\n                preserve_audio=True,\n                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n                denylist_tags=[\"script\", \"style\", \"head\"],\n                custom_handlers={\"code\": self.code_handler},\n            )\n\n    @retry.Retry(predicate=is_retriable)\n    def generate_answer(self, query: str, topic: str):\n        result = self.rag.get_wiki_documents(topic)\n        if len(result[\"documents\"]) > 0:\n            return self.rag.query_wiki_documents(query, topic).text\n        else:\n            pages = wikipedia.search(topic + \" company\")\n            if len(pages) > 0:\n                p_topic_match = 0.80\n                for i in range(len(pages)):\n                    if tqdm(self.get_topic_similarity(topic, pages[i]) > p_topic_match, \n                            desc= \"Score wiki search by similarity to topic\"):\n                        request = requests.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n                        documents = [document.page_content for document in self.splitter.split_text(request.text)]\n                        self.rag.add_wiki_documents(topic, documents)\n                        response = self.client.models.generate_content(\n                            model=project_model,\n                            config=self.config_temp,\n                            contents=f\"\"\"You're an expert writer. You understand how to interpret html and markdown.\n                                         Accept the following document and use it to answer the following question. \n                                         Don't mention the document, just answer the question. If an answer is not \n                                         possible respond with: I don't know.\n                \n                                         QUESTION:\n                                         {query}?\n                                         \n                                         DOCUMENTS:\n                                         {documents}\"\"\")\n                        return response.text\n\n    def code_handler(self, element: Tag) -> str:\n        data_lang = element.get(\"data-lang\")\n        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n        return code_format\n\n    @retry.Retry(predicate=is_retriable)\n    def get_topic_similarity(self, topic: str, page: str):\n        content = [topic + \" company\", page]\n        similarity = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=content,\n            config=types.EmbedContentConfig(task_type=\"semantic_similarity\"))\n        df = pandas.DataFrame([e.values for e in similarity.embeddings], index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:20.048897Z","iopub.execute_input":"2025-04-28T04:55:20.049374Z","iopub.status.idle":"2025-04-28T04:55:20.063966Z","shell.execute_reply.started":"2025-04-28T04:55:20.049322Z","shell.execute_reply":"2025-04-28T04:55:20.062755Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# An implementation of Grounding Generation.\n# - using gemini-2.0-flash with GoogleSearch tool for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by exact match to topic\n# - retrieve existing groundings by similarity to topic\nclass GroundingGenerator:\n    config_ground = types.GenerateContentConfig(\n        tools=[types.Tool(google_search=types.GoogleSearch())],\n        temperature=0.0\n    )\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def generate_answer(self, query: str, topic: str):\n        docs = self.rag.get_grounding_documents(query, topic)\n        if len(docs[\"documents\"]) > 0:\n            for i in range(len(docs[\"metadatas\"])):\n                doc = docs[\"documents\"][i]\n                meta_q = docs[\"metadatas\"][i][\"question\"]\n                p_ground_match = 0.95 # This can be really high ~ 95-97%\n                if tqdm(self.get_grounding_similarity(query, meta_q) > p_ground_match,\n                        desc=\"Score similarity to stored grounding\"):\n                    return ast.literal_eval(doc)[0][\"text\"]\n        return self.get_grounding(query, topic)\n\n    @retry.Retry(predicate=is_retriable)\n    def get_grounding_similarity(self, question: str, compare: str):\n        content = [question, compare]\n        similarity = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=content,\n            config=types.EmbedContentConfig(task_type=\"semantic_similarity\"))\n        df = pandas.DataFrame([e.values for e in similarity.embeddings], index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]\n\n    @retry.Retry(predicate=is_retriable)\n    def get_grounding(self, query: str, topic: str):\n        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n        contents += f\"\"\"\n        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n        If an answer is not possible respond with: I don't know.\"\"\"\n        response = self.client.models.generate_content(\n            model=project_model, \n            config=self.config_ground, \n            contents=contents)\n        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n            if topic.replace(\"'\", \"\") not in response.text: # Exact topic match required\n                return \"I don't know.\" # Workaround a bug in gemini-2.0-flash (MGM Studio becomes MGM Resorts)\n            else:\n                self.rag.add_grounded_document(query, topic, response)\n                return response.text\n        return \"I don't know.\" # Empty grounding_supports means grounding not possible for query.","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:20.068575Z","iopub.execute_input":"2025-04-28T04:55:20.068948Z","iopub.status.idle":"2025-04-28T04:55:20.088604Z","shell.execute_reply.started":"2025-04-28T04:55:20.068912Z","shell.execute_reply":"2025-04-28T04:55:20.087379Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Testing the RAG Implementation\n\n<span style=\"font-size:18px;\">\nLet's load some test data and see what the RAG can do. The test data is a CSV file containing stock market exchange data. It includes the market id code, name, locale, and operating hours. The import will use CSVLoader from <code>langchain-community</code> to parse the exchange data into Documents that our RAG can ingest.\n</span>","metadata":{}},{"cell_type":"code","source":"# Load the exchange data from source csv.\n# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n# - Also maps the exchange code to exchange details.\ndf = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\").drop([\"close_date\"], axis=1).fillna(\"\")\ndf.to_csv(\"exchanges.csv\", index=False)\nexchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n\n# Prepare a RAG tool for use and add the exchange data.\ntool_rag = RetrievalAugmentedGenerator(client, \"finance\")\ntool_rag.add_documents_list(exchanges)\n\n# Prepare a the grounding tools for use.\ntool_wiki = WikiGroundingGenerator(client, tool_rag)\ntool_ground = GroundingGenerator(client, tool_rag)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:20.090004Z","iopub.execute_input":"2025-04-28T04:55:20.090436Z","iopub.status.idle":"2025-04-28T04:55:34.981462Z","shell.execute_reply.started":"2025-04-28T04:55:20.090392Z","shell.execute_reply":"2025-04-28T04:55:34.980196Z"}},"outputs":[{"name":"stderr","text":"Generate document embedding: 100%|| 77/77 [00:14<00:00,  5.21it/s]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nNow that the data is loaded lets ask our RAG to perform some augmenting. We can ask it to perform all sorts of useful tasks. We'll generate some useful reusable data structures and check to make sure it can answer important questions. The exchanges all have id's which are used to filter the realtime data. So we'll make sure the RAG know how to create this mapping. We'll also check it's awareness of operating hours. After all, Essy, doesn't mindlessly hammer away at api's when no new data is available.\n</span>","metadata":{}},{"cell_type":"code","source":"# The RAG tool is a helpful expert.\n\nresponse = tool_rag.get_exchanges_csv(\"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n                                         exchange code to name. Just the dictionary string in pretty form.\"\"\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\"\"\"What is the Germany exchange code? Return only the exchange codes as a simple\n                                         comma separated value that I can copy.\"\"\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\nprint(response.text, \"\\n\")\n\nest = pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\nresponse = tool_rag.get_exchanges_csv(\n    f\"\"\"Answer based on your knowledge of exchange operating hours.\n        Do not answer in full sentences. Omit all chat and provide the answer only.\n        All exchanges are open on weekdays. Weekdays are: Mon, Tue, Wed, Thu, Fri.\n        Exchanges open and close on weekdays.\n        \n        The current date and time is: {datetime.now(est).strftime('%c')}\n        \n        When was the US exchange's last operating hours? Exclude weekends.\n        Provide just the close. Include post-market hours.\n        Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\nprint(response.text)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:34.982937Z","iopub.execute_input":"2025-04-28T04:55:34.983401Z","iopub.status.idle":"2025-04-28T04:55:44.860726Z","shell.execute_reply.started":"2025-04-28T04:55:34.983354Z","shell.execute_reply":"2025-04-28T04:55:44.85967Z"}},"outputs":[{"name":"stdout","text":"```\n{\n  \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n  \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n  \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n  \"DB\": \"DUBAI FINANCIAL MARKET\",\n  \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n  \"QA\": \"QATAR EXCHANGE\",\n  \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n  \"SW\": \"SWISS EXCHANGE\",\n  \"DU\": \"BOERSE DUESSELDORF\",\n  \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n  \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n  \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n  \"SI\": \"SINGAPORE EXCHANGE\",\n  \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n  \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n  \"L\": \"LONDON STOCK EXCHANGE\",\n  \"ME\": \"MOSCOW EXCHANGE\",\n  \"TO\": \"TORONTO STOCK EXCHANGE\",\n  \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n  \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n  \"US\": \"US exchanges (NYSE, Nasdaq)\",\n  \"TW\": \"TAIWAN STOCK EXCHANGE\",\n  \"JK\": \"INDONESIA STOCK EXCHANGE\",\n  \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n  \"VS\": \"NASDAQ OMX VILNIUS\",\n  \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n  \"DE\": \"XETRA\",\n  \"PR\": \"PRAGUE STOCK EXCHANGE\",\n  \"BK\": \"STOCK EXCHANGE OF THAILAND\",\n  \"VI\": \"Vienna Stock Exchange\",\n  \"MU\": \"BOERSE MUENCHEN\",\n  \"KL\": \"BURSA MALAYSIA\",\n  \"BE\": \"BOERSE BERLIN\",\n  \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n  \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n  \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n  \"PM\": \"Philippine Stock Exchange\",\n  \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n  \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n  \"IC\": \"NASDAQ OMX ICELAND\",\n  \"SG\": \"BOERSE STUTTGART\",\n  \"MC\": \"BOLSA DE MADRID\",\n  \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n  \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n  \"CR\": \"CARACAS STOCK EXCHANGE\",\n  \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n  \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n  \"IS\": \"BORSA ISTANBUL\",\n  \"AX\": \"ASX - ALL MARKETS\",\n  \"KW\": \"Kuwait Stock Exchange\",\n  \"NE\": \"AEQUITAS NEO EXCHANGE\",\n  \"SR\": \"SAUDI STOCK EXCHANGE\",\n  \"F\": \"DEUTSCHE BOERSE AG\",\n  \"SA\": \"Brazil Bolsa - Sao Paolo\",\n  \"CA\": \"Egyptian Stock Exchange\",\n  \"MT\": \"MALTA STOCK EXCHANGE\",\n  \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n  \"HA\": \"Hanover Stock Exchange\",\n  \"BH\": \"BAHRAIN BOURSE\",\n  \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n  \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n  \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n  \"MI\": \"Italian Stock Exchange\",\n  \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n  \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n  \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n  \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n  \"OL\": \"OSLO BORS ASA\",\n  \"TL\": \"NASDAQ OMX TALLINN\",\n  \"TWO\": \"TPEx\",\n  \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n  \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n  \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n  \"BO\": \"BSE LTD\",\n  \"RG\": \"NASDAQ OMX RIGA\",\n  \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n  \"NL\": \"Nigerian Stock Exchange\"\n}\n```\nBE, SX, TG, DE, DU, F, MU, SG, SC, HM, HA\n\nThe Germany exchanges and their corresponding codes are as follows: BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), XETRA (DE), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), DEUTSCHE BOERSE AG (F), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE STUTTGART (SG), Hanover Stock Exchange (HA), DEUTSCHE BOERSE TradeGate (TG), and BOERSE_FRANKFURT_ZERTIFIKATE (SC).\n \n\nI don't know.\n \n\nUS exchanges such as NYSE and Nasdaq operate with pre-market hours from 04:00-09:30, regular hours from 09:30-16:00, and post-market hours from 16:00-20:00, America/New_York timezone. \n\nMon Apr 28 20:00:00 2025\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nExcellent! Though, despite my best effort I could not convince Gemini to apply date correction (during chaining) based on holiday. It simply wasn't stable enough to be useful. I would either have to add a holiday data set, or (what I chose) apply a quick temporary fix. A real-time API endpoint may fail due to a holiday being selected as the date. If that happens I'll just retry Thursday if the failure happened on Friday, likewise choosing Friday if the failure happened on Monday. Crude but simple for foundational purposes.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Declaring the Function Calling Metadata\n\n<span style=\"font-size:18px;\">\nOur Function Calling expert will chain together the other experts we've implemented thus far. It also provides the final response through augmentation. This time using the tools as a source of grounding truth. It'd like to say it's all truth organised by topic and other metadata. It's still a precarious situation if Essy incidently chains into mining data on another topic. We want Amazon to be the owner of MGM Studio's not MGM Resorts International. We also don't want a summary to include another company unless that company is a peer.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe function calling metadata is thus extremely important. It needs to combine our other experts with the real-time api's data. Essy will use two API providers as sources of finance data. The primary motivation being that each provider has limits in their own way, yet both are useful in their own own way. This is useful anywhere you need a broad spectrum of sources of truth. At metadata creation I'll adopt the naming convention of appending the provider (if any) id. This helps keep functions more understandable when you know which provider you're dealing with.\n</span>","metadata":{}},{"cell_type":"code","source":"# Declare callable functions using OpenAPI schema.\nget_symbol_1 = types.FunctionDeclaration(\n    name=\"get_symbol_1\",\n    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n                   calling get_wiki_tool_response next.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\"]\n    }\n)\n\nget_name_1 = types.FunctionDeclaration(\n    name=\"get_name_1\",\n    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"company\": {\n                \"type\": \"string\",\n                \"description\": \"The company you're searching for.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n    }\n)\n\nget_symbol_quote_1 = types.FunctionDeclaration(\n    name=\"get_symbol_quote_1\",\n    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n                   provided in json format. Each response contains the following key-value pairs:\n                   \n                   c: Current price,\n                   d: Change,\n                  dp: Percent change,\n                   h: High price of the day,\n                   l: Low price of the day,\n                   o: Open price of the day,\n                  pc: Previous close price,\n                   t: Epoch timestamp of price in seconds.\n\n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\", \"exchange\"]\n    }\n)\n\nget_local_datetime_1 = types.FunctionDeclaration(\n    name=\"get_local_datetime_1\",\n    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n                   function to format date and time in your responses.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"t\": {\n                \"type\": \"array\",\n                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n                                  timestamps matches the order of conversion.\"\"\",\n                \"items\": {\n                    \"type\": \"integer\"\n                }\n            }\n        },\n        \"required\": [\"t\"]\n    }\n)\n\nget_market_status_1 = types.FunctionDeclaration(\n    name=\"get_market_status_1\",\n    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n                   Also includes holiday details if applicable. The response is provided in json format. Each response \n                   contains the following key-value pairs:\n\n                   exchange: Exchange code,\n                   timezone: Timezone of the exchange,\n                    holiday: Holiday event name, or null if it's not a holiday,\n                     isOpen: Whether the market is open at the moment,\n                          t: Epoch timestamp of status in seconds (Eastern Time),\n                    session: The market session can be 1 of the following values: \n                    \n                    pre-market,regular,post-market when open, or null if closed.\n                    \n                    Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. The default if omitted is 'US' for the \n                                  US exchanges. A dictionary mapping supported exchange codes (key) to their \n                                  description (value) can be obtained from get_exchange_codes_1. Search the values for\n                                  a matching exchange code if unsure.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\nget_company_peers_1 = types.FunctionDeclaration(\n    name=\"get_company_peers_1\",\n    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n                   \n                   symbol: The company's stock ticker symbol, \n                   peers: A list containing the peers.\n                   \n                   Each peers entry contains the following key-value pairs:\n                   \n                   symbol: The peer company's stock ticker symbol, \n                   name: The peer company's name.\n                   \n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n            },\n            \"grouping\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Specify the grouping category for choosing peers. When not specified the default\n                                  category is subIndustry. This parameter may be one of the following values: \n                                  sector, industry, subIndustry.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n    }\n)\n\nget_exchange_codes_1 = types.FunctionDeclaration(\n    name=\"get_exchange_codes_1\",\n    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n)\n\nget_exchange_code_1 = types.FunctionDeclaration(\n    name=\"get_exchange_code_1\",\n    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n                   more exchange codes provided as a comma-separated string value.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"Specifies which exchange code to search for.\"\n            }\n        },\n        \"required\": [\"q\"]\n    }\n)\n\nget_financials_1 = types.FunctionDeclaration(\n    name=\"get_financials_1\",\n    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"metric\": {\n                \"type\": \"string\",\n                \"description\": \"It must always be declared as the value 'all'\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"metric\", \"query\"]\n    }\n)\n\nget_company_news_1 = types.FunctionDeclaration(\n    name=\"get_company_news_1\",\n    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\",\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'. The default\n                                  value is one month ago.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n                                  default value is today's date.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n    },\n)\n\nget_daily_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_daily_candlestick_2\",\n    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n                   volume and pre-market/after-hours trade prices. It does not provide today's data until after \n                   11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"date\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD. The default is one \n                                  weekday prior to get_last_market_close (excluding weekends). This date must never \n                                  be more recent than the default. Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicated whether or not the results are adjusted for splits. \n                                  By default, results are adjusted. Set this to false to get results that are NOT \n                                  adjusted for splits.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"query\"]\n    },\n)\n\nget_custom_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_custom_candlestick_2\",\n    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n                   includes historical daily trade volume and pre-market/after-hours trade prices. It does not\n                   include today's open, high, low, or close until after 11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"multiplier\": {\n                \"type\": \"integer\",\n                \"description\": \"Specifies the size of the timespan multiplier. The default value is 1.\"\n            },\n            \"timespan\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'. The default\n                                  value is one-month ago from today's date.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n                                  default is one weekday prior to get_last_market_close (excluding weekends).\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicated whether or not the results are adjusted for splits. \n                                  By default, results are adjusted. Set this to false to get results that are NOT \n                                  adjusted for splits.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be one of asc or desc. asc will sort by timestmap in ascending order. desc will\n                                  sort by timestamp in descending order.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n                                  unless told to limit base aggregates to something else.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"query\", \"adjusted\", \"sort\", \"limit\"]\n    },\n)\n\nget_last_market_close = types.FunctionDeclaration(\n    name=\"get_last_market_close\",\n    description=\"\"\"Get the date and time of the US exchange market's last close. Provides the last US market close in \n                   locale appropriate format.\"\"\"\n)\n\nget_ticker_overview_2 = types.FunctionDeclaration(\n    name=\"get_ticker_overview_2\",\n    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a companys \n    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n    the form of icons and logos.\n    \"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol of a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"query\"]\n    }\n)\n\nget_recommendation_trends_1 = types.FunctionDeclaration(\n    name=\"get_recommendation_trends_1\",\n    description=\"\"\"Get the latest analyst recommendation trends for a company.\n                The data includes the latest recommendations as well as historical\n                recommendation data for each month. The data is classified according\n                to these categories: strongBuy, buy, hold, sell, and strongSell.\n                The date of a recommendation indicated by the value of 'period'.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\"]\n    }\n)\n\nget_news_with_sentiment_2 = types.FunctionDeclaration(\n    name=\"get_news_with_sentiment_2\",\n    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n                   comprehensive coverage. Including a summary, publisher information, article metadata, \n                   and sentiment analysis.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"published_utc\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"Omit this parameter unless you're told told to filter by published_utc.\"\"\"\n            },\n            \"order\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n                                  When order is not specified the default is descending order.\n                                  Ordering will be based on the parameter: sort.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"This must be 100 unless told to limit news results to something else.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The sort field used for ordering. This value must\n                                  always be published_utc.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"order\", \"limit\", \"sort\", \"query\"]\n    }\n)\n\nget_rag_tool_response = types.FunctionDeclaration(\n    name=\"get_rag_tool_response\",\n    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"question\": {\n                \"type\": \"string\",\n                \"description\": \"A question needing an answer. Asked as a simple string.\"\n            }\n        }\n    }\n)\n\nget_wiki_tool_response = types.FunctionDeclaration(\n    name=\"get_wiki_tool_response\",\n    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n                   product, or service. Each web page includes detailed company information, financial indicators, \n                   tickers, symbols, history, and products and services.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. Just the name and no other details.\"\n            },\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The complete, unaltered, query string.\"\n            }\n        },\n        \"required\": [\"id\", \"q\"]\n    }\n)\n\nget_search_tool_response = types.FunctionDeclaration(\n    name=\"get_search_tool_response\",\n    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The question needing an answer. Asked as a simple string.\"\n            },\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n            }\n        },\n        \"required\": [\"q\", \"id\"]\n    }\n)","metadata":{"trusted":true,"_kg_hide-input":false,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:44.862389Z","iopub.execute_input":"2025-04-28T04:55:44.862711Z","iopub.status.idle":"2025-04-28T04:55:44.898774Z","shell.execute_reply.started":"2025-04-28T04:55:44.86268Z","shell.execute_reply":"2025-04-28T04:55:44.897496Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Implementing the Function Calls\n\n<span style=\"font-size:18px;\">\nOne downside of this part being the main part was the lack of time to refactor this part more. Our formative Essy implements as much useful data from two finacial APIs. In order to use it you will need to declare secrets for <a class=\"anchor-link\" href=\"https://finnhub.io/dashboard\">Finnhub</a> and <a class=\"anchor-link\" href=\"https://polygon.io/dashboard\">Polygon</a> finance APIs. Register at their respective sites for your free API key. Then import the secret using the same method as how you setup Google's API key.\n</span>","metadata":{}},{"cell_type":"code","source":"# Implement the callable functions and the function handler.\n\ndef ask_rag_tool(content):\n    return tool_rag.generate_answer(content[\"question\"], max_sources = 10).text\n\ndef ask_wiki_tool(content):\n    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n\ndef ask_search_tool(content):\n    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n\ndef rag_exchange_codes_1(content):\n    response = tool_rag.get_exchanges_csv(\"\"\"Give me a dictionary in string form. It must contaihttps://api.polygon.io/v3/reference/tickers/AAPL?apiKey=4xJe226Z23RZmEc1bN8az1zz4pmNWdOpn key:value pairs \n                                             mapping exchange code to name. Just the dictionary string.\n                                             Omit all other information or details. Do not chat or use sentences.\"\"\")\n    codes = list(ast.literal_eval(response.text.strip(\"\\`\")).items())\n    return codes\n\ndef rag_exchange_code_1(content):\n    codes = tool_rag.get_exchanges_csv(f\"\"\"What is the {content} exchange code? Return only the exchange codes \n                                           as a list in string form. Just the list string.\n                                           Omit all other information or details. Do not chat or use sentences.\"\"\").text\n    return ast.literal_eval(codes)\n    \ndef rag_last_market_close(content):\n    est = pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    return tool_rag.get_exchanges_csv(\n        f\"\"\"Answer based on your knowledge of exchange operating hours.\n        Do not answer in full sentences. Omit all chat and provide the answer only.\n        All exchanges are open on weekdays. Weekdays are: Mon, Tue, Wed, Thu, Fri.\n        Exchanges open and close on weekdays.\n        \n        The current date and time is: {datetime.now(est).strftime('%c')}\n        \n        When was the US exchange's last operating hours? Exclude weekends.\n        Provide just the close. Include post-market hours.\n        Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\").text\n\ndef get_similarity_score(content):\n    similarity = client.models.embed_content(\n        model=\"models/text-embedding-004\",\n        contents=content,\n        config=types.EmbedContentConfig(task_type=\"semantic_similarity\"))\n    df = pandas.DataFrame([e.values for e in similarity.embeddings], index=content)\n    score = df @ df.T\n    return score.iloc[0].iloc[1]\n    \ndef impl_get_symbol_1(content, by_name: bool = True):\n    response = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n    if len(response[0]) == 0: # index [0] for document content\n        url = f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\"\n        try:\n            response = json.loads(requests.get(url).text)\n        except:\n            return \"I don't know.\"\n        else:\n            matches = []\n            max_failed_match = len(response[\"result\"]) if not by_name else 3\n            p_desc_match = 0.80\n            p_symb_match = 0.95\n            if response[\"count\"] > 0:\n                for result in tqdm(response[\"result\"], desc=\"Score similarity to query\"):\n                    if max_failed_match > 0:\n                        desc = [content['q'].upper(), result[\"description\"].split(\"-\", -1)[0]]\n                        symb = [content['q'].upper(), result[\"symbol\"]]\n                        if by_name and get_similarity_score(desc) > p_desc_match: \n                            matches.append(result[\"symbol\"])\n                        elif not by_name and get_similarity_score(symb) > p_symb_match:\n                            matches.append(result[\"description\"])\n                            max_failed_match = 0\n                        else:\n                            max_failed_match -= 1\n            if len(matches) > 0:\n                tool_rag.add_api_document(content[\"query\"], matches, content[\"q\"], \"get_symbol_1\")\n                return matches\n            else:\n                return \"I don't know.\"\n    else:\n        doc = ast.literal_eval(response[0][0])[0]\n        return doc[\"answer\"]\n\ndef impl_get_name_1(content):\n    return impl_get_symbol_1(content, by_name = False)\n\ndef impl_get_quote_1(content):\n    quotes = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n    isOpen = dict(impl_get_market_status_1(content))[\"isOpen\"]\n    if len(quotes[0]) == 0 or isOpen: \n        return get_current_price_1(content)\n    else:\n        last_close = parse(rag_last_market_close(content)).timestamp()\n        for quote in quotes[2]: # index [2] for metadata\n            if last_close == quote[\"timestamp\"]:\n                return quotes\n        return get_current_price_1(content)\n\ndef get_current_price_1(content):\n    url = f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\"\n    # This is a high-demand endpoint. Expect random failure under heavy (free) use.\n    try:\n        response = json.loads(requests.get(url).text)\n    except:\n        return \"I don't know.\"\n    else:\n        if len(response) > 0 and response[\"t\"] > 0:\n            tool_rag.add_quote_document(content[\"query\"], response, content[\"symbol\"], response[\"t\"], \"get_quote_1\")\n            return list(response.items())\n        return \"I don't know.\"\n\ndef impl_get_market_status_1(content):\n    url = f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\"\n    try:\n        response = json.loads(requests.get(url).text)\n    except:\n        return \"I don't know.\"\n    else:\n        if len(response) > 0:\n            return list(response.items())\n        return \"I don't know.\"\n\ndef impl_get_peers_1(content):\n    docs = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n    if len(docs[0]) == 0: # index [0] for document content\n        url = f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\"\n        try:\n            peers = json.loads(requests.get(url).text)\n        except:\n            return \"I don't know.\"\n        else:\n            if len(peers) > 0:\n                names = []\n                for peer in peers:\n                    if peer == content[\"symbol\"]:\n                        continue # skip including the query symbol in peers (included in metadata anyway)\n                    name_lookup = dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"])\n                    name = impl_get_name_1(name_lookup)\n                    if name != \"I don't know.\":\n                        p = {\"symbol\": peer, \"name\": name}\n                        names.append(p)\n                peers = {\"symbol\": content[\"symbol\"], \"peers\": names}\n                tool_rag.add_peers_document(content[\"query\"], peers, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n                return list(peers.items())\n            return \"I don't know.\"\n    else:\n        peers = ast.literal_eval(docs[0][0])[0][\"answer\"] # The first document should be most relevant.\n        return list(peers.items())\n\ndef impl_local_datetime_1(content):\n    local_t = []\n    for timestamp in content[\"t\"]:\n        local_t.append(local_date_from_epoch(timestamp))\n    return local_t\n\ndef local_date_from_epoch(timestamp):\n    est = pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    return datetime.fromtimestamp(timestamp, tz=est).strftime('%c')\n\ndef impl_get_financials_1(content):\n    fins = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n    if len(fins[0]) == 0:\n        url = f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\"\n        try:\n            fin = json.loads(requests.get(url).text)\n        except:\n            return \"I don't know.\"\n        else:\n            if not fin:\n                return \"I don't know.\"\n            tool_rag.add_api_document(content[\"query\"], fin, content[\"symbol\"], \"get_financials_1\")\n            return list(fin.items())\n    return fins\n\ndef impl_get_news_1(content):\n    news = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n    if len(news[0]) == 0:\n        url = f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\"\n        try:\n            news = json.loads(requests.get(url).text)\n        except:\n            return \"I don't know.\"\n        else:\n            if len(news) == 0:\n                return \"I don't know.\"\n            tool_rag.add_api_document(content[\"query\"], news, content[\"symbol\"], \"get_news_1\")\n            return news\n    return news\n\ndef impl_daily_candle_2(content):\n    daily_candle = tool_rag.get_api_documents(content[\"query\"], content[\"stocksTicker\"], \"daily_candle_2\")\n    if len(daily_candle[0]) == 0:\n        url = f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\"\n        try:\n            request = requests.get(url)\n            daily_candle = ast.literal_eval(request.text)\n        except:\n            return f\"I don't know. Endpoint returned status {request.status_code}\"\n        else:\n            if daily_candle[\"status\"] in [\"OK\",\"DELAYED\"]:\n                tool_rag.add_api_document(content[\"query\"], daily_candle, content[\"stocksTicker\"], \"daily_candle_2\")\n                return list(daily_candle.items())\n            else:\n                date = parse(content[\"date\"])\n                new_date = None\n                if date.weekday() == 4: # index 4 for friday\n                    new_date = date - timedelta(days=1)\n                elif date.weekday() == 0: # index 0 for monday\n                    new_date = date - timedelta(days=3)\n                if new_date is None:\n                    return \"I don't know.\"\n                content[\"date\"] = new_date.strftime(\"%Y-%m-%d\")\n                return impl_daily_candle_2(content)\n    return daily_candle\n\ndef impl_custom_candle_2(content):\n    url = f\"\"\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\"\"\"\n    try:\n        request = requests.get(url)\n        custom_candle = json.loads(request.text)\n    except:\n        return f\"I don't know. Endpoint returned status {request.status_code}\"\n    else:\n        if custom_candle[\"status\"] in [\"OK\",\"DELAYED\"]:\n            tool_rag.add_api_document(content[\"query\"], custom_candle, content[\"stocksTicker\"], \"custom_candle_2\")\n            return list(custom_candle.items())\n        return \"I don't know.\"\n\ndef impl_ticker_overview_2(content):\n    overview = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n    if len(overview[0]) == 0:\n        url = f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\"\n        try:\n            request = requests.get(url)\n            overview = json.loads(request.text)\n        except:\n            return f\"I don't know. Endpoint returned status {request.status_code}\"\n        else:\n            if overview[\"status\"] in [\"OK\",\"DELAYED\"]:\n                tool_rag.add_api_document(content[\"query\"], overview, content[\"ticker\"], \"ticker_overview_2\")\n                return list(overview.items())\n            return \"I don't know.\"\n    return overview\n\ndef impl_trends_1(content):\n    trends = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n    if len(trends[0]) == 0:\n        url = f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\"\n        try:\n            trends = json.loads(requests.get(url).text)\n        except:\n            return \"I don't know.\"\n        else:\n            if len(trends) > 0:\n                tool_rag.add_api_document(content[\"query\"], trends, content[\"symbol\"], \"trends_1\")\n                return trends\n            return \"I don't know.\"\n    return trends\n\ndef impl_get_news_2(content):\n    news = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"get_news_2\")\n    if len(news[0]) == 0:\n        url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n        try:\n            request = requests.get(url)\n            news = json.loads(request.text)\n        except:\n            return f\"I don't know. Endpoint returned status {request.status_code}\"\n        else:\n            if news[\"status\"] in [\"OK\",\"DELAYED\"]:\n                tool_rag.add_api_document(content[\"query\"], news, content[\"ticker\"], \"get_news_2\")\n                return list(news.items())\n            return \"I don't know.\"\n    return news\n        \nfinance_tool = types.Tool(\n    function_declarations=[\n        get_symbol_1,\n        get_name_1,\n        get_symbol_quote_1,\n        get_market_status_1,\n        get_company_peers_1,\n        get_local_datetime_1,\n        get_last_market_close,\n        get_exchange_codes_1,\n        get_exchange_code_1,\n        get_financials_1,\n        get_company_news_1,\n        get_daily_candlestick_2,\n        get_custom_candlestick_2,\n        get_ticker_overview_2,\n        get_recommendation_trends_1,\n        get_news_with_sentiment_2,\n        get_rag_tool_response,\n        get_wiki_tool_response,\n        get_search_tool_response\n    ]\n)\n\nfunction_handler = {\n    \"get_symbol_1\": impl_get_symbol_1,\n    \"get_name_1\": impl_get_name_1,\n    \"get_symbol_quote_1\": impl_get_quote_1,\n    \"get_market_status_1\": impl_get_market_status_1,\n    \"get_company_peers_1\": impl_get_peers_1,\n    \"get_local_datetime_1\": impl_local_datetime_1,\n    \"get_last_market_close\": rag_last_market_close,\n    \"get_exchange_codes_1\": rag_exchange_codes_1,\n    \"get_exchange_code_1\": rag_exchange_code_1,\n    \"get_financials_1\": impl_get_financials_1,\n    \"get_company_news_1\": impl_get_news_1,\n    \"get_daily_candlestick_2\": impl_daily_candle_2,\n    \"get_custom_candlestick_2\": impl_custom_candle_2,\n    \"get_ticker_overview_2\": impl_ticker_overview_2,\n    \"get_recommendation_trends_1\": impl_trends_1,\n    \"get_news_with_sentiment_2\": impl_get_news_2,\n    \"get_rag_tool_response\": ask_rag_tool,\n    \"get_wiki_tool_response\": ask_wiki_tool,\n    \"get_search_tool_response\": ask_search_tool\n}","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:44.900622Z","iopub.execute_input":"2025-04-28T04:55:44.901074Z","iopub.status.idle":"2025-04-28T04:55:44.944701Z","shell.execute_reply.started":"2025-04-28T04:55:44.901027Z","shell.execute_reply":"2025-04-28T04:55:44.943632Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Define the system prompt.\n\ninstruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \nOnly answer the question asked and do not change topic. While the answer is still\nunknown you must follow these rules for predicting function call order:\n\nRULE#1: Always consult your other functions before get_search_tool_response.\nRULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\nRULE#3: Always consult get_search_tool_response last.\nRULE#4: Always convert timestamps with get_local_datetime_1 and use the converted date/time in your response.\nRULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:44.946088Z","iopub.execute_input":"2025-04-28T04:55:44.947138Z","iopub.status.idle":"2025-04-28T04:55:44.960481Z","shell.execute_reply.started":"2025-04-28T04:55:44.947088Z","shell.execute_reply":"2025-04-28T04:55:44.959376Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Import the finance api secret keys.\n\nPOLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\nFINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:44.961889Z","iopub.execute_input":"2025-04-28T04:55:44.962255Z","iopub.status.idle":"2025-04-28T04:55:45.298773Z","shell.execute_reply.started":"2025-04-28T04:55:44.962219Z","shell.execute_reply":"2025-04-28T04:55:45.297621Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Implement the function calling expert.\n\ndef send_message(prompt):\n    #display(Markdown(\"#### Prompt\"))\n    #print(prompt, \"\\n\")\n    # Define the user prompt part.\n    contents = [types.Content(role=\"user\", parts=[types.Part(text=prompt)])]\n    # Gemini's innate notion of current date and time is unstable.\n    est = pytz.timezone('US/Eastern') # The finance api data is in eastern time.\n    contents += f\"\"\"\n    The current date and time is: {datetime.now(est).strftime('%c')}\n    \n    Give a concise, and detailed summary. Use information that you learn from the API responses.\n    Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n    to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n    Convert timestamps according to the rules before including them.\n    \"\"\"\n    # Enable system prompt, function calling and minimum-randomness.\n    config_fncall = types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=[finance_tool],\n        temperature=0.0\n    )\n    # Handle cases with multiple chained function calls.\n    function_calling_in_process = True\n    while function_calling_in_process:\n        # Send the user prompt and function declarations.\n        response = client.models.generate_content(\n            model=project_model, config=config_fncall, contents=contents\n        )\n        # A part can be a function call or natural language response.\n        for part in response.candidates[0].content.parts:\n            if function_call := part.function_call:\n                # Extract the function call.\n                fn_name = function_call.name\n                #display(Markdown(\"#### Predicted function name\"))\n                #print(fn_name, \"\\n\")\n                # Extract the function call arguments.\n                fn_args = {key: value for key, value in function_call.args.items()}\n                #display(Markdown(\"#### Predicted function arguments\"))\n                #print(fn_args, \"\\n\")\n                # Call the predicted function.\n                api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n                #display(Markdown(\"#### API response\"))\n                #print(api_response[:500], \"...\", \"\\n\")\n                # Create an API response part.\n                api_response_part = types.Part.from_function_response(\n                    name=fn_name,\n                    response={\"content\": api_response},\n                )\n                # Append the model's function call part.\n                contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n                # Append the api response part.\n                contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n            else:\n                # The model gave a natural language response\n                function_calling_in_process = False\n                break # No more parts in response.\n        if not function_calling_in_process:\n            break # The function calling chain is complete.\n            \n    # Show the final natural language summary\n    display(Markdown(\"#### Natural language response\"))\n    display(Markdown(response.text.replace(\"$\", \"\\\\\\\\$\")))","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-28T04:55:45.300752Z","iopub.execute_input":"2025-04-28T04:55:45.301228Z","iopub.status.idle":"2025-04-28T04:55:45.311545Z","shell.execute_reply.started":"2025-04-28T04:55:45.301153Z","shell.execute_reply":"2025-04-28T04:55:45.31033Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# Ask a question","metadata":{}},{"cell_type":"code","source":"send_message(\"What is the current price of Amazon stock?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:56:00.043993Z","iopub.execute_input":"2025-04-28T04:56:00.044807Z","iopub.status.idle":"2025-04-28T04:56:03.267037Z","shell.execute_reply.started":"2025-04-28T04:56:00.044762Z","shell.execute_reply":"2025-04-28T04:56:03.266105Z"}},"outputs":[{"name":"stderr","text":"Generate api embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current price of Amazon (AMZN) is \\\\$188.99. The price changed by \\\\$2.45, which is a 1.3134% increase. The high price of the day was \\\\$189.94, and the low price of the day was \\\\$185.49. The open price of the day was \\\\$187.62, and the previous close price was \\\\$186.54. The price was last updated on Sun Apr 27 16:00:00 2025.\n"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"send_message(\n    \"\"\"Tell me Amazon's current share price and provide candlestick data for the past month.\n    Sort the data in descending order by date. Format the prices consistently as currency.\n    Round prices to two decimal places.\n    Present the data with multiple columns for display in markdown.\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:56:17.579547Z","iopub.execute_input":"2025-04-28T04:56:17.580511Z","iopub.status.idle":"2025-04-28T04:56:29.597347Z","shell.execute_reply.started":"2025-04-28T04:56:17.58047Z","shell.execute_reply":"2025-04-28T04:56:29.596317Z"}},"outputs":[{"name":"stderr","text":"Generate api embedding: 0it [00:00, ?it/s]\nGenerate api embedding: 100%|| 2/2 [00:00<00:00,  5.17it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of April 25, 2025, at 00:00 AM, Amazon's (AMZN) current share price is \\\\$188.99, which is up \\\\$2.45 (1.31%) from its previous close of \\\\$186.54.\n\nHere is the candlestick data for the past month, sorted in descending order by date:\n\n| Date               | Open    | High    | Low     | Close   | Volume     |\n| ------------------ | ------- | ------- | ------- | ------- | ---------- |\n| Fri Apr 25 00:00:00 2025 | \\\\$187.62 | \\\\$189.94 | \\\\$185.49 | \\\\$188.99 | 36,413,330 |\n| Thu Apr 24 00:00:00 2025 | \\\\$180.92 | \\\\$186.74 | \\\\$180.18 | \\\\$186.54 | 43,051,696 |\n| Wed Apr 23 00:00:00 2025 | \\\\$183.45 | \\\\$187.38 | \\\\$180.19 | \\\\$180.60 | 63,470,094 |\n| Tue Apr 22 00:00:00 2025 | \\\\$169.85 | \\\\$176.78 | \\\\$169.35 | \\\\$173.18 | 56,607,202 |\n| Mon Apr 21 00:00:00 2025 | \\\\$169.60 | \\\\$169.60 | \\\\$165.29 | \\\\$167.32 | 48,126,111 |\n| Thu Apr 17 00:00:00 2025 | \\\\$176.00 | \\\\$176.21 | \\\\$172.00 | \\\\$172.61 | 44,726,453 |\n| Wed Apr 16 00:00:00 2025 | \\\\$176.29 | \\\\$179.10 | \\\\$171.41 | \\\\$174.33 | 51,866,916 |\n| Tue Apr 15 00:00:00 2025 | \\\\$181.41 | \\\\$182.35 | \\\\$177.93 | \\\\$179.59 | 43,617,902 |\n| Mon Apr 14 00:00:00 2025 | \\\\$186.84 | \\\\$187.44 | \\\\$179.23 | \\\\$182.12 | 48,002,540 |\n| Fri Apr 11 00:00:00 2025 | \\\\$179.93 | \\\\$185.86 | \\\\$178.00 | \\\\$184.87 | 50,594,339 |\n| Thu Apr 10 00:00:00 2025 | \\\\$185.44 | \\\\$186.87 | \\\\$175.85 | \\\\$181.22 | 68,302,045 |\n| Wed Apr  9 00:00:00 2025 | \\\\$172.12 | \\\\$192.65 | \\\\$169.93 | \\\\$191.10 | 116,804,328|\n| Tue Apr  8 00:00:00 2025 | \\\\$185.23 | \\\\$185.90 | \\\\$168.57 | \\\\$170.66 | 87,710,360 |\n| Mon Apr  7 00:00:00 2025 | \\\\$162.00 | \\\\$183.41 | \\\\$161.38 | \\\\$175.26 | 109,297,115|\n| Fri Apr  4 00:00:00 2025 | \\\\$167.15 | \\\\$178.14 | \\\\$166.00 | \\\\$171.00 | 123,136,859|\n| Thu Apr  3 00:00:00 2025 | \\\\$183.00 | \\\\$184.13 | \\\\$176.92 | \\\\$178.41 | 95,553,617 |\n| Wed Apr  2 00:00:00 2025 | \\\\$187.66 | \\\\$198.34 | \\\\$187.66 | \\\\$196.01 | 53,679,198 |\n| Tue Apr  1 00:00:00 2025 | \\\\$187.86 | \\\\$193.93 | \\\\$187.20 | \\\\$192.17 | 41,246,065 |\n| Mon Mar 31 00:00:00 2025 | \\\\$188.19 | \\\\$191.33 | \\\\$184.40 | \\\\$190.26 | 63,543,658 |\n| Fri Mar 28 00:00:00 2025 | \\\\$198.42 | \\\\$199.26 | \\\\$191.88 | \\\\$192.72 | 52,542,526 |\n"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"send_message(\n    '''Tell me about Amazon's current bullish versus bearish predictions, and recommendation trends.\n    Include a discussion of any short-term trends, and sentiment analysis.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T04:57:00.787161Z","iopub.execute_input":"2025-04-28T04:57:00.788268Z","iopub.status.idle":"2025-04-28T04:57:31.400003Z","shell.execute_reply.started":"2025-04-28T04:57:00.788213Z","shell.execute_reply":"2025-04-28T04:57:31.399075Z"}},"outputs":[{"name":"stderr","text":"Generate api embedding: 100%|| 1/1 [00:00<00:00,  4.98it/s]\nGenerate api embedding: 100%|| 131/131 [00:24<00:00,  5.25it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of April 28, 2025, here's a summary of Amazon's bullish versus bearish predictions and recommendation trends, including short-term trends and sentiment analysis:\n\n**Analyst Recommendations:**\n\n*   Based on the latest analyst recommendation trends from April 1, 2025, there is a generally positive outlook:\n    *   Strong Buy: 23\n    *   Buy: 50\n    *   Hold: 4\n    *   Sell: 0\n    *   Strong Sell: 0\n*   The trend in analyst recommendations has remained relatively stable over the past few months, with a consistently high number of \"Buy\" and \"Strong Buy\" ratings.\n\n**News Sentiment Analysis:**\n\n*   Recent news articles (last few days of April 2025) present a mixed sentiment regarding Amazon:\n    *   **Positive Sentiments:** Several articles highlight Amazon's long-term growth potential in cloud services, AI, and non-retail sectors. Some predict Amazon could surpass Nvidia, Microsoft, and Apple in market valuation within 5 years. There's also positive sentiment related to Amazon's role in the robotic software platforms market and the potential benefits from easing U.S.-China trade tensions.\n    *   **Neutral Sentiments:** Some articles present a balanced view, acknowledging both the challenges and opportunities for Amazon. For example, the potential impact of tariffs is discussed, with some suggesting that Amazon's diversification could help it navigate these challenges.\n    *   **Negative Sentiments:** Some articles express concerns about the impact of tariffs on Amazon's business, potentially leading to higher prices and reduced consumer appeal. An analyst downgrade due to macroeconomic headwinds and tariffs is also mentioned.\n\n**Short-Term Trends:**\n\n*   **Tariff Impact:** The potential impact of tariffs on Amazon's business is a recurring theme in recent news, creating uncertainty and potentially affecting short-term performance.\n*   **AI and Cloud Computing:** Amazon's investments and growth prospects in AI and cloud computing (Amazon Web Services) continue to be a significant driver of positive sentiment.\n*   **Market Correction:** Some articles discuss Amazon as a potential buy during the S&P 500 correction, highlighting its long-term growth potential and attractive valuation.\n\n**Overall Summary:**\n\nAmazon's recommendation trends lean towards a bullish outlook, with a high number of \"Buy\" and \"Strong Buy\" ratings from analysts. Recent news sentiment is mixed, with positive views on Amazon's long-term growth potential in AI and cloud computing, but concerns about the impact of tariffs on its e-commerce business. Short-term trends are influenced by tariff-related uncertainties and the broader market correction, while long-term sentiment remains positive due to Amazon's diversified revenue streams and growth opportunities.\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"send_message(\n    '''Tell me about Google's share price over the past month.\n    Perform a sentiment analysis of news during the same period. Include trends.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:01:38.461041Z","iopub.execute_input":"2025-04-28T05:01:38.462013Z","iopub.status.idle":"2025-04-28T05:01:48.669795Z","shell.execute_reply.started":"2025-04-28T05:01:38.461972Z","shell.execute_reply":"2025-04-28T05:01:48.668749Z"}},"outputs":[{"name":"stderr","text":"Generate api embedding: 100%|| 2/2 [00:00<00:00,  3.66it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Over the past month, from March 28, 2025, to April 27, 2025, Google's (GOOG) share price has fluctuated.\n\nHere's a summary of the price movements based on the candlestick data:\n\n*   **March 28, 2025:** Opened at \\\\$162.36, closed at \\\\$156.06.\n*   **March 31, 2025:** Opened at \\\\$154.81, closed at \\\\$156.23.\n*   **April 1, 2025:** Opened at \\\\$155.30, closed at \\\\$158.88.\n*   **April 2, 2025:** Opened at \\\\$156.96, closed at \\\\$158.86.\n*   **April 3, 2025:** Opened at \\\\$152.835, closed at \\\\$152.63.\n*   **April 4, 2025:** Opened at \\\\$149.90, closed at \\\\$147.74.\n*   **April 7, 2025:** Opened at \\\\$143.39, closed at \\\\$149.24.\n*   **April 8, 2025:** Opened at \\\\$153.575, closed at \\\\$146.58.\n*   **April 9, 2025:** Opened at \\\\$146.33, closed at \\\\$161.06.\n*   **April 10, 2025:** Opened at \\\\$158.76, closed at \\\\$155.37.\n*   **April 11, 2025:** Opened at \\\\$155.585, closed at \\\\$159.40.\n*   **April 14, 2025:** Opened at \\\\$162.31, closed at \\\\$161.47.\n*   **April 15, 2025:** Opened at \\\\$161.57, closed at \\\\$158.68.\n*   **April 16, 2025:** Opened at \\\\$155.47, closed at \\\\$155.50.\n*   **April 17, 2025:** Opened at \\\\$156.61, closed at \\\\$153.36.\n*   **April 21, 2025:** Opened at \\\\$150.965, closed at \\\\$149.86.\n*   **April 22, 2025:** Opened at \\\\$151.07, closed at \\\\$153.90.\n*   **April 23, 2025:** Opened at \\\\$157.91, closed at \\\\$157.72.\n*   **April 24, 2025:** Opened at \\\\$158.525, closed at \\\\$161.47.\n*   **April 25, 2025:** Opened at \\\\$167.10, closed at \\\\$163.85.\n\n**Sentiment Analysis of News:**\n\nThe news sentiment over the past month has been predominantly positive. Several articles highlight Google's strong fundamentals, particularly its experience, capital, and technological foundation in artificial intelligence. This positions the company well for future growth. Additionally, Google's geographic diversification and core business contribute to its resilience against potential challenges like tariff hikes.\n\nOther positive news includes:\n\n*   Goldman Sachs scrapping recession call, leading to a strong market rally that benefits Google.\n*   Recognition of Google as a leading information and communications technology vendor supporting the automotive ecosystem.\n*   A report highlighting the Internet of Things Analytics market's growth, driven by real-time insights and smart tech investments, with Google being a key player.\n*   Buzz's innovative artificial intelligence-powered travel companion and its partnerships, suggesting a positive outlook for the company.\n\nHowever, there are also some neutral and potentially negative sentiments:\n\n*   One article presents a mixed outlook, noting potential headwinds in Google's advertising and artificial intelligence/cybersecurity businesses.\n*   Another article discusses the potential impact of competition and disruption on Google's search engine.\n*   One article suggests that Amazon's growing advertising business could pose a threat to Google's advertising dominance.\n\nOverall, the news sentiment leans towards positive, with several articles emphasizing Google's strengths and growth opportunities.\n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"send_message(\n    '''How is the outlook for Apple based on trends and news sentiment over the past month?\n    Perform the same analysis on Apple's peers. Then compare Apple result to it's peers.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:08:41.154666Z","iopub.execute_input":"2025-04-28T05:08:41.155098Z","iopub.status.idle":"2025-04-28T05:09:08.22316Z","shell.execute_reply.started":"2025-04-28T05:08:41.155058Z","shell.execute_reply":"2025-04-28T05:09:08.222227Z"}},"outputs":[{"name":"stderr","text":"Generate api embedding: 100%|| 1/1 [00:00<00:00,  5.22it/s]\nGenerate api embedding: 100%|| 33/33 [00:07<00:00,  4.36it/s]\nGenerate api embedding: 100%|| 1/1 [00:00<00:00,  5.33it/s]\nGenerate api embedding: 100%|| 13/13 [00:02<00:00,  5.26it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Based on the data gathered, here's an analysis of the outlook for Apple and its peers:\n\n**Apple (AAPL):**\n\n*   **Recommendation Trends:** Analyst recommendations for Apple have remained relatively stable over the past month. In April 2025, there were 23 buy, 12 hold, 3 sell, 12 strong buy, and 1 strong sell recommendations.\n*   **News Sentiment:** Recent news articles concerning Apple highlight several key themes:\n    *   **Tariff Concerns:** Apple's exposure to tariffs and trade tensions, particularly between the U.S. and China, remains a significant concern. News suggests Apple is planning to shift iPhone production to India to mitigate these risks.\n    *   **AI and Innovation:** There is discussion around Apple's AI capabilities, with some analysts suggesting the company \"fumbled\" its AI launch. However, there are also reports of Apple using on-device data and synthetic inputs to boost its AI capabilities.\n    *   **Production Shifts:** Reports indicate Apple is moving more iPhone production to India, potentially shifting all U.S.-bound iPhone production from China by the end of 2026.\n    *   **Market Competition:** Apple is reportedly losing ground in China's smartphone market to local rivals.\n\n**Peer Analysis:**\n\nApple's peers, based on the subIndustry grouping, include Dell Technologies, HP Inc, Super Micro Computer Inc, Hewlett Packard Enterprise, NetApp Inc, Pure Storage Inc, Western Digital Corp, and IONQ Inc.\n\n*   **Dell Technologies (DELL):**\n    *   **Recommendation Trends:** Analyst recommendations for Dell are generally positive. In April 2025, there were 20 buy, 4 hold, 0 sell, 6 strong buy, and 0 strong sell recommendations.\n    *   **News Sentiment:** Recent news highlights Dell's advancements in AI-driven products and its focus on AI and data resilience. There are also mentions of potential impacts from the tariff war.\n*   **HP Inc. (HPQ):**\n    *   **Recommendation Trends:** Analyst recommendations for HP Inc. are mixed. In April 2025, there were 4 buy, 13 hold, 1 sell, 2 strong buy, and 0 strong sell recommendations.\n    *   **News Sentiment:** Recent news includes HP's Digital Equity Accelerator program and discussions around its stock performance relative to competitors. There are also articles discussing reasons to sell HPQ stock.\n\n**Comparative Summary:**\n\n*   **Apple vs. Peers:** Apple faces similar challenges as its peers regarding tariffs and trade tensions. However, Apple's situation is unique due to its significant presence in the smartphone market and its reliance on China for manufacturing.\n*   **AI Focus:** Both Apple and Dell are focusing on AI, but there are differing views on their success in this area. Apple is reportedly working to improve its AI capabilities, while Dell is highlighting its AI-driven product enhancements.\n*   **Recommendation Trends:** Dell has a more positive recommendation trend compared to Apple and HP Inc., with a higher proportion of \"buy\" and \"strong buy\" recommendations.\n\n**Overall Outlook:**\n\nThe outlook for Apple is mixed. While the company is taking steps to mitigate risks related to tariffs and is investing in AI, it faces challenges in the Chinese market and mixed sentiment regarding its AI capabilities. Dell appears to have a more positive outlook, with strong analyst recommendations and a focus on AI-driven products. HP Inc. faces challenges related to declining stock value and mixed analyst sentiment.\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"send_message('''What does the recent news say about Apple and the impact of tariffs? Over the past 2 month.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T05:09:49.749572Z","iopub.execute_input":"2025-04-28T05:09:49.749986Z","iopub.status.idle":"2025-04-28T05:09:53.056503Z","shell.execute_reply.started":"2025-04-28T05:09:49.749949Z","shell.execute_reply":"2025-04-28T05:09:53.05542Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Between February 28, 2025, and April 28, 2025, news articles indicate that Apple is navigating a complex trade environment, particularly concerning tariffs.\n\nHere's a summary of the key points:\n\n*   **Tariff Impact:** Concerns loom over Apple's earnings report as analysts gauge the impact of tariffs on its business. Tariffs are expected to increase costs for businesses.\n*   **China Dependence:** Apple's significant iPhone production in China exposes it to U.S. tariffs.\n*   **Potential Shift to India:** Apple is reportedly planning to shift all production for U.S.-sold iPhones from China to India by the end of 2026, accelerating its supply chain diversification strategy amid trade war and tariff concerns.\n*   **Trump's Stance:** The Trump administration has temporarily exempted smartphones, computers, and other electronic devices from tariffs on China imports.\n*   **Analyst Views:** Wedbush's Dan Ives remains bullish on Apple in the long term, despite cutting Apple's price target.\n*   **Political Pressure:** Senator Elizabeth Warren has criticized Tim Cook over alleged deals with the Trump administration to shield Apple from tariffs.\n*   **Consumer Impact:** T-Mobile's CEO suggests that tariffs on phones will likely be absorbed by consumers."},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"# Conclusion\n\n<span style=\"font-size:18px;\">\nFor now that will have to do. Our Essy has a solid foundation but more could be done to organise metadata. No evaluation or validation has been performed (except fuzzing the prompt). Next steps include restructuring the vector database based on lessons learned. That'll be followed by plotting, multi-modal, and structured output. The last close date (generative) function can be temperamental. In the same way Gemini always feels regarding dates. I've learnt so much. I'm happy I decided to participate in the event! It really has been a joy to see Essy grow from random chat with Gemini into the foundation for a good-broker buddy. I hope you enjoy playing with this edition as much as I enjoyed building it!\n</span>","metadata":{}}]}