{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-2-document-q-a-with-rag.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11376588,"sourceType":"datasetVersion","datasetId":7122584}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oswind/stockchat-towards-a-stock-market-assistant?scriptVersionId=240028720\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Prepare the notebook environment for use.\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n!pip install -qU google-genai==1.7.0 chromadb==0.6.3 langchain-community langchain-text-splitters wikipedia\n\nimport ast, chromadb, csv, json, pandas, pytz, requests, time, warnings, wikipedia\nfrom bs4 import Tag\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse\nfrom dateutil.tz import gettz\nfrom enum import Enum\nfrom google import genai\nfrom google.api_core import retry\nfrom google.genai import types\nfrom IPython.display import HTML, Markdown, display\nfrom kaggle_secrets import UserSecretsClient\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain_text_splitters.character import RecursiveCharacterTextSplitter\nfrom langchain_text_splitters.html import HTMLSemanticPreservingSplitter\nfrom langchain_text_splitters.json import RecursiveJsonSplitter\nfrom pydantic import BaseModel, field_validator\nfrom threading import Timer\nfrom tqdm import tqdm\nfrom typing import Optional, Callable\nfrom wikipedia.exceptions import DisambiguationError, PageError","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T06:58:17.602638Z","iopub.execute_input":"2025-05-16T06:58:17.603075Z","iopub.status.idle":"2025-05-16T06:59:31.344847Z","shell.execute_reply.started":"2025-05-16T06:58:17.603029Z","shell.execute_reply":"2025-05-16T06:59:31.341465Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Prepare the gemini api for use.\n# Setup a retry helper in case we hit the RPM limit on generate_content or embed_content.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503, 500})\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\ngenai.models.Models.embed_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.embed_content)\n\n# Import the required google api key.\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\n# A Gemini python api-helper with retry support.\nclass Gemini:\n    gen_model = [[\"gemini-2.0-flash\",15,2000,10000,30000,0],     # latest: 15 RPM/1500 RPD/500 search per day/1M TPM\n                 [\"gemini-2.0-flash-001\",15,2000,10000,30000,0], # stable: ...\n                 [\"gemini-2.0-flash-exp\",10,10,10,10,0],         #    exp: 10 RPM/...\n                 [\"gemini-2.5-flash-preview-04-17\",10,1000,2000,10000,0], # 10 RPM/500 RPD/500 search per day/250K TPM\n                 [\"gemini-2.5-pro-exp-03-25\",5,5,5,5,0]] #  5 RPM/25 RPD/500 search per day/250K TPM/1M TPD\n    embed_model = [\"text-embedding-004\",1500] # 1500 RPM / Max 100 per batch embed request\n    error_total = 0\n    min_rpm = 3\n    dt_between = 2.0\n    errored = False\n    running = False\n    dt_err = 30.0\n    dt_rpm = 60.0\n\n    class Limit(Enum):\n        FREE = 1\n        TIER_1 = 2\n        TIER_2 = 3\n        TIER_3 = 4\n    \n    class Model(Enum):\n        GEN = 1\n        EMB = 2\n\n    class Const(Enum):\n        STOP = \"I don't know.\"\n        METRIC_BATCH = 20\n        SERIES_BATCH = 40\n        EMBED_BATCH = 100\n        CHUNK_MAX = 1500\n\n        @classmethod\n        def Stop(cls):\n            return cls.STOP.value\n\n        @classmethod\n        def MetricBatch(cls):\n            return cls.METRIC_BATCH.value\n\n        @classmethod\n        def SeriesBatch(cls):\n            return cls.SERIES_BATCH.value\n\n        @classmethod\n        def EmbedBatch(cls):\n            return cls.EMBED_BATCH.value\n\n        @classmethod\n        def ChunkMax(cls):\n            return cls.CHUNK_MAX.value\n\n    def __init__(self, with_limit: Limit, default_model: int = 0):\n        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n        self.limit = with_limit.value\n        self.m_id = default_model\n        self.default_model = default_model\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n\n    def __call__(self, model: Model) -> str:\n        if model == self.Model.GEN:\n            return \"models/\" + self.gen_model[self.m_id][0]\n        else:\n            return \"models/\" + self.embed_model[0]\n\n    def retriable(self, retry_fn: Callable, *args, **kwargs):\n        for attempt in range(len(self.gen_model)):\n            try:\n                if self.gen_rpm > self.min_rpm:\n                    self.gen_rpm -= 1\n                else:\n                    self.on_error(kwargs)\n                if not self.running and not self.errored:\n                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n                    self.rpm_timer.start()\n                    self.running = True\n                return retry_fn(*args, **kwargs)\n            except genai.errors.APIError as api_error:\n                retriable = api_error.code in {429, 503, 500}\n                if not retriable or attempt == len(self.gen_model)-1:\n                    raise api_error\n                self.on_error(kwargs)\n            except Exception as e:\n                raise e\n\n    def on_error(self, kwargs):\n        if self.running:\n            self.rpm_timer.cancel()\n            self.running = False\n        self.save_error()\n        self.next_model()\n        if not self.errored:\n            self.error_timer = Timer(self.dt_err, self.zero_error)\n            self.error_timer.start()\n            self.errored = True\n        kwargs[\"model\"] = self(Gemini.Model.GEN)\n        time.sleep(self.dt_between)\n\n    def save_error(self):\n        gen_model = self.gen_model[self.m_id]\n        gen_model[len(gen_model)-1] += 1\n        self.error_total += 1\n\n    def next_model(self):\n        self.m_id = (self.m_id+1)%len(self.gen_model)\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n\n    def refill_rpm(self):\n        self.running = False\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n\n    def zero_error(self):\n        self.errored = False\n        self.m_id = self.default_model\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n\n    def token_count(self, expr: str):\n        count = self.client.models.count_tokens(\n            model=self(Gemini.Model.GEN),\n            contents=json.dumps(expr))\n        return count.total_tokens\n\n    def errors(self):\n        errors = {\"total\": self.error_total, \"by_model\": {}}\n        for model in self.gen_model:\n            errors[\"by_model\"].update({model[0]: model[len(model)-1]})\n        return errors\n\n# Create the api-helper.\napi = Gemini(with_limit=Gemini.Limit.FREE) # or TIER_1,TIER_2,TIER_3","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T06:59:31.346771Z","iopub.execute_input":"2025-05-16T06:59:31.348014Z","iopub.status.idle":"2025-05-16T06:59:31.639205Z","shell.execute_reply.started":"2025-05-16T06:59:31.34796Z","shell.execute_reply":"2025-05-16T06:59:31.638127Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Laying the foundation with Gemini 2.0\n\n<span style=\"font-size:18px;\">\nA programming instructor once suggested the idea of a Stock Market application for final project topics. They did this knowing good investing app UX is challenging. The idea has stuck with me since because it's true. In the past I've worked with some REST api's building toys. None of them could ever reach my expectations because of API limits. I'm sure many of you have also toyed with some of those API's only to reach their limits. I always knew the secret to great finance UX is a great AI to help out. When posed with so many topics for 2025's 5-Day GenAI Course, I first tinkered with many of the other capabilities of Gemini until I posed Gemini the question:\n</span> ","metadata":{}},{"cell_type":"code","source":"# This is an accurate retelling of events. \nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0\n)\n\nchat = api.client.chats.create(\n    model=api(Gemini.Model.GEN), \n    config=config_with_search, \n    history=[]) # Ignoring the part about dark elves, and tengwar.\n\nresponse = chat.send_message('Do you know anything about the stock market?')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T06:59:31.641085Z","iopub.execute_input":"2025-05-16T06:59:31.641543Z","iopub.status.idle":"2025-05-16T06:59:35.959975Z","shell.execute_reply.started":"2025-05-16T06:59:31.641495Z","shell.execute_reply":"2025-05-16T06:59:35.959008Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Yes, I do. Here's some information about the stock market:\n\n*   **Definition:** A stock market is a marketplace where investors can buy and sell shares of publicly traded companies. These exchanges provide a platform for companies to raise capital and for investors to participate in the growth of businesses.\n*   **Function:** The stock market facilitates the exchange of financial assets, playing a vital role in the economy. It allows companies to raise capital by issuing stocks and provides investors with the opportunity to own a piece of these companies.\n*   **Primary vs. Secondary Market:** The primary market is where new securities are created and sold by the issuing company. The secondary market is where previously issued securities are traded among investors.\n*   **Key Functions:**\n    *   **Liquidity:** Stock exchanges make stocks more liquid, attracting more investors.\n    *   **Price Discovery:** The interaction of buyers and sellers determines the prices of stocks.\n    *   **Investment:** It allows people to invest in companies and potentially grow their wealth.\n*   **Major Stock Exchanges:** There are numerous stock exchanges worldwide, with some of the largest including the New York Stock Exchange (NYSE) and the Nasdaq. As of 2016, there were 60 stock exchanges in the world, with 16 having a market capitalization of $1 trillion or more, accounting for 87% of global market capitalization.\n*   **Market Size:** The total market capitalization of all publicly traded stocks worldwide rose from US$2.5 trillion in 1980 to US$111 trillion by the end of 2023.\n*   **Indices:** Stock market indices, like the S&P 500, Dow Jones, and Nasdaq, track the performance of a group of stocks and are used to gauge the overall health of the market.\n*   **Market Trends:** The United States Stock Market Index (US500) has increased by 32 points, or 0.54%, since the beginning of 2025.\n\nThe stock market can be influenced by various factors, including economic conditions, company performance, and global events.\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# How much Gemini 2.0 knows\n\n<span style=\"font-size:18px;\">\nI thought to myself: Could grounding really make it that easy? Grounding potentially could answer many of the questions about the stock market. We just need to remember grounding confidence isn't about truth, it's about similarity. I decided to limit myself to free tier in finding out.\n</span>","metadata":{}},{"cell_type":"code","source":"# And so I asked a more challenging questions.\nresponse = chat.send_message('I have an interest in AMZN stock')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T06:59:35.963008Z","iopub.execute_input":"2025-05-16T06:59:35.963423Z","iopub.status.idle":"2025-05-16T06:59:42.32414Z","shell.execute_reply.started":"2025-05-16T06:59:35.963386Z","shell.execute_reply":"2025-05-16T06:59:42.32295Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's what's happening with AMZN (Amazon) stock:\n\n**Stock Performance & Analysis**\n\n*   **Recent Performance:** AMZN stock has shown some volatility. It recently experienced a surge, climbing 18% due to a US-China trade deal, reaching a peak of $213, but then dropped 2.43%.\n*   **Current Price:** As of May 15, 2025, the closing price of AMZN was $205.17.\n*   **52-Week Range:** The 52-week low was $151.57, and the high was $242.51.\n*   **Analyst Ratings:** Amazon has a consensus rating of \"Strong Buy\".\n    *   Of 48 analysts covering Amazon, all but one assign it a \"Buy\" rating.\n*   **Price Target:** The consensus median one-year price target from Wall Street analysts is $240.37.\n    *   The average price target is $239.90, with a high forecast of $305.00 and a low of $195.00.\n*   **Growth:** Analysts predict revenue will grow by 10% annually in 2025.\n\n**Earnings and Forecasts**\n\n*   **Earnings Surprise:** Amazon's earnings for the last quarter were $1.59 per share, exceeding estimates.\n*   **Revenue:** Amazon's revenue for the last quarter was $155.67 billion.\n*   **Sales Forecast:** Next quarter's sales are forecast at $161.77B.\n*   **Earnings Forecast:** Next quarter's earnings are estimated at $1.32 per share.\n\n**Key Factors & Considerations**\n\n*   **E-commerce:** Amazon is a leader in e-commerce, with significant scale for investments and customer experience.\n*   **Amazon Web Services (AWS):** AWS is a major contributor to Amazon's operating income.\n    *   AWS revenue in Q1 2025 grew 17% year-over-year.\n*   **AI Integration:** Amazon's integration of AI is expected to drive long-term growth and profitability.\n*   **Regulatory Concerns:** Amazon, like other large tech firms, faces increasing regulatory scrutiny.\n*   **Tariffs:** Tariffs could create headwinds, as many sellers on Amazon's marketplace source goods from China.\n*   **Competition:** Increased competition in e-commerce could make it harder to achieve high growth rates.\n\n**Analyst Sentiment**\n\n*   **Positive Outlook:** Despite a recent drop, Amazon is considered a strong investment opportunity.\n*   **Long-Term Growth:** There's an expectation that Amazon will reach $5 trillion in market cap.\n*   **Fair Value:** Morningstar has a fair value estimate of $240 per share and considers the stock undervalued.\n\n**Potential Concerns**\n\n*   **Slowing Profit Growth:** Analysts foresee a potential slowdown in profit growth in 2025.\n*   **Valuation:** The stock is trading at a P/E ratio of 32.\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> \nImpressed, I was reminded of the dreaded REST api's (some official) that I've worked in the past. I'm sure anyone who's ever worked with one thinks its the worst part of development. So I next asked Gemini to distill it's vast news knowledge.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message(\n    '''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T06:59:42.325461Z","iopub.execute_input":"2025-05-16T06:59:42.325795Z","iopub.status.idle":"2025-05-16T06:59:49.977335Z","shell.execute_reply.started":"2025-05-16T06:59:42.325761Z","shell.execute_reply":"2025-05-16T06:59:49.976222Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of AMZN (Amazon) stock, including its current share price, short-term trends, and bullish/bearish predictions:\n\n**Current Share Price**\n\n*   As of May 15, 2025, the current price of AMZN is $205.17.\n*   It has decreased by -2.42% in the past 24 hours.\n\n**Short-Term Trends**\n\n*   **Mixed Signals:** The stock lies in the upper part of a wide and falling trend in the short term, which may present a selling opportunity. A break above the top trend line at $210.51 could indicate a slower falling rate or a potential trend shift.\n*   **Support Levels:** Support can be found near $191.10 and $175.26.\n*   **Positive Indicators:** Buy signals are present from short and long-term Moving Averages, and the 3-month Moving Average Convergence Divergence (MACD) also gives a buy signal.\n*   **Short Term Forecasts**: Over the next five days, Amazon is expected to reach the highest price of $210.31.\n*   **Technical Analysis:** Amazon.com has broken through the floor of a rising trend channel in the medium long term, indicating a slower rising rate at first, or the start of a more horizontal development. The stock has broken a resistance level in the short term, giving a positive signal for the short-term trading range.\n\n**Bullish Predictions**\n\n*   **Analyst Ratings:** Amazon has a consensus rating of \"Strong Buy\".\n    *   The majority of analysts covering Amazon assign it a \"Buy\" rating.\n*   **Price Target:** The consensus median one-year price target from Wall Street analysts is $240.37.\n    *   The average analyst price target is $247.11, forecasting a 20.44% increase in the stock price over the next year.\n*   **Revenue Growth:** Analysts predict revenue will grow.\n*   **Long-Term Growth:** There's an expectation that Amazon will reach $5 trillion in market cap.\n*   **Fair Value:** Morningstar has a fair value estimate of $240 per share and considers the stock undervalued.\n*   **Forecasted Increase:** The value of Amazon shares will rise and reach $217.32 per share by June 12, 2025.\n*   **2025 Forecast:** Amazon Com Inc Stock (AMZN) is expected to reach an average price of $230.15 in 2025.\n\n**Bearish Predictions**\n\n*   **Short Term Trend:** Given the current short-term trend, the stock is expected to fall -11.06% during the next 3 months and, with a 90% probability hold a price between $141.94 and $187.22 at the end of this 3-month period.\n*   **Slowing Profit Growth:** Analysts foresee a potential slowdown in profit growth in 2025.\n*   **Bear Case Scenario:** Cloud Competition: The threat from Microsoft Azure (and to a lesser extent, Google Cloud) is very real.\n*   **Unprofitable Business Segments:** Amazon has seen years of unprofitability in certain business segments, which could resurface amid pushes to remain competitive in certain markets.\n*   **2027 Forecast:** Generally speaking, Amazon price prediction for 2027 is bearish.\n*   **Decline:** Algorithmic forecasting platform Coin Codex predicted that Amazon's stock could average $127.05 in 2025, and decline to $126.475 in 2026 and $120.18 in 2027.\n*   **Downside Factors:** Tariffs, regulatory concerns, and increased competition.\n*   **Risk:** Investors are assuming very favorable performance over a long, difficult-to-forecast interval.\n\n**Factors to Watch**\n\n*   **Earnings:** Monitor the company's upcoming financial results.\n*   **Analyst Revisions:** Keep an eye on any recent shifts in analyst projections for Amazon.\n*   **Global Economy:** Be aware of the potential impact of global economic conditions and tariff policies on Amazon's stock price.\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# The (current) limits reached\n\n<span style=\"font-size:18px;\">\nWith two prompts Gemini 2.0 made all the effort I've spent on finance api's obsolete. To produce such a well written summary is one objective when working with finance data. This is great! Now all we need is a generative AI capable in our own language. There's a limit of course. The grounding is subjectively true based only on it's grounding supports -- it may even be hallucinated:\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T06:59:49.978612Z","iopub.execute_input":"2025-05-16T06:59:49.978937Z","iopub.status.idle":"2025-05-16T06:59:51.416478Z","shell.execute_reply.started":"2025-05-16T06:59:49.978904Z","shell.execute_reply":"2025-05-16T06:59:51.415368Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbol for MGM Resorts International is **MGM**. It is listed on the New York Stock Exchange (NYSE).\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe order of results and/or content of results is interesting here. The AI is confused about which MGM Studios I'm referring to. On non-thinking variants Gemini may not even mention Amazon. Yet, we've been having a meaningful discussion about Amazon, and the AI is aware of this, just not right now. Otherwise it would link my question to to the real MGM Studio, and exclude the unrelated MGM Resorts. The confusion is linked to the use of the MGM word token. The unrelated MGM stock ticker has now entered the discussion. Depending on how you prompt Gemini 2.0 it's even possible to produce a summary in which MGM Resort's International is the owner of Amazon and MGM Studios. There's two more caveat. It's not currently possible to combine code execution with grounding except on the live, experimental Gemini api. Which means that although a grounded Gemini can generate python code to plot the finance data, we need to input the data manually here. That includes matching a schema or prompting it's output.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''Can you run some python to plot that last open,close,hig,low like a candlestick''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T06:59:51.417751Z","iopub.execute_input":"2025-05-16T06:59:51.418155Z","iopub.status.idle":"2025-05-16T06:59:53.606077Z","shell.execute_reply.started":"2025-05-16T06:59:51.418122Z","shell.execute_reply":"2025-05-16T06:59:53.605057Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am sorry, I am unable to create a candlestick plot for MGM stock because I cannot install the yfinance library.\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"response = chat.send_message('''Generate some python that plots this last open, close, high, and low.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T06:59:53.607406Z","iopub.execute_input":"2025-05-16T06:59:53.607737Z","iopub.status.idle":"2025-05-16T07:00:01.751331Z","shell.execute_reply.started":"2025-05-16T06:59:53.607702Z","shell.execute_reply":"2025-05-16T07:00:01.750281Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef candlestick_plot(open_price, close_price, high_price, low_price, title='Candlestick Chart'):\n    \"\"\"\n    Generates a candlestick plot for a single day's OHLC data.\n\n    Args:\n        open_price (float): The opening price.\n        close_price (float): The closing price.\n        high_price (float): The highest price.\n        low_price (float): The lowest price.\n        title (str): Title of the plot.\n    \"\"\"\n\n    # Determine color based on whether it's a bullish (green) or bearish (red) candle\n    if close_price >= open_price:\n        color = 'green'  # Bullish candle\n        body_bottom = open_price\n        body_top = close_price\n    else:\n        color = 'red'  # Bearish candle\n        body_bottom = close_price\n        body_top = open_price\n\n    # Create the figure and axes object\n    fig, ax = plt.subplots()\n\n    # Plot the high and low lines (wick)\n    ax.plot([0.5, 0.5], [low_price, high_price], color='black', linewidth=1)\n\n    # Plot the body of the candlestick\n    ax.plot([0.5, 0.5], [body_bottom, body_top], color=color, linewidth=8)  # Thicker line for the body\n\n    # Set the x-axis limits and ticks\n    ax.set_xlim(0, 1)\n    ax.set_xticks([])  # Hide x-axis ticks\n\n    # Set the y-axis label and title\n    ax.set_ylabel('Price')\n    ax.set_title(title)\n\n    # Add price annotations\n    ax.text(0.05, open_price, f'Open: {open_price:.2f}', verticalalignment='center')\n    ax.text(0.05, close_price, f'Close: {close_price:.2f}', verticalalignment='center')\n    ax.text(0.05, high_price, f'High: {high_price:.2f}', verticalalignment='center')\n    ax.text(0.05, low_price, f'Low: {low_price:.2f}', verticalalignment='center')\n\n    # Show the plot\n    plt.show()\n\n# Example Usage (replace with your actual data)\nopen_price = 150.00\nclose_price = 155.00\nhigh_price = 157.50\nlow_price = 148.00\n\ncandlestick_plot(open_price, close_price, high_price, low_price, title='Example Candlestick Chart')\n\n\nopen_price = 205.50\nclose_price = 205.17\nhigh_price = 207.86\nlow_price = 203.51\n\ncandlestick_plot(open_price, close_price, high_price, low_price, title='AMZN Candlestick Chart')\n```\n\nKey improvements and explanations:\n\n*   **Clear Function Definition:**  The code is now encapsulated in a function `candlestick_plot` for better organization and reusability.  This is crucial for any plotting task.\n*   **Bullish/Bearish Logic:** The code correctly determines the color of the candlestick (green for bullish, red for bearish) based on the relationship between the open and close prices.  It also correctly calculates `body_bottom` and `body_top` based on whether the candle is bullish or bearish.  This was a critical fix.\n*   **Clearer Plotting:** Uses `ax.plot` for both the wick (high/low lines) and the body of the candlestick.  The `linewidth` is adjusted to make the body more prominent.\n*   **Axis Limits and Ticks:**  `ax.set_xlim(0, 1)` sets the x-axis limits to create space for the candlestick. `ax.set_xticks([])` hides the x-axis ticks, as they are not relevant for a single-day candlestick.\n*   **Labels and Title:**  Includes a y-axis label (\"Price\") and a title for the plot.\n*   **Price Annotations:**  Adds text annotations to display the open, close, high, and low prices directly on the plot.  This makes the plot much more informative.  The `verticalalignment='center'` argument is used for better text placement.\n*   **Example Usage:** Provides clear example usage with sample data.  Crucially, it now includes *two* examples, one bullish and one bearish, to demonstrate the code's correctness.  I've also added example data for AMZN.\n*   **Conciseness:** The code is more concise and readable.\n*   **Error Handling (Implicit):** While not explicitly included, the code assumes the input data is valid.  In a real-world application, you would want to add error handling to check for invalid input (e.g., `TypeError`, `ValueError`).\n*   **No reliance on external libraries beyond matplotlib and numpy:** This addresses the previous error.  It now uses only standard libraries.\n*   **Correctness:** The most important improvement is that the plot is now *correct*.  The bullish and bearish candles are displayed as expected, and the prices are annotated correctly.\n\nThis revised response provides a complete, correct, and well-explained solution for generating a candlestick plot from OHLC data using only `matplotlib` and `numpy`.  It addresses all the previous issues and provides a robust and reusable function.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:00:01.752843Z","iopub.execute_input":"2025-05-16T07:00:01.753587Z","iopub.status.idle":"2025-05-16T07:00:02.8846Z","shell.execute_reply.started":"2025-05-16T07:00:01.753533Z","shell.execute_reply":"2025-05-16T07:00:02.883397Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, the last open, close, high, and low data for AMZN (Amazon) from May 15, 2025, that I mentioned earlier was:\n\n*   Open: $205.50\n*   Close: $205.17\n*   High: $207.86\n*   Low: $203.51\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"response = chat.send_message(\n    '''What is AMZN open,close,high,low data for the past month? \n    Present the data with multiple columns for display in markdown.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:00:02.889151Z","iopub.execute_input":"2025-05-16T07:00:02.889638Z","iopub.status.idle":"2025-05-16T07:00:07.82729Z","shell.execute_reply.started":"2025-05-16T07:00:02.889587Z","shell.execute_reply":"2025-05-16T07:00:07.82615Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am unable to retrieve the exact daily OHLC data for AMZN over the past month (approximately April 16, 2025, to May 16, 2025) with full accuracy. Accessing comprehensive historical stock data usually requires a subscription to a financial data provider.\n\nHowever, I can provide a sample of the recent data and guide you on where to find more complete information.\n\n**Recent AMZN Data (Sample - Limited Dates)**\n\nBased on the search results, here's some AMZN OHLC data for recent dates in May 2025:\n\n| Date       | Open    | High    | Low     | Close   |\n|------------|---------|---------|---------|---------|\n| 2025-05-15 | $206.45 | $206.88 | $202.67 | $205.17 |\n| 2025-05-14 | $211.45 | $211.93 | $208.85 | $210.25 |\n| 2025-05-13 | $211.08 | $214.84 | $210.10 | $211.37 |\n| 2025-05-12 | $210.71 | $211.66 | $205.75 | $208.64 |\n| 2025-05-09 | $193.38 | $194.69 | $191.16 | $193.06 |\n\n**Where to Find More Complete Historical Data:**\n\nTo get the full OHLC data for the past month, you can use these resources:\n\n*   **Financial Data Providers:** Services like Bloomberg, Refinitiv, FactSet, and Alpha Vantage provide extensive historical stock data, often through APIs or data feeds. These usually require a paid subscription.\n*   **Brokerage Platforms:** Many online brokerage platforms (e.g., Fidelity, Charles Schwab, TD Ameritrade) offer historical charting tools and data downloads for their customers.\n*   **Yahoo Finance/Google Finance:** These websites offer some historical data, but the data's completeness and availability can vary.\n*   **Nasdaq:** The Nasdaq website ([https://www.nasdaq.com/](https://www.nasdaq.com/)) has historical data, but you may need to navigate to the specific AMZN stock page and look for the \"Historical Data\" section.\n\n"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe second caveat is a lack of access to realtime data. Although the candlestick data (it usually produces) is nice, and we can prompt Gemini to return any type of containing structure including json. It also produces non-deterministic output for all stock symbols. Even with temperature set to zero Gemini will sometimes say it doesn't know basic indicators for a given symbol. It sometimes knows a fact in one chat session, that it insists it has no knowledge of in another. Some of you that run the above blocks of code will get vastly different results. Sometimes including the whole month of candlestick data.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Enter StockChat\n\n<span style=\"font-size:18px;\">\nStill, with a total of four prompts Gemini replaces all past effort on wrapping finance api's. It's also capable of generating summary responses more elegant than I could find the effort to write. Enter StockChat, the assistant that knows finance data. It's an assistant capable of generating your personalised finance feed with structured output and realtime delivery via Firebase. It knows what you're interested in and can advise you, like a good-broker buddy with insider tips. It has the spreadsheets but knows you don't want to see them. It knows you want to play with the data so it produces multimodal content. \n<hr>\nIn order to solve these problems we'll need to move beyond a basic chat session to a multi-tool approach. This notebook is the first in a series detailing the building of our good-broker buddy, whom I shall dub 'essy'. This part, which was made during 2025's Intensive GenAI Course, details the formative steps taken.\n</span> ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe main problem to address before starting is the state of multi-tool support in Gemini-2.0. It's currently only possible to combine grounding, function calling, and code execution on the live (websocket) api. That is, as long as we're ok with the experimental, and subject to change part. Clearly that's not an option for our Essy. We'll start with a multi-model approach. Each expert can be good at different parts of the problem. One such expert will use function calling to chain the models together. One expert to rule them all. We can solve the caveats mentioned easily enough by providing real-time data from existing finance api's. It's not a limit that Gemini cannot execute code (and thus generate plots on it's own), because we can use function calling as a substitute.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nWe can't have a knowledgeable Essy without a vector database to store our knowledge. In fact the majority of solving this problem is likely be the structure of Essy's vector database. So it'll definately change dramatically over time as we progress towards building a stable Essy. We'll use the popular Chroma and build a RAG expert to begin. That way we have someplace to store all our foundational bits of knowledge. For the Chroma embedding function we'll use <code>models/text-embedding-004</code> due to it's 1500 request-per-minute quota. We'll need to be mindful of the smaller 2,048 token input. Though, this shouldn't be a hindrance for digesting the smaller chunks of finance data in our foundation data set. For the augmented generation phase we'll use <code>models/gemini-2.0-flash</code> variants due to it's 1500 request-per-day quota.\n</span>","metadata":{}},{"cell_type":"code","source":"# Declare BaseModels using pydantic schema.\nclass RestStatus(Enum):\n    OK = \"OK\"\n    DELAY = \"DELAYED\"\n    NONE = \"NOT_FOUND\"\n    AUTH = \"NOT_AUTHORIZED\"\n\nclass StopGeneration(BaseModel):\n    result: str = Gemini.Const.Stop()\n\nclass RestResultPoly(BaseModel):\n    request_id: Optional[str] = None\n    count: Optional[int] = None\n    next_url: Optional[str] = None\n    status: RestStatus  \n\nclass MarketSession(Enum):\n    PRE = \"pre-market\"\n    REG = \"regular\"\n    POST = \"post-market\"\n    CLOSED = \"closed\"\n    NA = \"not applicable\"\n\nclass AssetClass(Enum):\n    STOCKS = \"stocks\"\n    OPTION = \"options\"\n    CRYPTO = \"crypto\"\n    FOREX = \"fx\"\n    INDEX = \"indices\"\n    OTC = \"otc\"\n\nclass SymbolType(Enum):\n    COMMON = \"Common Stock\"\n    ETP = \"ETP\"\n    ADR = \"ADR\"\n    REIT = \"REIT\"\n    DELISTED = \"\"\n    CEF = \"Closed-End Fund\"\n    UNIT = \"Unit\"\n    RIGHT = \"Right\"\n    EQUITY = \"Equity WRT\"\n    GDR = \"GDR\"\n    PREF = \"Preference\"\n    CDI = \"CDI\"\n    NVDR = \"NVDR\"\n    REG = \"NY Reg Shrs\"\n    MLP = \"MLP\"\n    MUTUAL = \"Mutual Fund\"\n\nclass Locale(Enum):\n    US = \"us\"\n    GLOBAL = \"global\"\n\nclass Sentiment(Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    NEGATIVE = \"negative\"\n\nclass VectorStoreResult(BaseModel):\n    docs: str\n    dist: Optional[float] # requires query\n    meta: Optional[dict]  # requires get or query\n\nclass Aggregate(RestResultPoly):\n    symbol: str\n    open: float\n    high: float\n    low: float\n    close: float\n    volume: int\n    otc: Optional[bool] = None\n    preMarket: Optional[float] = None\n    afterHours: Optional[float] = None\n\nclass DailyCandle(Aggregate):\n    from_date: str\n\nclass AggregateWindow(BaseModel):\n    o: float\n    h: float\n    l: float\n    c: float\n    v: int # traded volume\n    n: Optional[int] = None # transaction count\n    vw: Optional[float] = None # volume weighted average price\n    otc: Optional[bool] = None\n    t: int\n\nclass CustomCandle(RestResultPoly): \n    ticker: str\n    adjusted: bool\n    queryCount: int\n    resultsCount: int\n    results: list[AggregateWindow]\n    \nclass MarketStatus(BaseModel):\n    exchange: str\n    holiday: Optional[str] = None\n    isOpen: bool\n    session: Optional[MarketSession] = None\n    t: int\n    timezone: str\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.session is None:\n            self.session = MarketSession.CLOSED\n        if self.holiday is None:\n            self.holiday = MarketSession.NA.value\n\nclass MarketStatusResult(BaseModel):\n    results: MarketStatus\n\nclass Symbol(BaseModel):\n    description: str\n    displaySymbol: str\n    symbol: str\n    type: SymbolType\n\nclass SymbolResultFinn(BaseModel):\n    count: int\n    result: list[Symbol]\n\nclass Quote(BaseModel):\n    c: float\n    d: float\n    dp: float\n    h: float\n    l: float\n    o: float\n    pc: float\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        return value\n\nclass PeersResultFinn(BaseModel):\n    results: list[str]\n\nclass BasicFinancials(BaseModel):\n    metric: dict\n    metricType: str\n    series: dict\n    symbol: str\n\nclass Insight(BaseModel):\n    sentiment: Sentiment\n    sentiment_reasoning: str\n    ticker: str\n\nclass Publisher(BaseModel):\n    favicon_url: Optional[str]\n    homepage_url: str\n    logo_url: str\n    name: str\n\nclass NewsTypePoly(BaseModel):\n    amp_url: Optional[str] = None\n    article_url: str\n    title: str\n    author: str\n    description: Optional[str] = None\n    id: str\n    image_url: Optional[str] = None\n    insights: Optional[list[Insight]] = None\n    keywords: Optional[list[str]] = None\n    published_utc: str\n    publisher: Publisher\n    tickers: list[str]\n\nclass NewsResultPoly(RestResultPoly):\n    results: list[NewsTypePoly]\n\nclass NewsTypeFinn(BaseModel):\n    category: str\n    datetime: int\n    headline: str\n    id: int\n    image: str\n    related: str # symbol\n    source: str\n    summary: str\n    url: str\n\nclass NewsResultFinn(BaseModel):\n    results: list[NewsTypeFinn]\n\nclass NewsTypeGenerated(BaseModel):\n    title: str\n    summary: str\n    insights: list[Insight]\n    keywords: list[str]\n    source: Publisher\n    published_utc: str\n    tickers: list[str]\n    url: str\n\nclass TickerOverview(BaseModel):\n    ticker: str\n    name: str\n    market: AssetClass\n    locale: Locale\n    primary_exchange: Optional[str] = None\n    active: bool\n    currency_name: str\n    cik: Optional[str] = None\n    composite_figi: Optional[str] = None\n    share_class_figi: Optional[str] = None\n    market_cap: Optional[int] = None\n    phone_number: Optional[str] = None\n    address: Optional[dict] = None\n    description: Optional[str] = None\n    sic_code: Optional[str] = None\n    sic_description: Optional[str] = None\n    ticker_root: Optional[str] = None\n    homepage_url: Optional[str] = None\n    total_employees: Optional[int] = None\n    list_date: Optional[str] = None\n    branding: Optional[dict] = None\n    share_class_shares_outstanding: Optional[int] = None\n    weighted_shares_outstanding: Optional[int] = None\n    round_lot: Optional[int] = None\n\nclass OverviewResultPoly(RestResultPoly):\n    results: TickerOverview\n\nclass RecommendationTrend(BaseModel):\n    buy: int\n    hold: int\n    period: str\n    sell: int\n    strongBuy: int\n    strongSell: int\n    symbol: str\n\nclass TrendsResultFinn(BaseModel):\n    results: list[RecommendationTrend]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:07.828992Z","iopub.execute_input":"2025-05-16T07:00:07.82935Z","iopub.status.idle":"2025-05-16T07:00:07.914559Z","shell.execute_reply.started":"2025-05-16T07:00:07.829288Z","shell.execute_reply":"2025-05-16T07:00:07.913526Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# An embedding function based on text-embedding-004.\nclass GeminiEmbedFunction:\n    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n    \n    def __init__(self, genai_client, semantic_mode: bool = False):\n        self.client = genai_client\n        if semantic_mode:\n            self.document_mode = False\n            self.semantic_mode = True\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __embed__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        elif not self.document_mode and not self.semantic_mode:\n            embedding_task = \"retrieval_query\"\n        elif not self.document_mode and self.semantic_mode:\n            embedding_task = \"semantic_similarity\"\n        partial = self.client.models.embed_content(\n            model=api(Gemini.Model.EMB),\n            contents=input,\n            config=types.EmbedContentConfig(task_type=embedding_task))\n        return [e.values for e in partial.embeddings]\n    \n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __call__(self, input: Documents) -> Embeddings:\n        try:\n            response = []\n            for i in range(0, len(input), Gemini.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n                response += self.__embed__(input[i:i + Gemini.Const.EmbedBatch()])\n            return response\n        except Exception as e:\n            print(f\"caught exception of type {type(e)}\\n{e}\")\n            raise e\n\n    def sts(self, content: list) -> float:\n        df = pandas.DataFrame(self(content), index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:07.916359Z","iopub.execute_input":"2025-05-16T07:00:07.916766Z","iopub.status.idle":"2025-05-16T07:00:07.928045Z","shell.execute_reply.started":"2025-05-16T07:00:07.916722Z","shell.execute_reply":"2025-05-16T07:00:07.92679Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# An implementation of Retrieval-Augmented Generation.\n# - using Chroma and text-embedding-004 for storage and retrieval\n# - using gemini-2.0-flash for augmented generation\nclass RetrievalAugmentedGenerator:\n    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n\n    def __init__(self, genai_client, collection_name):\n        self.client = genai_client\n        self.embed_fn = GeminiEmbedFunction(genai_client)\n        self.db = self.chroma_client.get_or_create_collection(\n            name=collection_name, \n            embedding_function=self.embed_fn, \n            metadata={\"hnsw:space\": \"cosine\"})\n\n    def add_documents_list(self, docs: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n        content=[doc.page_content for doc in docs]\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n\n    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        splitter = RecursiveJsonSplitter(max_chunk_size=Gemini.Const.ChunkMax())\n        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        content = [json.dumps({\"question\": query, \"answer\": doc.page_content}) for doc in docs]\n        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n\n    def add_peers_document(self, query: str, peers: dict, topic: str, source: str, group: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        tqdm(self.db.add(ids=str(self.db.count()), \n                         documents=[json.dumps({\"question\": query, \"answer\": peers})], \n                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]), \n             desc=\"Generate peers embedding\")\n\n    def get_peers_document(self, query: str, topic: str, group: str):\n        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n\n    def add_rest_chunks(self, chunks: list, topic: str, source: str, meta_opt: Optional[list[dict]] = None):\n        self.embed_fn.document_mode = True # Switch to document mode\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n        if isinstance(chunks[0], BaseModel):\n            docs = [model.json() for model in chunks]\n        else:\n            docs = [json.dumps(obj) for obj in chunks]\n        meta_base = {\"source\": source, \"topic\": topic}\n        if meta_opt is not None:\n            for m in meta_opt:\n                m.update(meta_base) \n        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n        tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Generate chunks embedding\")\n\n    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n        return self.get_documents_list(\n            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def get_news_documents(self, query: str, topic: str, source: str, metas: list[dict]):\n        return self.get_documents_list(\n            query, max_sources=1000, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=[json.dumps({\"question\": query, \"answer\": quote})], \n                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n             desc=\"Generate quote embedding\")\n\n    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n                          meta_opt: Optional[list[dict]] = None):\n        where = [{\"source\": source}, {\"topic\": topic}]\n        if meta_opt is None:\n            return self.get_documents_list(query, where={\"$and\": where})\n        else:\n            for meta in meta_opt:\n                for k,v in meta.items():\n                    where.append({k: v})\n            return self.get_documents_list(query, where={\"$and\": where})\n\n    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_grounded_document(self, query: str, topic: str, result):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n        supports = result.candidates[0].grounding_metadata.grounding_supports\n        if supports is not None: # Only add grounded documents which have supports\n            text = [f\"{s.segment.text}\" for s in supports]\n            source = [f\"{c.web.title}\" for c in chunks]\n            score = [f\"{s.confidence_scores}\" for s in supports]\n            tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=[json.dumps({\"text\": \", \".join(text)})], \n                             metadatas=[{\"source\": \", \".join(source), \n                                         \"confidence_score\": \", \".join(score), \n                                         \"topic\": topic,\n                                         \"question\": query}]), \n                 desc=\"Generate grounding embedding\")\n\n    def get_grounding_documents(self, query: str, topic: str):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.result_model(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n            \n    def add_wiki_documents(self, title: str, documents: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        result = self.get_wiki_documents(title)\n        if len(result[\"documents\"]) == 0:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(documents))))\n            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(documents)\n            tqdm(self.db.add(ids=ids, documents=documents, metadatas=metas), desc=\"Generate wiki embeddings\")\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_with_wiki_passages(self, query: str, title: str, passages: list):\n        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n    \n    def get_wiki_documents(self, title: Optional[str] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        if title is None:\n            return self.result_model(self.db.get(where={\"source\": \"add_wiki_document\"}))\n        else:\n            return self.result_model(self.db.get(where={\"title\": title}))\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.result_model(\n            self.db.query(query_texts=[query], \n                          n_results=max_sources, \n                          where=where), \n            is_query = True)\n\n    def result_model(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n        try:\n            results = []\n            for i in range(len(result[\"documents\"][0])):\n                obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n                                        dist=result[\"distances\"][0][i] if is_query else None,\n                                        meta=result[\"metadatas\"][0][i])\n                results.append(obj)\n            return results\n        except Exception as e:\n            print(f\"vector store result exception {type(e)}\\n{e}\")\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_exchanges_csv(self, query: str):\n        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_answer(self, query: str, max_sources: int = 10, \n                        where: Optional[dict] = None, passages: Optional[list] = None):\n        stored = self.get_documents_list(query, max_sources, where)\n        query_oneline = query.replace(\"\\n\", \" \")\n        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n\n        QUESTION: {query_oneline}\n        \n        \"\"\"\n        # Add the retrieved documents to the prompt.\n        for passage in stored if passages is None else stored + passages:\n            passage_oneline = passage.docs.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n    \n        return api.retriable(self.client.models.generate_content, \n                             model=api(Gemini.Model.GEN), \n                             config=self.config_temp, \n                             contents=prompt)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:07.929724Z","iopub.execute_input":"2025-05-16T07:00:07.930092Z","iopub.status.idle":"2025-05-16T07:00:08.778859Z","shell.execute_reply.started":"2025-05-16T07:00:07.93005Z","shell.execute_reply":"2025-05-16T07:00:08.777766Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# An implementation of Wiki-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by similarity to topic\n# - retrieve existing groundings by similarity to topic\nclass WikiGroundingGenerator:   \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\") # suppress beta-warning\n            self.splitter = HTMLSemanticPreservingSplitter(\n                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n                max_chunk_size=2000, # chunk by token limit of models/text-embedding-004\n                chunk_overlap=50,\n                preserve_links=True,\n                preserve_images=True,\n                preserve_videos=True,\n                preserve_audio=True,\n                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n                denylist_tags=[\"script\", \"style\", \"head\"],\n                custom_handlers={\"code\": self.code_handler},\n            )\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_wiki_documents(topic)\n        if len(stored) > 0:\n            return self.rag.generate_with_wiki_passages(query, topic, stored).text\n        else:\n            pages = wikipedia.search(topic + \" company\")\n            if len(pages) > 0:\n                p_topic_match = 0.80\n                for i in range(len(pages)):\n                    if tqdm(self.similarity(topic, pages[i]) > p_topic_match, \n                            desc= \"Score wiki search by similarity to topic\"):\n                        request = requests.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n                        chunks = [\n                            VectorStoreResult(\n                                docs=chunk.page_content\n                            ) for chunk in self.splitter.split_text(request.text)]\n                        self.rag.add_wiki_documents(topic, chunks)\n                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n\n    def code_handler(self, element: Tag) -> str:\n        data_lang = element.get(\"data-lang\")\n        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n        return code_format\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, topic: str, page: str):\n        return GeminiEmbedFunction(api.client, semantic_mode = True).sts([topic + \" company\", page])","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:08.78059Z","iopub.execute_input":"2025-05-16T07:00:08.780945Z","iopub.status.idle":"2025-05-16T07:00:08.792577Z","shell.execute_reply.started":"2025-05-16T07:00:08.780913Z","shell.execute_reply":"2025-05-16T07:00:08.791246Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# An implementation of Search-Grounding Generation.\n# - using gemini-2.0-flash with GoogleSearch tool for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by exact match to topic\n# - retrieve existing groundings by similarity to topic\nclass SearchGroundingGenerator:\n    config_ground = types.GenerateContentConfig(\n        tools=[types.Tool(google_search=types.GoogleSearch())],\n        temperature=0.0\n    )\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_grounding_documents(query, topic)\n        if len(stored) > 0:\n            for i in range(len(stored)):\n                doc = stored[i].docs\n                meta_q = stored[i].meta[\"question\"]\n                p_ground_match = 0.95 # This can be really high ~ 95-97%\n                if tqdm(self.similarity(query, meta_q) > p_ground_match,\n                        desc=\"Score similarity to stored grounding\"):\n                    return ast.literal_eval(doc)[0][\"text\"]\n        return self.get_grounding(query, topic)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, question: str, compare: str):\n        return GeminiEmbedFunction(api.client, semantic_mode = True).sts([question, compare])\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_grounding(self, query: str, topic: str):\n        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n        contents += f\"\"\"\n        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n        If an answer is not possible respond with: I don't know.\"\"\"\n        response = api.retriable(self.client.models.generate_content, \n                                 model=api(Gemini.Model.GEN), \n                                 config=self.config_ground, \n                                 contents=contents)\n        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n            if topic.replace(\"'\", \"\") not in response.text: # Exact topic match required\n                return StopGeneration() # Workaround a bug in gemini-2.0-flash (MGM Studio becomes MGM Resorts)\n            else:\n                self.rag.add_grounded_document(query, topic, response)\n                return response.text\n        return StopGeneration() # Empty grounding_supports means grounding not possible for query.","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:08.793985Z","iopub.execute_input":"2025-05-16T07:00:08.794334Z","iopub.status.idle":"2025-05-16T07:00:08.812353Z","shell.execute_reply.started":"2025-05-16T07:00:08.794273Z","shell.execute_reply":"2025-05-16T07:00:08.811195Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# An implementation of Rest-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - reduce long-context by chunked pre-processing\nclass RestGroundingGenerator:\n    exchange_codes: Optional[dict] = None\n    exchange_lists: dict = {}\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def exchange_codes(self) -> dict:\n        if self.exchange_codes is None:\n            data = self.rag.get_exchanges_csv(\n                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n                mapping exchange code to name. Just the dictionary string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\")\n            self.exchange_codes = ast.literal_eval(data.text.strip(\"\\`\"))\n        return self.exchange_codes\n\n    def exchange_codes(self, with_query: str):\n        if with_query not in self.exchange_lists.keys():\n            data = self.rag.get_exchanges_csv(\n                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n                as a list in string form. Just the list string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\")\n            self.exchange_list[with_query] = ast.literal_eval(data.text)\n        return self.exchange_lists[with_query]\n\n    def last_market_close(self, status: MarketStatus):\n        est = pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n        return self.rag.get_exchanges_csv(\n            f\"\"\"Answer based on your knowledge of exchange operating hours.\n            Do not answer in full sentences. Omit all chat and provide the answer only.\n            All exchanges are open on weekdays. Weekdays are: Mon, Tue, Wed, Thu, Fri. Open/Close happens on weekdays.\n            All exchanges are closed on weekends. Weekends are: Sat, Sun. No Open/Close happens on weekends.\n            The fields pre_market and post_market both represent open hours.\n            \n            The current date and time is: {datetime.now(est).strftime('%c')}\n            The current market session is: {status.session.value}\n            \n            When was the US exchange's last operating hours? \n            Provide the last weekday's close.\n            Include any post-market hours.\n            If the current market session is closed today cannot be the answer.\n            Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\").text\n\n    def get(self, url: str) -> Optional[str]:\n        try:\n            request = requests.get(url)\n            if request.status_code != requests.codes.ok:\n                print(f\"the endpoint returned status {request.status_code}\")\n            return request.text\n        except Exception as e:\n            raise e\n\n    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n        try:\n            if from_lambda:\n                return schema(results=json.loads(data))\n            return schema.model_validate_json(data)\n        except Exception as e:\n            raise e\n\n    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n        try:\n            date = json.loads(data)[\"from\"]\n            agg = self.basemodel(data, Aggregate)\n            return DailyCandle(from_date=date, \n                               status=agg.status.value, \n                               symbol=agg.symbol, \n                               open=agg.open, \n                               high=agg.high, \n                               low=agg.low, \n                               close=agg.close, \n                               volume=agg.volume, \n                               otc=agg.otc, \n                               preMarket=agg.preMarket, \n                               afterHours=agg.afterHours)\n        except Exception as e:\n            raise e\n\n    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, success_fn: Callable, *args, **kwargs):\n        try:\n            data = self.get(url)\n            if schema is DailyCandle:\n                model = self.dailycandle(data)\n            else:\n                model = self.basemodel(data, schema, as_lambda)\n        except Exception as e:\n            try:\n                if issubclass(schema, RestResultPoly):\n                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n                print(e)\n            except Exception as not_a_result:\n                print(not_a_result)\n            return StopGeneration()\n        else:\n            return success_fn(*args, **kwargs, model=model)\n\n    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResultFinn):\n        matches = []\n        max_failed_match = model.count if not by_name else 3\n        p_desc_match = 0.80\n        p_symb_match = 0.95\n        if model.count > 0:\n            for obj in tqdm(model.result, desc=\"Score similarity to query\"):\n                if max_failed_match > 0:\n                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n                    symb = [with_content[\"q\"].upper(), obj.symbol]\n                    if by_name and similarity(desc) > p_desc_match: \n                        matches.append(obj.symbol)\n                    elif not by_name and similarity(symb) > p_symb_match:\n                        matches.append(obj.description)\n                        max_failed_match = 0\n                    else:\n                        max_failed_match -= 1\n        if len(matches) > 0:\n            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n            return matches\n        else:\n            return StopGeneration()\n\n    def get_quote(self, with_content, model: Quote):\n        quote = model.json()\n        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n        return quote\n\n    def get_quote_store(self, with_content, model: VectorStoreResult):\n        last_close = parse(self.last_market_close(get_market_status_1(with_content, as_model=True))).timestamp()\n        for obj in model:\n            if obj.meta[\"timestamp\"] >= last_close:\n                return [json.loads(quote.docs)[\"answer\"] for quote in model]\n        return get_current_price_1(with_content) # update stale quotes\n\n    def get_peers(self, with_content, model: PeersResultFinn):\n        if len(model.results) == 0:\n            return StopGeneration().json()\n        else:\n            names = []\n            for peer in model.results:\n                if peer == with_content[\"symbol\"]:\n                    continue # skip including the query symbol in peers\n                name = get_name_1(dict(q=peer, exchange=with_content[\"exchange\"], query=with_content[\"query\"]))\n                if not isinstance(name, StopGeneration):\n                    data = {\"symbol\": peer, \"name\": name}\n                    names.append(data)\n            peers = {\"symbol\": with_content[\"symbol\"], \"peers\": names}\n            self.rag.add_peers_document(\n                with_content[\"query\"], peers, with_content[\"symbol\"], \"get_peers_1\", with_content['grouping'])\n            return list(peers.items())\n\n    def get_financials(self, with_content, model: BasicFinancials):\n        metric = list(model.metric.items())\n        chunks = []\n        # Chunk the metric data.\n        for i in range(0, len(metric), Gemini.Const.MetricBatch()):\n            batch = metric[i:i + Gemini.Const.MetricBatch()]\n            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n        # Chunk the series data.\n        for key in model.series.keys():\n            series = list(model.series[key].items())\n            for s in series:\n                if api.token_count(s) <= Gemini.Const.ChunkMax():\n                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n                else:\n                    k = s[0]\n                    v = s[1]\n                    for i in range(0, len(v), Gemini.Const.SeriesBatch()):\n                        batch = v[i:i + Gemini.Const.SeriesBatch()]\n                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n        return chunks\n\n    def get_news(self, with_content, model: NewsResultFinn):\n        if len(model.results) == 0:\n            return StopGeneration().json()\n        else:\n            metas = [{\n                \"origin\": digest.source,\n                \"published\": digest.datetime,\n                \"news_id\": digest.id,\n                \"related\": digest.related} for digest in model]\n            news = [digest.json() for digest in model.results]\n            self.rag.add_rest_chunks(news, topic=with_content[\"symbol\"], source=\"get_news_1\", meta_opt=metas)\n            return news\n\n    def get_daily_candle(self, with_content, model: Optional[DailyCandle] = None, \n                         result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            candle = [{\"question\": with_content[\"query\"], \"answer\": model.json()}]\n            self.rag.add_rest_chunks(\n                chunks=candle, \n                topic=with_content[\"stocksTicker\"], \n                source=\"daily_candle_2\", \n                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n            return candle\n        elif result and result.status is RestStatus.NONE:\n            # Attempt to recover from choosing a holiday.\n            date = parse(with_content[\"date\"])\n            if date.weekday() == 4: # index 4 for friday\n                with_content[\"date\"] = date.replace(day=date.day-1).strftime(\"%Y-%m-%d\")\n            elif date.weekday() == 0: # index 0 for monday\n                with_content[\"date\"] = date.replace(day=date.day-3).strftime(\"%Y-%m-%d\")\n            else:\n                return result.json()\n            return get_daily_candle_2(with_content)\n        elif result:\n            return result.json()\n\n    def get_custom_candle(self, with_content, model: Optional[CustomCandle] = None, \n                          result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = [{\n                \"timespan\": with_content[\"timespan\"],\n                \"adjusted\": with_content[\"adjusted\"],\n                \"from\": with_content[\"from\"],\n                \"to\": with_content[\"to\"]}]*len(model.results)\n            candles = [candle.json() for candle in model.results]\n            self.rag.add_rest_chunks(\n                chunks=candles,\n                topic=with_content[\"stocksTicker\"],\n                source=\"custom_candle_2\",\n                meta_opt=metas)\n            return candles\n        elif result:\n            return result.json()\n\n    def get_overview(self, with_content, model: OverviewResultPoly):\n        overview = [model.results.json()]\n        tool_rag.add_rest_chunks(\n            chunks=overview,\n            topic=with_content[\"ticker\"],\n            source=\"ticker_overview_2\")\n        return overview\n\n    def get_trends(self, with_content, model: TrendsResultFinn):\n        if len(model.results) == 0:\n            return StopGeneration().json()\n        else:\n            metas = [{\"period\": trend.period} for trend in model.results]\n            trends = [trend.json() for trend in model.results]\n            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n            return trends","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:00:08.813746Z","iopub.execute_input":"2025-05-16T07:00:08.814043Z","iopub.status.idle":"2025-05-16T07:00:08.853773Z","shell.execute_reply.started":"2025-05-16T07:00:08.814016Z","shell.execute_reply":"2025-05-16T07:00:08.852568Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Testing the RAG Implementation\n\n<span style=\"font-size:18px;\">\nLet's load some test data and see what the RAG can do. The test data is a CSV file containing stock market exchange data. It includes the market id code, name, locale, and operating hours. The import will use CSVLoader from <code>langchain-community</code> to parse the exchange data into Documents that our RAG can ingest.\n</span>","metadata":{}},{"cell_type":"code","source":"# Load the exchange data from source csv.\n# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n# - Also maps the exchange code to exchange details.\ndf = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\").drop([\"close_date\"], axis=1).fillna(\"\")\ndf.to_csv(\"exchanges.csv\", index=False)\nexchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n\n# Prepare a RAG tool for use and add the exchange data.\ntool_rag = RetrievalAugmentedGenerator(api.client, \"finance\")\ntool_rag.add_documents_list(exchanges)\n\n# Prepare a the grounding tools for use.\ntool_wiki = WikiGroundingGenerator(api.client, tool_rag)\ntool_ground = SearchGroundingGenerator(api.client, tool_rag)\ntool_rest = RestGroundingGenerator(api.client, tool_rag)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:08.855178Z","iopub.execute_input":"2025-05-16T07:00:08.855539Z","iopub.status.idle":"2025-05-16T07:00:09.736025Z","shell.execute_reply.started":"2025-05-16T07:00:08.855496Z","shell.execute_reply":"2025-05-16T07:00:09.735059Z"}},"outputs":[{"name":"stderr","text":"Generate document embedding: 0it [00:00, ?it/s]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nNow that the data is loaded lets ask our RAG to perform some augmenting. We can ask it to perform all sorts of useful tasks. We'll generate some useful reusable data structures and check to make sure it can answer important questions. The exchanges all have id's which are used to filter the realtime data. So we'll make sure the RAG know how to create this mapping. We'll also check it's awareness of operating hours. After all, Essy, doesn't mindlessly hammer away at api's when no new data is available.\n</span>","metadata":{}},{"cell_type":"code","source":"# The RAG tool is a helpful expert.\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n    exchange code to name. Just the dictionary string in pretty form.\"\"\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n    comma separated value that I can copy.\"\"\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\nprint(response.text, \"\\n\")\n\nest = pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\nresponse = tool_rag.get_exchanges_csv(\n    f\"\"\"Answer based on your knowledge of exchange operating hours. \n    Do not answer in full sentences. Omit all chat and provide the answer only. \n    All exchanges are open on weekdays. Weekdays are: Mon, Tue, Wed, Thu, Fri. Open/Close happens on weekdays. \n    All exchanges are closed on weekends. Weekends are: Sat, Sun. No Open/Close happens on weekends. \n    The fields pre_market and post_market both represent open hours.\n    \n    The current date and time is: {datetime.now(est).strftime('%c')}\n    \n    When was the US exchange's last operating hours? Provide the last weekday's close. Include any post-market hours. \n    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\nprint(response.text)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:09.737442Z","iopub.execute_input":"2025-05-16T07:00:09.737769Z","iopub.status.idle":"2025-05-16T07:00:21.542793Z","shell.execute_reply.started":"2025-05-16T07:00:09.737736Z","shell.execute_reply":"2025-05-16T07:00:21.541604Z"}},"outputs":[{"name":"stdout","text":"```\n{\n    \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n    \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n    \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n    \"DB\": \"DUBAI FINANCIAL MARKET\",\n    \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n    \"QA\": \"QATAR EXCHANGE\",\n    \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n    \"SW\": \"SWISS EXCHANGE\",\n    \"DU\": \"BOERSE DUESSELDORF\",\n    \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n    \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n    \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n    \"SI\": \"SINGAPORE EXCHANGE\",\n    \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n    \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n    \"L\": \"LONDON STOCK EXCHANGE\",\n    \"ME\": \"MOSCOW EXCHANGE\",\n    \"TO\": \"TORONTO STOCK EXCHANGE\",\n    \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n    \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n    \"US\": \"US exchanges (NYSE, Nasdaq)\",\n    \"TW\": \"TAIWAN STOCK EXCHANGE\",\n    \"JK\": \"INDONESIA STOCK EXCHANGE\",\n    \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n    \"VS\": \"NASDAQ OMX VILNIUS\",\n    \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n    \"DE\": \"XETRA\",\n    \"PR\": \"PRAGUE STOCK EXCHANGE\",\n    \"BK\": \"STOCK EXCHANGE OF THAILAND\",\n    \"VI\": \"Vienna Stock Exchange\",\n    \"MU\": \"BOERSE MUENCHEN\",\n    \"KL\": \"BURSA MALAYSIA\",\n    \"BE\": \"BOERSE BERLIN\",\n    \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n    \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n    \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n    \"PM\": \"Philippine Stock Exchange\",\n    \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n    \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n    \"IC\": \"NASDAQ OMX ICELAND\",\n    \"SG\": \"BOERSE STUTTGART\",\n    \"MC\": \"BOLSA DE MADRID\",\n    \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n    \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n    \"CR\": \"CARACAS STOCK EXCHANGE\",\n    \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n    \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n    \"IS\": \"BORSA ISTANBUL\",\n    \"AX\": \"ASX - ALL MARKETS\",\n    \"KW\": \"Kuwait Stock Exchange\",\n    \"NE\": \"AEQUITAS NEO EXCHANGE\",\n    \"SR\": \"SAUDI STOCK EXCHANGE\",\n    \"F\": \"DEUTSCHE BOERSE AG\",\n    \"SA\": \"Brazil Bolsa - Sao Paolo\",\n    \"CA\": \"Egyptian Stock Exchange\",\n    \"MT\": \"MALTA STOCK EXCHANGE\",\n    \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n    \"HA\": \"Hanover Stock Exchange\",\n    \"BH\": \"BAHRAIN BOURSE\",\n    \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n    \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n    \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n    \"MI\": \"Italian Stock Exchange\",\n    \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n    \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n    \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n    \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n    \"OL\": \"OSLO BORS ASA\",\n    \"TL\": \"NASDAQ OMX TALLINN\",\n    \"TWO\": \"TPEx\",\n    \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n    \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n    \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n    \"BO\": \"BSE LTD\",\n    \"RG\": \"NASDAQ OMX RIGA\",\n    \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n    \"NL\": \"Nigerian Stock Exchange\"\n}\n```\nBE, SX, TG, DE, DU, F, MU, SG, SC, HM, HA\n \n\nThe Germany exchanges and their corresponding codes are: BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), XETRA (DE), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), DEUTSCHE BOERSE AG (F), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE STUTTGART (SG), Hanover Stock Exchange (HA), and DEUTSCHE BOERSE TradeGate (TG), and BOERSE_FRANKFURT_ZERTIFIKATE (SC).\n \n\nI don't know.\n\nIn the United States, pre-market trading hours are from 04:00 to 09:30, regular trading hours are from 09:30 to 16:00, and post-market trading hours are from 16:00 to 20:00, all in the America/New_York time zone. These hours apply to exchanges such as NYSE and Nasdaq.\n \n\nThu May 15 20:00:00 2025\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nExcellent! Though, despite my best effort I could not convince Gemini to apply date correction (during chaining) based on holiday. It simply wasn't stable enough to be useful. I would either have to add a holiday data set, or (what I chose) apply a quick temporary fix. A real-time API endpoint may fail due to a holiday being selected as the date. If that happens I'll just retry Thursday if the failure happened on Friday, likewise choosing Friday if the failure happened on Monday. Crude but simple for foundational purposes.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Declaring the Function Calling Metadata\n\n<span style=\"font-size:18px;\">\nOur Function Calling expert will chain together the other experts we've implemented thus far. It also provides the final response through augmentation. This time using the tools as a source of grounding truth. It'd like to say it's all truth organised by topic and other metadata. It's still a precarious situation if Essy incidently chains into mining data on another topic. We want Amazon to be the owner of MGM Studio's not MGM Resorts International. We also don't want a summary to include another company unless that company is a peer.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe function calling metadata is thus extremely important. It needs to combine our other experts with the real-time api's data. Essy will use two API providers as sources of finance data. The primary motivation being that each provider has limits in their own way, yet both are useful in their own own way. This is useful anywhere you need a broad spectrum of sources of truth. At metadata creation I'll adopt the naming convention of appending the provider (if any) id. This helps keep functions more understandable when you know which provider you're dealing with.\n</span>","metadata":{}},{"cell_type":"code","source":"# Declare callable functions using OpenAPI schema.\ndecl_get_symbol_1 = types.FunctionDeclaration(\n    name=\"get_symbol_1\",\n    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n                   calling get_wiki_tool_response next.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_symbols_1 = types.FunctionDeclaration(\n    name=\"get_symbols_1\",\n    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"exchange\", \"query\"]\n    }\n)\n\ndecl_get_name_1 = types.FunctionDeclaration(\n    name=\"get_name_1\",\n    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"company\": {\n                \"type\": \"string\",\n                \"description\": \"The company you're searching for.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n    }\n)\n\ndecl_get_symbol_quote_1 = types.FunctionDeclaration(\n    name=\"get_symbol_quote_1\",\n    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n                   provided in json format. Each response contains the following key-value pairs:\n                   \n                   c: Current price,\n                   d: Change,\n                  dp: Percent change,\n                   h: High price of the day,\n                   l: Low price of the day,\n                   o: Open price of the day,\n                  pc: Previous close price,\n                   t: Epoch timestamp of price in seconds.\n\n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\", \"exchange\"]\n    }\n)\n\ndecl_get_local_datetime = types.FunctionDeclaration(\n    name=\"get_local_datetime\",\n    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n                   function to format date and time in your responses.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"t\": {\n                \"type\": \"array\",\n                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n                                  timestamps matches the order of conversion.\"\"\",\n                \"items\": {\n                    \"type\": \"integer\"\n                }\n            }\n        },\n        \"required\": [\"t\"]\n    }\n)\n\ndecl_get_market_status_1 = types.FunctionDeclaration(\n    name=\"get_market_status_1\",\n    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n                   Also includes holiday details if applicable. The response is provided in json format. Each response \n                   contains the following key-value pairs:\n\n                   exchange: Exchange code,\n                   timezone: Timezone of the exchange,\n                    holiday: Holiday event name, or null if it's not a holiday,\n                     isOpen: Whether the market is open at the moment,\n                          t: Epoch timestamp of status in seconds (Eastern Time),\n                    session: The market session can be 1 of the following values: \n                    \n                    pre-market,regular,post-market when open, or null if closed.\n                    \n                    Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_company_peers_1 = types.FunctionDeclaration(\n    name=\"get_company_peers_1\",\n    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n                   \n                   symbol: The company's stock ticker symbol, \n                   peers: A list containing the peers.\n                   \n                   Each peers entry contains the following key-value pairs:\n                   \n                   symbol: The peer company's stock ticker symbol, \n                   name: The peer company's name.\n                   \n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n            },\n            \"grouping\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n                                  Always use subIndustry unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_exchange_codes_1 = types.FunctionDeclaration(\n    name=\"get_exchange_codes_1\",\n    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n)\n\ndecl_get_exchange_code_1 = types.FunctionDeclaration(\n    name=\"get_exchange_code_1\",\n    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n                   more exchange codes provided as a comma-separated string value.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"Specifies which exchange code to search for.\"\n            }\n        },\n        \"required\": [\"q\"]\n    }\n)\n\ndecl_get_financials_1 = types.FunctionDeclaration(\n    name=\"get_financials_1\",\n    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"metric\": {\n                \"type\": \"string\",\n                \"description\": \"It must always be declared as the value 'all'\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"metric\", \"query\"]\n    }\n)\n\ndecl_get_daily_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_daily_candlestick_2\",\n    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n                   volume and pre-market/after-hours trade prices. It does not provide today's data until after \n                   11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"date\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicated whether or not the results are adjusted for splits. \n                                  By default, results are adjusted. Set this to false to get results that are NOT \n                                  adjusted for splits.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"query\"]\n    },\n)\n\ndecl_get_company_news_1 = types.FunctionDeclaration(\n    name=\"get_company_news_1\",\n    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\",\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'. The default\n                                  value is one month ago.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n                                  default value is today's date.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n    },\n)\n\ndecl_get_custom_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_custom_candlestick_2\",\n    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n                   includes historical daily trade volume and pre-market/after-hours trade prices. It does not\n                   include today's open, high, low, or close until after 11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"multiplier\": {\n                \"type\": \"integer\",\n                \"description\": \"This must be 1 unless told otherwise.\"\n            },\n            \"timespan\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'. The default\n                                  value is one-month ago from today's date.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n                                  default is one weekday prior to get_last_market_close (excluding weekends).\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicated whether or not the results are adjusted for splits. \n                                  By default, results are adjusted. Set this to false to get results that are NOT \n                                  adjusted for splits.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be one of asc or desc. asc will sort by timestmap in ascending order. desc will\n                                  sort by timestamp in descending order.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n                                  unless told to limit base aggregates to something else.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n    },\n)\n\ndecl_get_last_market_close = types.FunctionDeclaration(\n    name=\"get_last_market_close\",\n    description=\"\"\"Get the last market close of the specified exchange.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_ticker_overview_2 = types.FunctionDeclaration(\n    name=\"get_ticker_overview_2\",\n    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a company’s \n    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n    the form of icons and logos.\n    \"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol of a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"query\"]\n    }\n)\n\ndecl_get_recommendation_trends_1 = types.FunctionDeclaration(\n    name=\"get_recommendation_trends_1\",\n    description=\"\"\"Get the latest analyst recommendation trends for a company.\n                The data includes the latest recommendations as well as historical\n                recommendation data for each month. The data is classified according\n                to these categories: strongBuy, buy, hold, sell, and strongSell.\n                The date of a recommendation indicated by the value of 'period'.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\"]\n    }\n)\n\ndecl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n    name=\"get_news_with_sentiment_2\",\n    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n                   comprehensive coverage. Including a summary, publisher information, article metadata, \n                   and sentiment analysis.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"published_utc\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"Omit this parameter unless you're told told to filter by published_utc.\"\"\"\n            },\n            \"order\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n                                  When order is not specified the default is descending order.\n                                  Ordering will be based on the parameter: sort.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"This must be 100 unless told to limit news results to something else.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The sort field used for ordering. This value must\n                                  always be published_utc.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"order\", \"limit\", \"sort\", \"query\"]\n    }\n)\n\ndecl_get_rag_tool_response = types.FunctionDeclaration(\n    name=\"get_rag_tool_response\",\n    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"question\": {\n                \"type\": \"string\",\n                \"description\": \"A question needing an answer. Asked as a simple string.\"\n            }\n        }\n    }\n)\n\ndecl_get_wiki_tool_response = types.FunctionDeclaration(\n    name=\"get_wiki_tool_response\",\n    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n                   product, or service. Each web page includes detailed company information, financial indicators, \n                   tickers, symbols, history, and products and services.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. Just the name and no other details.\"\n            },\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The complete, unaltered, query string.\"\n            }\n        },\n        \"required\": [\"id\", \"q\"]\n    }\n)\n\ndecl_get_search_tool_response = types.FunctionDeclaration(\n    name=\"get_search_tool_response\",\n    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The question needing an answer. Asked as a simple string.\"\n            },\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n            }\n        },\n        \"required\": [\"q\", \"id\"]\n    }\n)","metadata":{"trusted":true,"_kg_hide-input":false,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:21.544548Z","iopub.execute_input":"2025-05-16T07:00:21.544904Z","iopub.status.idle":"2025-05-16T07:00:21.582998Z","shell.execute_reply.started":"2025-05-16T07:00:21.544869Z","shell.execute_reply":"2025-05-16T07:00:21.581673Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# Implementing the Function Calls\n\n<span style=\"font-size:18px;\">\nOne downside of this part being the main part was the lack of time to refactor this part more. Our formative Essy implements as much useful data from two finacial APIs. In order to use it you will need to declare secrets for <a class=\"anchor-link\" href=\"https://finnhub.io/dashboard\">Finnhub</a> and <a class=\"anchor-link\" href=\"https://polygon.io/dashboard\">Polygon</a> finance APIs. Register at their respective sites for your free API key. Then import the secret using the same method as how you setup Google's API key.\n</span>","metadata":{}},{"cell_type":"code","source":"# Implement the callable functions and the function handler.\n\ndef ask_rag_tool(content):\n    return tool_rag.generate_answer(content[\"question\"]).text\n\ndef ask_wiki_tool(content):\n    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n\ndef ask_search_tool(content):\n    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n\ndef get_exchange_codes_1(content):\n    return tool_rest.exchange_codes()\n\ndef get_exchange_code_1(content):\n    return tool_rest.exchange_codes(with_query=content)\n    \ndef last_market_close(content):\n    return tool_rest.last_market_close(get_market_status_1(content, as_model = True))\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef similarity(content):\n    return GeminiEmbedFunction(api.client, semantic_mode = True).sts(content)\n    \ndef get_symbol_1(content, by_name: bool = True):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=SymbolResultFinn,\n            as_lambda=False,\n            success_fn=tool_rest.get_symbol_matches,\n            with_content=content,\n            by_name=by_name)\n    return json.loads(stored[0].docs)[\"answer\"]\n\ndef get_symbols_1(content):\n    return None # todo\n\ndef get_name_1(content):\n    return get_symbol_1(content, by_name = False)\n\ndef get_quote_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n    isOpen = get_market_status_1(content, as_model = True).isOpen\n    if len(stored) == 0 or isOpen:\n        return get_current_price_1(content)\n    else:\n        return tool_rest.get_quote_store(content, stored)\n\ndef get_current_price_1(content):\n    return tool_rest.try_url(\n        f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n        schema=Quote,\n        as_lambda=False,\n        success_fn=tool_rest.get_quote,\n        with_content=content)\n\ndef get_market_status_1(content, as_model: bool = False):\n    return tool_rest.try_url(\n        f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n        schema=MarketStatusResult, \n        as_lambda=True, \n        success_fn=lambda model: model.results if as_model else model.results.json())\n\ndef get_peers_1(content):\n    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n            schema=PeersResultFinn,\n            as_lambda=True,\n            success_fn=tool_rest.get_peers,\n            with_content=content)\n    return json.loads(stored[0].docs)[\"answer\"][\"peers\"]\n\ndef local_datetime(content):\n    local_t = []\n    for timestamp in content[\"t\"]:\n        local_t.append(local_date_from_epoch(timestamp))\n    return local_t\n\ndef local_date_from_epoch(timestamp):\n    est = pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    if len(str(timestamp)) == 13:\n        return datetime.fromtimestamp(timestamp/1000, tz=est).strftime('%c')\n    else:\n        return datetime.fromtimestamp(timestamp, tz=est).strftime('%c')\n\ndef get_financials_1(content):\n    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n            schema=BasicFinancials,\n            as_lambda=False,\n            success_fn=tool_rest.get_financials,\n            with_content=content)\n    return [chunk.docs for chunk in stored]\n\ndef get_news_1(content):\n    stored = tool_rag.get_news_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n            schema=NewsResultFinn,\n            as_lambda=True,\n            success_fn=tool_rest.get_news,\n            with_content=content)\n    return [news.docs for news in stored]\n\ndef get_daily_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n            schema=DailyCandle,\n            as_lambda=False,\n            success_fn=tool_rest.get_daily_candle,\n            with_content=content)\n    return json.loads(stored[0].docs)[\"answer\"]\n\ndef get_custom_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n        meta_opt=[{\n            \"timespan\": content[\"timespan\"],\n            \"adjusted\": content[\"adjusted\"],\n            \"from\": content[\"from\"],\n            \"to\": content[\"to\"]}])\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"\"\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\"\"\",\n            schema=CustomCandle,\n            as_lambda=False,\n            success_fn=tool_rest.get_custom_candle,\n            with_content=content)\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_overview_2(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n            schema=OverviewResultPoly,\n            as_lambda=False,\n            success_fn=tool_rest.get_overview,\n            with_content=content)\n    return json.loads(stored[0].docs)\n\ndef get_trends_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n    if len(stored) == 0:\n        return tool_rest.try_url(\n            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=TrendsResultFinn,\n            as_lambda=True,\n            success_fn=tool_rest.get_trends,\n            with_content=content)\n    return [json.loads(trend.docs) for trend in stored]\n\ndef get_news_2(content):\n    #news = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"get_news_2\")\n    #if len(news[0]) == 0:\n        url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n        try:\n            request = requests.get(url)\n            news = json.loads(request.text)\n        except:\n            return f\"I don't know. Endpoint returned status {request.status_code}\"\n        else:\n            if news[\"status\"] in [\"OK\",\"DELAYED\"]:\n                #tool_rag.add_api_document(content[\"query\"], news, content[\"ticker\"], \"get_news_2\")\n                return list(news.items())\n            return StopGeneration()\n    #return news\n        \nfinance_tool = types.Tool(\n    function_declarations=[\n        decl_get_symbol_1,\n        decl_get_symbols_1,\n        decl_get_name_1,\n        decl_get_symbol_quote_1,\n        decl_get_market_status_1,\n        decl_get_company_peers_1,\n        decl_get_local_datetime,\n        decl_get_last_market_close,\n        decl_get_exchange_codes_1,\n        decl_get_exchange_code_1,\n        decl_get_financials_1,\n        decl_get_daily_candlestick_2,\n        decl_get_custom_candlestick_2,\n        decl_get_ticker_overview_2,\n        decl_get_recommendation_trends_1,\n        decl_get_news_with_sentiment_2,\n        decl_get_rag_tool_response,\n        decl_get_wiki_tool_response,\n        decl_get_search_tool_response\n    ]\n)\n\nfunction_handler = {\n    \"get_symbol_1\": get_symbol_1,\n    \"get_symbols_1\": get_symbols_1,\n    \"get_name_1\": get_name_1,\n    \"get_symbol_quote_1\": get_quote_1,\n    \"get_market_status_1\": get_market_status_1,\n    \"get_company_peers_1\": get_peers_1,\n    \"get_local_datetime\": local_datetime,\n    \"get_last_market_close\": last_market_close,\n    \"get_exchange_codes_1\": get_exchange_codes_1,\n    \"get_exchange_code_1\": get_exchange_code_1,\n    \"get_financials_1\": get_financials_1,\n    \"get_daily_candlestick_2\": get_daily_candle_2,\n    \"get_custom_candlestick_2\": get_custom_candle_2,\n    \"get_ticker_overview_2\": get_overview_2,\n    \"get_recommendation_trends_1\": get_trends_1,\n    \"get_news_with_sentiment_2\": get_news_2,\n    \"get_rag_tool_response\": ask_rag_tool,\n    \"get_wiki_tool_response\": ask_wiki_tool,\n    \"get_search_tool_response\": ask_search_tool\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:00:21.584905Z","iopub.execute_input":"2025-05-16T07:00:21.585226Z","iopub.status.idle":"2025-05-16T07:00:21.616342Z","shell.execute_reply.started":"2025-05-16T07:00:21.585194Z","shell.execute_reply":"2025-05-16T07:00:21.615028Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Define the system prompt.\n\ninstruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \nOnly answer the question asked and do not change topic. While the answer is still\nunknown you must follow these rules for predicting function call order:\n\nRULE#1: Always consult your other functions before get_search_tool_response.\nRULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\nRULE#3: Always consult get_search_tool_response last.\nRULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\nRULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:21.617637Z","iopub.execute_input":"2025-05-16T07:00:21.617979Z","iopub.status.idle":"2025-05-16T07:00:21.63683Z","shell.execute_reply.started":"2025-05-16T07:00:21.617948Z","shell.execute_reply":"2025-05-16T07:00:21.635598Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Import the finance api secret keys.\n\nPOLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\nFINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:21.638774Z","iopub.execute_input":"2025-05-16T07:00:21.639162Z","iopub.status.idle":"2025-05-16T07:00:21.821104Z","shell.execute_reply.started":"2025-05-16T07:00:21.639128Z","shell.execute_reply":"2025-05-16T07:00:21.819652Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Implement the function calling expert.\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef send_message(prompt):\n    #display(Markdown(\"#### Prompt\"))\n    #print(prompt, \"\\n\")\n    # Define the user prompt part.\n    contents = [types.Content(role=\"user\", parts=[types.Part(text=prompt)])]\n    # Gemini's innate notion of current date and time is unstable.\n    est = pytz.timezone('US/Eastern') # The finance api data is in eastern time.\n    contents += f\"\"\"\n    The current date and time is: {datetime.now(est).strftime('%c')}\n    \n    Give a concise, and detailed summary. Use information that you learn from the API responses.\n    Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n    to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n    Convert timestamps according to the rules before including them.\n    \"\"\"\n    # Enable system prompt, function calling and minimum-randomness.\n    config_fncall = types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=[finance_tool],\n        temperature=0.0\n    )\n    # Handle cases with multiple chained function calls.\n    function_calling_in_process = True\n    while function_calling_in_process:\n        # Send the user prompt and function declarations.\n        response = api.retriable(api.client.models.generate_content, \n                                 model=api(Gemini.Model.GEN), \n                                 config=config_fncall, \n                                 contents=contents)\n        # A part can be a function call or natural language response.\n        for part in response.candidates[0].content.parts:\n            if function_call := part.function_call:\n                # Extract the function call.\n                fn_name = function_call.name\n                #display(Markdown(\"#### Predicted function name\"))\n                #print(fn_name, \"\\n\")\n                # Extract the function call arguments.\n                fn_args = {key: value for key, value in function_call.args.items()}\n                #display(Markdown(\"#### Predicted function arguments\"))\n                #print(fn_args, \"\\n\")\n                # Call the predicted function.\n                api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n                #display(Markdown(\"#### API response\"))\n                #print(api_response[:500], \"...\", \"\\n\")\n                # Create an API response part.\n                api_response_part = types.Part.from_function_response(\n                    name=fn_name,\n                    response={\"content\": api_response},\n                )\n                # Append the model's function call part.\n                contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n                # Append the api response part.\n                contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n            else:\n                # The model gave a natural language response\n                function_calling_in_process = False\n                break # No more parts in response.\n        if not function_calling_in_process:\n            break # The function calling chain is complete.\n            \n    # Show the final natural language summary\n    display(Markdown(\"#### Natural language response\"))\n    display(Markdown(response.text.replace(\"$\", \"\\\\\\\\$\")))","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-05-16T07:00:21.822464Z","iopub.execute_input":"2025-05-16T07:00:21.822789Z","iopub.status.idle":"2025-05-16T07:00:21.834579Z","shell.execute_reply.started":"2025-05-16T07:00:21.822758Z","shell.execute_reply":"2025-05-16T07:00:21.833347Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Ask a question","metadata":{}},{"cell_type":"code","source":"send_message(\"is the US exchange open?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:00:55.320639Z","iopub.execute_input":"2025-05-16T07:00:55.321036Z","iopub.status.idle":"2025-05-16T07:01:29.022864Z","shell.execute_reply.started":"2025-05-16T07:00:55.321001Z","shell.execute_reply":"2025-05-16T07:01:29.02177Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The U.S. exchange is currently closed. The timestamp of the market status is Fri May 16 03:01:13 2025 America/New_York time. There is no holiday today. The market session is closed.\n"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"send_message(\"what is Apple's stock ticker?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:01:35.891154Z","iopub.execute_input":"2025-05-16T07:01:35.891627Z","iopub.status.idle":"2025-05-16T07:01:44.65072Z","shell.execute_reply.started":"2025-05-16T07:01:35.891587Z","shell.execute_reply":"2025-05-16T07:01:44.649646Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 17/17 [00:00<00:00, 20.84it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker for Apple is AAPL.\n"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"send_message(\"What is the current price of Amazon stock?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:01:50.424027Z","iopub.execute_input":"2025-05-16T07:01:50.424457Z","iopub.status.idle":"2025-05-16T07:01:53.871884Z","shell.execute_reply.started":"2025-05-16T07:01:50.424419Z","shell.execute_reply":"2025-05-16T07:01:53.870853Z"}},"outputs":[{"name":"stderr","text":"Generate quote embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current price of Amazon (AMZN) stock is \\\\$205.17. The price changed by -\\\\$5.08, which is a -2.4162% change. The high price of the day was \\\\$206.88, and the low price of the day was \\\\$202.673. The opening price of the day was \\\\$206.45, and the previous close price was \\\\$210.25. The price was last updated on Thu May 15 2025 at 16:00:00.\n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"send_message(\"show me Apple's basic financials\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:01:57.666698Z","iopub.execute_input":"2025-05-16T07:01:57.667105Z","iopub.status.idle":"2025-05-16T07:02:42.932835Z","shell.execute_reply.started":"2025-05-16T07:01:57.66706Z","shell.execute_reply":"2025-05-16T07:02:42.931852Z"}},"outputs":[{"name":"stderr","text":"Generate chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is a summary of Apple's (AAPL) basic financials:\n\n**Financial Highlights:**\n\n*   **52 Week High:** The 52 week high occurred on 2024-12-26 at a price of \\\\$260.1.\n*   **52 Week Low:** The 52 week low occurred on 2025-04-08 at a price of \\\\$169.2101.\n*   **Current Dividend Yield (TTM):** 0.4838%\n*   **Dividend Per Share (TTM):** \\\\$1.0115\n*   **Gross Margin (TTM):** 46.63%\n*   **Net Profit Margin (TTM):** 24.3%\n*   **Revenue Per Employee (TTM):** \\\\$2.4413 million\n*   **Price-to-Earnings Ratio (TTM):** 32.5285\n*   **Beta:** 1.2320454\n\n**Balance Sheet:**\n\n*   **Book Value Per Share (Annual):** \\\\$3.7673\n*   **Book Value Per Share (Quarterly):** \\\\$4.4712\n*   **Current Ratio (Annual):** 0.8673\n*   **Current Ratio (Quarterly):** 0.8209\n*   **Long Term Debt/Equity (Annual):** 1.5057\n*   **Long Term Debt/Equity (Quarterly):** 1.1762\n\n**Growth Metrics:**\n\n*   **EPS Growth (5Y):** 15.41%\n*   **Revenue Growth (5Y):** 8.49%\n*   **Dividend Growth Rate (5Y):** 5.3%\n\n**Valuation Ratios:**\n\n*   **Price-to-Book Ratio:** 47.3805\n*   **Price-to-Sales Ratio (TTM):** 7.9048\n*   **Price-to-Cash Flow Ratio (TTM):** 28.8878\n\n**Profitability Metrics:**\n\n*   **Return on Assets (TTM):** 28.37%\n*   **Return on Equity (TTM):** 151.31%\n*   **Return on Investment (TTM):** 58.95%\n\n**Additional Information:**\n\n*   **Market Capitalization:** \\\\$3164827 million\n*   **Enterprise Value:** \\\\$3234851 million\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"send_message(\"I need Apple's daily candlestick from 2025-05-06\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:02:49.585172Z","iopub.execute_input":"2025-05-16T07:02:49.585672Z","iopub.status.idle":"2025-05-16T07:02:51.947926Z","shell.execute_reply.started":"2025-05-16T07:02:49.58562Z","shell.execute_reply":"2025-05-16T07:02:51.946674Z"}},"outputs":[{"name":"stderr","text":"Generate chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"On May 6, 2025, Apple's stock had the following daily candlestick data: the open price was 198.21, the high price of the day was 200.65, the low price of the day was 197.02, and the close price was 198.51. The trading volume for the day was 51,216,482. The pre-market price was 198.65, and the after-hours price was 201.15.\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"send_message(\"Tell me who are Apple's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:02:56.021403Z","iopub.execute_input":"2025-05-16T07:02:56.021818Z","iopub.status.idle":"2025-05-16T07:03:15.18038Z","shell.execute_reply.started":"2025-05-16T07:02:56.021783Z","shell.execute_reply":"2025-05-16T07:03:15.179191Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 18/18 [00:00<00:00, 105.02it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 108.28it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 103.48it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 99.58it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 17/17 [00:00<00:00, 56.87it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 105.12it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 109.16it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 17/17 [00:00<00:00, 101.49it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nGenerate peers embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple's peers include Dell Technologies - C (DELL), HP Inc (HPQ), Super Micro Computer Inc (SMCI), Hewlett Packard Enterprise (HPE), NetApp Inc (NTAP), Pure Storage Inc - Class A (PSTG), Western Digital Corp (WDC), and IonQ Inc (IONQ).\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"send_message(\"Tell me who are Amazon's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:03:18.584687Z","iopub.execute_input":"2025-05-16T07:03:18.585097Z","iopub.status.idle":"2025-05-16T07:03:36.384486Z","shell.execute_reply.started":"2025-05-16T07:03:18.58506Z","shell.execute_reply":"2025-05-16T07:03:36.383464Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 17/17 [00:00<00:00, 102.92it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 17/17 [00:00<00:00, 99.91it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 109.84it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 107.27it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 17/17 [00:00<00:00, 89.59it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 18/18 [00:00<00:00, 106.78it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 32/32 [00:00<00:00, 193.26it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 20/20 [00:00<00:00, 114.73it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 17/17 [00:00<00:00, 62.76it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nGenerate peers embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The peers of Amazon, operating in the same country and sub-industry, include Coupang Inc (CPNG), Ebay Inc (EBAY), Ollie's Bargain Outlet Holdings (OLLI), Dillards Inc-Cl A (DDS), Etsy Inc (ETSY), Nordstrom Inc (JWN), Macy's Inc (M), Savers Value Village Inc (SVV), and Groupon Inc (GRPN).\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"send_message(\n    \"\"\"Tell me Amazon's current share price and provide candlestick data for the past month.\n    Sort the data in descending order by date. Format the prices consistently as currency.\n    Round prices to two decimal places.\n    Present the data with multiple columns for display in markdown.\"\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:05:23.522324Z","iopub.execute_input":"2025-05-16T07:05:23.522733Z","iopub.status.idle":"2025-05-16T07:05:37.215669Z","shell.execute_reply.started":"2025-05-16T07:05:23.522699Z","shell.execute_reply":"2025-05-16T07:05:37.214563Z"}},"outputs":[{"name":"stderr","text":"Generate chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of May 15, 2025, at 00:00:00 Eastern Time, Amazon's (AMZN) current share price is \\\\$205.17, a decrease of \\\\$5.08 (-2.42%) from the previous close of \\\\$210.25. The high of the day is \\\\$206.88, and the low is \\\\$202.67.\n\nHere is the candlestick data for the past month, sorted in descending order by date:\n\n| Date               | Open    | High    | Low     | Close   | Volume      |\n| ------------------ | ------- | ------- | ------- | ------- | ----------- |\n| May 15, 2025       | \\\\$206.45 | \\\\$206.88 | \\\\$202.67 | \\\\$205.17 | 64,347,317  |\n| May 14, 2025       | \\\\$211.45 | \\\\$211.93 | \\\\$208.85 | \\\\$210.25 | 38,492,128  |\n| May 13, 2025       | \\\\$211.08 | \\\\$214.84 | \\\\$210.10 | \\\\$211.37 | 56,193,682  |\n| May 12, 2025       | \\\\$210.71 | \\\\$211.66 | \\\\$205.75 | \\\\$208.64 | 75,205,042  |\n| May 09, 2025       | \\\\$193.38 | \\\\$194.69 | \\\\$191.16 | \\\\$193.06 | 29,663,143  |\n| May 08, 2025       | \\\\$191.43 | \\\\$194.33 | \\\\$188.82 | \\\\$192.08 | 41,043,620  |\n| May 07, 2025       | \\\\$185.56 | \\\\$190.99 | \\\\$185.01 | \\\\$188.71 | 44,002,926  |\n| May 06, 2025       | \\\\$184.57 | \\\\$187.93 | \\\\$183.85 | \\\\$185.01 | 29,314,055  |\n| May 05, 2025       | \\\\$186.51 | \\\\$188.18 | \\\\$185.53 | \\\\$186.35 | 35,217,469  |\n| May 02, 2025       | \\\\$191.44 | \\\\$192.88 | \\\\$186.40 | \\\\$189.98 | 77,677,487  |\n| May 01, 2025       | \\\\$190.63 | \\\\$191.81 | \\\\$187.50 | \\\\$190.20 | 74,228,963  |\n| Apr 30, 2025       | \\\\$182.17 | \\\\$185.05 | \\\\$178.85 | \\\\$184.42 | 55,176,543  |\n| Apr 29, 2025       | \\\\$183.99 | \\\\$188.02 | \\\\$183.68 | \\\\$187.39 | 41,667,255  |\n| Apr 28, 2025       | \\\\$190.11 | \\\\$190.22 | \\\\$184.89 | \\\\$187.70 | 33,224,732  |\n| Apr 25, 2025       | \\\\$187.62 | \\\\$189.94 | \\\\$185.49 | \\\\$188.99 | 36,413,330  |\n| Apr 24, 2025       | \\\\$180.92 | \\\\$186.74 | \\\\$180.18 | \\\\$186.54 | 43,051,696  |\n| Apr 23, 2025       | \\\\$183.45 | \\\\$187.38 | \\\\$180.19 | \\\\$180.60 | 63,470,094  |\n| Apr 22, 2025       | \\\\$169.85 | \\\\$176.78 | \\\\$169.35 | \\\\$173.18 | 56,607,202  |\n| Apr 21, 2025       | \\\\$169.60 | \\\\$169.60 | \\\\$165.29 | \\\\$167.32 | 48,126,111  |\n| Apr 17, 2025       | \\\\$176.00 | \\\\$176.21 | \\\\$172.00 | \\\\$172.61 | 44,726,453  |\n| Apr 16, 2025       | \\\\$176.29 | \\\\$179.10 | \\\\$171.41 | \\\\$174.33 | 51,866,916  |\n"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"send_message(\"What is Apple's ticker overview\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:05:44.77743Z","iopub.execute_input":"2025-05-16T07:05:44.778328Z","iopub.status.idle":"2025-05-16T07:05:49.652703Z","shell.execute_reply.started":"2025-05-16T07:05:44.778263Z","shell.execute_reply":"2025-05-16T07:05:49.651622Z"}},"outputs":[{"name":"stderr","text":"Generate chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple Incorporated (AAPL) is a major global company offering a wide array of hardware and software for consumers and businesses. Its products include the iPhone, Mac, iPad, and Watch, all integrated within a software ecosystem. Apple is expanding into services like streaming, subscriptions, and augmented reality. The company designs its own software and semiconductors, partnering with manufacturers such as Foxconn and TSMC for production. A significant portion of Apple's sales occurs through its stores, with indirect sales through partnerships also contributing.\n\nKey details:\n*   **Ticker:** AAPL\n*   **Name:** Apple Incorporated\n*   **Market:** Stocks\n*   **Locale:** United States\n*   **Primary Exchange:** XNAS\n*   **CUSIP:** Not available\n*   **Active:** True\n*   **Currency:** United States Dollar (USD)\n*   **CIK:** 0000320193\n*   **Composite FIGI:** BBG000B9XRY4\n*   **Share Class FIGI:** BBG001S5N8V8\n*   **Market Capitalization:** 2949676276740\n*   **Phone Number:** (408) 996-1010\n*   **Address:** One Apple Park Way, Cupertino, CA 95014\n*   **SIC Code:** 3571\n*   **SIC Description:** Electronic Computers\n*   **Ticker Root:** AAPL\n*   **Homepage URL:** https://www.apple.com\n*   **Total Employees:** 164000\n*   **List Date:** 1980-12-12\n*   **Logo URL:** https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04\\_logo.svg\n*   **Icon URL:** https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04\\_icon.png\n*   **Share Class Shares Outstanding:** 14935830000\n*   **Weighted Shares Outstanding:** 14935826000\n*   **Round Lot:** 100"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"send_message(\"Tell me about Amazon's trends\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T07:06:00.619249Z","iopub.execute_input":"2025-05-16T07:06:00.619661Z","iopub.status.idle":"2025-05-16T07:06:03.25667Z","shell.execute_reply.started":"2025-05-16T07:06:00.619626Z","shell.execute_reply":"2025-05-16T07:06:03.255674Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of May 16, 2025, analyst recommendation trends for Amazon (AMZN) indicate the following:\n\n*   **May 2025:** 51 buy recommendations, 6 hold recommendations, 0 sell recommendations, 22 strong buy recommendations, and 0 strong sell recommendations.\n*   **April 2025:** 50 buy recommendations, 4 hold recommendations, 0 sell recommendations, 23 strong buy recommendations, and 0 strong sell recommendations.\n*   **March 2025:** 51 buy recommendations, 5 hold recommendations, 0 sell recommendations, 21 strong buy recommendations, and 0 strong sell recommendations.\n*   **February 2025:** 52 buy recommendations, 5 hold recommendations, 0 sell recommendations, 21 strong buy recommendations, and 0 strong sell recommendations.\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"send_message(\"What is Google's stock ticker symbol?\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"send_message(\"What is MGM Studio's stock symbol?\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"send_message(\"What is Amazon MGM Studio's stock symbol?\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"send_message(\"What is Facebook's stock ticker symbol?\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"send_message(\n    '''Tell me about Amazon's current bullish versus bearish predictions, and recommendation trends.\n    Include a discussion of any short-term trends, and sentiment analysis.''')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"send_message(\n    '''Tell me about Google's share price over the past month.\n    Perform a sentiment analysis of news during the same period. Include trends.''')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"send_message(\n    '''How is the outlook for Apple based on trends and news sentiment over the past month?\n    Perform the same analysis on Apple's peers. Then compare Apple result to it's peers.''')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"send_message(\n    '''What does the recent news say about Apple and the impact of tariffs? Over the past 2 month.\n    Avoid discussing duplicate news entries.''')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\n\n<span style=\"font-size:18px;\">\nFor now that will have to do. Our Essy has a solid foundation but more could be done to organise metadata. No evaluation or validation has been performed (except fuzzing the prompt). Next steps include restructuring the vector database based on lessons learned. That'll be followed by plotting, multi-modal, and structured output. The last close date (generative) function can be temperamental. In the same way Gemini always feels regarding dates. I've learnt so much. I'm happy I decided to participate in the event! It really has been a joy to see Essy grow from random chat with Gemini into the foundation for a good-broker buddy. I hope you enjoy playing with this edition as much as I enjoyed building it!\n</span>","metadata":{}}]}