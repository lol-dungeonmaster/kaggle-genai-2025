{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-2-document-q-a-with-rag.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"},{"sourceId":11376588,"sourceType":"datasetVersion","datasetId":7122584}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oswind/stockchat-a-stock-market-assistant?scriptVersionId=244458421\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Environment Setup","metadata":{}},{"cell_type":"code","source":"# Setup the notebook based on running environment.\nimport os\ntry:\n    from kaggle_secrets import UserSecretsClient\nexcept Exception as e:\n    class UserSecretsClient:\n        @classmethod\n        def get_secret(cls, id: str):\n            try:\n                return os.environ[id]\n            except KeyError as e:\n                print(f\"KeyError: authentication key for {id} is undefined\")\n    # Local Run: update the venv.\n    %pip install -qU google-genai==1.7.0 chromadb==0.6.3\n    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core\nelse:\n    # Kaggle Run: update the system.\n    !pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n    !pip install -qU google-genai==1.7.0 chromadb==0.6.3\n    !pip install -qU langchain-community langchain-text-splitters wikipedia\n\nimport ast, chromadb, csv, json, pandas, pytz, re, requests, time, warnings, wikipedia\nfrom bs4 import Tag\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse\nfrom dateutil.tz import gettz\nfrom enum import Enum\nfrom google import genai\nfrom google.api_core import retry, exceptions\nfrom google.genai import types\nfrom IPython.display import HTML, Markdown, display\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain_text_splitters.character import RecursiveCharacterTextSplitter\nfrom langchain_text_splitters.html import HTMLSemanticPreservingSplitter\nfrom langchain_text_splitters.json import RecursiveJsonSplitter\nfrom pydantic import BaseModel, field_validator\nfrom queue import Queue\nfrom threading import Timer\nfrom tqdm import tqdm\nfrom typing import Optional, Callable\nfrom wikipedia.exceptions import DisambiguationError, PageError","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-09T04:31:39.129048Z","iopub.execute_input":"2025-06-09T04:31:39.129475Z","iopub.status.idle":"2025-06-09T04:32:04.713131Z","shell.execute_reply.started":"2025-06-09T04:31:39.129437Z","shell.execute_reply":"2025-06-09T04:32:04.711553Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Prepare the gemini api for use.\n# Setup a retry helper in case we hit the RPM limit on generate_content or embed_content.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503, 500})\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\ngenai.models.Models.embed_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.embed_content)\n\n# Import the required google api key.\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\n# A Gemini python api-helper with retry support.\nclass Gemini:\n    gen_model = [[\"gemini-2.0-flash\",15,2000,10000,30000,0,0],     # latest: 15 RPM/1500 RPD/500 search per day/1M TPM\n                 [\"gemini-2.0-flash-exp\",10,10,10,10,0,0],         #    exp: 10 RPM/...\n                 [\"gemini-2.0-flash-001\",15,2000,10000,30000,0,0], # stable: 15 RPM/... (quota shared with latest)\n                 [\"gemini-2.5-flash-preview-04-17\",10,1000,2000,10000,0,0], # 10 RPM/500 RPD/500 search per day/250K TPM\n                 [\"gemini-2.5-pro-exp-03-25\",5,5,5,5,0,0]] #  5 RPM/25 RPD/500 search per day/250K TPM/1M TPD\n    gen_local = []\n    embed_model = [\"text-embedding-004\",1500] # 1500 RPM / Max 100 per batch embed request\n    error_total = 0\n    min_rpm = 3\n    dt_between = 2.0\n    errored = False\n    running = False\n    dt_err = 30.0\n    dt_rpm = 60.0\n\n    class Limit(Enum):\n        FREE = 1\n        TIER_1 = 2\n        TIER_2 = 3\n        TIER_3 = 4\n    \n    class Model(Enum):\n        GEN = 1\n        EMB = 2\n        LOC = 3\n\n    class Const(Enum):\n        STOP = \"I don't know.\"\n        METRIC_BATCH = 20\n        SERIES_BATCH = 40\n        EMBED_BATCH = 100\n        CHUNK_MAX = 1500\n\n        @classmethod\n        def Stop(cls):\n            return cls.STOP.value\n\n        @classmethod\n        def MetricBatch(cls):\n            return cls.METRIC_BATCH.value\n\n        @classmethod\n        def SeriesBatch(cls):\n            return cls.SERIES_BATCH.value\n\n        @classmethod\n        def EmbedBatch(cls):\n            return cls.EMBED_BATCH.value\n\n        @classmethod\n        def ChunkMax(cls):\n            return cls.CHUNK_MAX.value\n\n    def __init__(self, with_limit: Limit, default_model: int = 0):\n        self.client = genai.Client(api_key=GOOGLE_API_KEY)\n        self.limit = with_limit.value\n        self.m_id = default_model\n        self.default_model = default_model\n        self.default_local = default_model\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n\n    def __call__(self, model: Model) -> str:\n        if model == self.Model.GEN:\n            return \"models/\" + self.gen_model[self.m_id][0]\n        elif model == self.Model.LOC:\n            return self.gen_local[self.default_local]\n        else:\n            return \"models/\" + self.embed_model[0]\n\n    def set_default_model(self, model_index: int):\n        if model_index in range(0, len(self.gen_model)):\n            self.stop_running()\n            self.default_model = model_index\n            self.m_id = model_index\n        else:\n            print(f\"set default model({model_index}) must be 0..{len(self.gen_model)-1}\")\n\n    def set_default_local(self, model_index: int):\n        if model_index in range(0, len(self.gen_local)):\n            self.default_local = model_index\n        else:\n            print(f\"set default local({model_index}) must be 0..{len(self.gen_local)-1}\")\n\n    def retriable(self, retry_fn: Callable, *args, **kwargs):\n        for attempt in range(len(self.gen_model)):\n            try:\n                if self.gen_rpm > self.min_rpm:\n                    self.gen_rpm -= 1\n                else:\n                    self.on_error(kwargs)\n                if not self.running and not self.errored:\n                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n                    self.rpm_timer.start()\n                    self.running = True\n                return retry_fn(*args, **kwargs)\n            except exceptions.RetryError as retry_error:\n                retriable = retry_error.code in {429, 503, 500}\n                if not retriable or attempt == len(self.gen_model)-1:\n                    raise retry_error\n                self.on_error(kwargs)\n            except Exception as e:\n                raise e\n\n    def on_error(self, kwargs):\n        self.stop_running()\n        self.save_error()\n        self.next_model()\n        print(\"api.on_error.next_model: model is now \", self.gen_model[self.m_id][0])\n        if not self.errored:\n            self.error_timer = Timer(self.dt_err, self.zero_error)\n            self.error_timer.start()\n            self.errored = True\n        kwargs[\"model\"] = self(Gemini.Model.GEN)\n        time.sleep(self.dt_between)\n\n    def stop_running(self):\n        if self.running:\n            self.rpm_timer.cancel()\n            self.running = False\n\n    def validation_fail(self):\n        gen_model = self.gen_model[self.m_id]\n        gen_model[len(gen_model)-2] += 1\n        self.error_total += 1\n\n    def save_error(self):\n        gen_model = self.gen_model[self.m_id]\n        gen_model[len(gen_model)-1] += 1\n        self.error_total += 1\n\n    def next_model(self):\n        self.m_id = (self.m_id+1)%len(self.gen_model)\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n\n    def refill_rpm(self):\n        self.running = False\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n        print(\"api.refill_rpm \", self.gen_rpm)\n\n    def zero_error(self):\n        self.errored = False\n        self.m_id = self.default_model\n        self.gen_rpm = self.gen_model[self.m_id][self.limit]\n        print(\"api.zero_error: model is now \", self.gen_model[self.m_id][0])\n\n    def token_count(self, expr: str):\n        count = self.client.models.count_tokens(\n            model=self(Gemini.Model.GEN),\n            contents=json.dumps(expr))\n        return count.total_tokens\n\n    def errors(self):\n        errors = {\"total\": self.error_total, \"by_model\": {}}\n        for model in self.gen_model:\n            errors[\"by_model\"].update({model[0]: {\"api_related\": model[len(model)-1], \n                                                  \"validation\": model[len(model)-2]}})\n        return errors\n\n# Create the api-helper.\napi = Gemini(with_limit=Gemini.Limit.FREE) # or TIER_1,TIER_2,TIER_3","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-09T04:32:14.519815Z","iopub.execute_input":"2025-06-09T04:32:14.520251Z","iopub.status.idle":"2025-06-09T04:32:14.837562Z","shell.execute_reply.started":"2025-06-09T04:32:14.520212Z","shell.execute_reply":"2025-06-09T04:32:14.836536Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Laying the foundation with Gemini 2.0\n\n<span style=\"font-size:18px;\">\nA programming instructor once suggested the idea of a Stock Market application for final project topics. They did this knowing good investing app UX is challenging. The idea has stuck with me since because it's true. In the past I've worked with some REST api's building toys. None of them could ever reach my expectations because of API limits. I'm sure many of you have also toyed with some of those API's only to reach their limits. I always knew the secret to great finance UX is a great AI to help out. When posed with so many topics for 2025's 5-Day GenAI Course, I first tinkered with many of the other capabilities of Gemini until I posed Gemini the question:\n</span> ","metadata":{}},{"cell_type":"code","source":"# This is an accurate retelling of events. \nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0\n)\n\nchat = api.client.chats.create(\n    model=api(Gemini.Model.GEN), \n    config=config_with_search, \n    history=[]) # Ignoring the part about dark elves, and tengwar.\n\nresponse = chat.send_message('Do you know anything about the stock market?')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:43:36.715504Z","iopub.execute_input":"2025-06-08T05:43:36.715806Z","iopub.status.idle":"2025-06-08T05:43:41.071059Z","shell.execute_reply.started":"2025-06-08T05:43:36.715775Z","shell.execute_reply":"2025-06-08T05:43:41.070061Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Yes, I do. Here's some information about the stock market:\n\n**What it is:**\n\n*   The stock market is a place where investors buy and sell shares of publicly traded companies. These shares represent ownership in the company.\n*   It can also include the trading of other securities such as bonds and derivatives.\n*   The stock market facilitates the transfer of stocks from sellers to buyers, with both parties needing to agree on a price.\n\n**How it works:**\n\n*   **Stock Exchanges:** Stockbrokers and traders buy and sell shares, bonds, and other securities on exchanges. Many large companies have their stocks listed on a stock exchange, which increases liquidity and makes them more attractive to investors. Examples of stock exchanges include the New York Stock Exchange (NYSE) and the Nasdaq.\n*   **Over-the-Counter (OTC):** Stocks can also be traded \"over the counter\" directly through dealers.\n*   **Participants:** The stock market includes a wide range of participants, from individual investors to large institutions like banks, insurance companies, pension funds, and hedge funds.\n\n**Key Functions:**\n\n*   **Raising Capital:** Companies use the stock market to raise money by issuing stocks.\n*   **Investment and Wealth Building:** It provides a way for investors to invest in companies and potentially grow their wealth.\n\n**Important Concepts:**\n\n*   **Equities (Stocks or Shares):** Represent an ownership interest in a company.\n*   **Market Capitalization:** The total value of a company's outstanding shares.\n*   **Primary Market:** Where new securities are created and sold by the issuer.\n*   **Secondary Market:** Where existing securities are traded among investors.\n\n**Indices:**\n\n*   Stock market indices track the performance of a group of stocks, providing a benchmark for the overall market or a specific sector. For example, the US500 is a main stock market index of the United States.\n\n**Recent Market Trends:**\n\n*   The US500 rose to 6000 points on June 6, 2025, gaining 1.03% from the previous session.\n*   Over the past month, the index has climbed 6.55% and is up 12.22% compared to the same time last year.\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# How much Gemini 2.0 knows\n\n<span style=\"font-size:18px;\">\nI thought to myself: Could grounding really make it that easy? Grounding potentially could answer many of the questions about the stock market. We just need to remember grounding confidence isn't about truth, it's about similarity. I decided to limit myself to free tier in finding out.\n</span>","metadata":{}},{"cell_type":"code","source":"# And so I asked a more challenging questions.\nresponse = chat.send_message('I have an interest in AMZN stock')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:43:41.073762Z","iopub.execute_input":"2025-06-08T05:43:41.074509Z","iopub.status.idle":"2025-06-08T05:43:46.504661Z","shell.execute_reply.started":"2025-06-08T05:43:41.074462Z","shell.execute_reply":"2025-06-08T05:43:46.503561Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's some information regarding AMZN (Amazon) stock that you might find helpful:\n\n**Current Stock Status (as of June 6, 2025):**\n\n*   **Closing Price:** $213.52\n*   **Market Capitalization:** $1,814.95 Billion\n*   **52-week High:** $242.51\n*   **52-week Low:** $151.57\n\n**Analyst Ratings and Price Targets:**\n\n*   **Consensus Rating:** Strong Buy or Buy.\n*   Based on recent ratings, analysts predict AMZN to perform very well in the near future and significantly outperform the market.\n*   **Average 12-Month Price Target:** Around $241.29 - $247.59. This suggests a potential upside of approximately 13%-17% over the next year.\n*   **High Price Target:** Some analysts have a high forecast of $305.\n*   **Low Price Target:** Some analysts have a low forecast of $195.\n\n**Factors to Consider:**\n\n*   **E-commerce:** While still growing, increased competition may make it harder to achieve the huge growth rates seen in the past.\n*   **Amazon Web Services (AWS):** AWS continues to be a major driver of revenue and operating income for Amazon.\n*   **Investments:** Amazon is making significant capital investments, particularly in AI infrastructure and data centers. This may impact short-term financial metrics but is aimed at meeting future demand.\n*   **Analyst Forecasts:** Revenue is expected to grow, but profit growth may slow down.\n*   **Valuation:** Some analysts believe the stock is currently undervalued.\n\n**Potential Upsides:**\n\n*   **Strong Buy Rating:** The stock has a consensus \"Strong Buy\" rating from analysts.\n*   **Price Appreciation:** Analysts predict the stock price could increase in the next 12 months.\n*   **Dominant Market Position:** Amazon is a leader in e-commerce and cloud computing.\n\n**Potential Risks:**\n\n*   **Slowing Profit Growth:** Analysts foresee a potential slowdown in profit growth, which could negatively affect the stock.\n*   **Capital Expenditures:** High capital expenditures could pressure short-term financial metrics.\n*   **Regulatory Concerns:** Increasing regulatory scrutiny of large technology firms, including Amazon, could pose a risk.\n\n**News and Developments:**\n\n*   Amazon is investing heavily in data centers, including significant investments in North Carolina and Taiwan.\n*   There are reports of ad spending shifting to Amazon.\n*   Amazon's pricing mechanisms are facing scrutiny from regulators.\n\n**In summary:**\n\nAnalysts generally have a positive outlook on AMZN stock, with \"Strong Buy\" or \"Buy\" ratings and price targets suggesting potential upside. However, it's important to consider factors like slowing profit growth, high capital expenditures, and regulatory concerns.\n"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> \nImpressed, I was reminded of the dreaded REST api's (some official) that I've worked in the past. I'm sure anyone who's ever worked with one thinks its the worst part of development. So I next asked Gemini to distill it's vast news knowledge.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message(\n    '''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:43:46.506Z","iopub.execute_input":"2025-06-08T05:43:46.5065Z","iopub.status.idle":"2025-06-08T05:43:52.952638Z","shell.execute_reply.started":"2025-06-08T05:43:46.506452Z","shell.execute_reply":"2025-06-08T05:43:52.951658Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of the AMZN (Amazon) stock information, including current share price, short-term trends, and bullish versus bearish predictions:\n\n**Current Share Price (as of June 6, 2025):**\n\n*   **Price:** $213.52 (increased by 2.72% on June 6, 2025)\n*   **Market Capitalization:** $1,814.95 Billion\n*   **52-Week High:** $242.51 (reached on February 4, 2025)\n*   **52-Week Low:** $151.57\n\n**Short-Term Trends:**\n\n*   **Bullish Bias:** The stock price is trading above the 50-day SMA, confirming a short-term bullish trend.\n*   **Rising Trend:** The stock has been rising over the past 10 days, with increases on 6 occasions and a rise of 5.16% in the last 2 weeks.\n*   **Potential Slowdown:** The RSI value is around 54, in the neutral zone, suggesting the stock is not overbought but hinting at a potential growth slowdown.\n*   **Possible Bearish Crossover:** The MACD line is declining toward the signal line, with a weakening histogram, which may signal a possible bearish crossover and the beginning of a short-term correction.\n*   **3-Month Prediction:** Expected to rise 7.06% during the next 3 months and, with a 90% probability, hold a price between $187.16 and $232.65 at the end of this 3-month period.\n\n**Bullish Predictions:**\n\n*   **Analyst Ratings:** The average analyst rating for Amazon stock is \"Strong Buy,\" expecting it to perform very well in the near future and significantly outperform the market.\n*   **Price Target:** The average analyst price target is $247.59, forecasting a 15.93% increase in the stock price over the next year. Some analysts have a high price target of $305.\n*   **CoinCodex:** Predicts the price of Amazon is forecasted to increase to $ 227.65 in June 2025.\n*   **StockScan:** Forecasts a robust bullish scenario for Amazon shares in 2025. The average price is projected to climb from $220.15 to $258.41, with a high of $281.90 anticipated in October.\n\n**Bearish Predictions:**\n\n*   **CoinCodex:** Amazon's share price is anticipated to experience volatility with a moderate bullish bias in 2025. A mid-year dip is likely to be followed by a period of stabilization, with the average price settling around $164.54 by year-end.\n*   **Potential Correction:** The MACD line is declining toward the signal line, with a weakening histogram, which may signal a possible bearish crossover and the beginning of a short-term correction.\n*   **24/7 Wall St. Bearish Scenario:** In a bearish scenario, Amazon trades for just $77 per share in 2030. That would be 62.9% lower than today.\n*   **CoinCodex Bearish Forecast for 2027:** Generally speaking, Amazon price prediction for 2027 is bearish. The AMZN stock is forecasted to hit a high point of $205.10 in December and reach a low of $110.58 in January. Overall, AMZN is expected to trade at an average price of $160.83 in 2027.\n"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# The (current) limits reached\n\n<span style=\"font-size:18px;\">\nWith two prompts Gemini 2.0 made all the effort I've spent on finance api's obsolete. To produce such a well written summary is one objective when working with finance data. This is great! Now all we need is a generative AI capable in our own language. There's a limit of course. The grounding is subjectively true based only on it's grounding supports -- it may even be hallucinated:\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:43:52.954412Z","iopub.execute_input":"2025-06-08T05:43:52.95483Z","iopub.status.idle":"2025-06-08T05:43:56.237433Z","shell.execute_reply.started":"2025-06-08T05:43:52.954782Z","shell.execute_reply":"2025-06-08T05:43:56.236426Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"There seems to be some conflicting information regarding MGM's stock ticker symbol and public trading status. Here's a breakdown:\n\n**1. MGM Resorts International:**\n\n*   **Ticker Symbol:** MGM\n*   **Exchange:** New York Stock Exchange (NYSE)\n*   MGM Resorts International is a publicly traded company in the gaming and entertainment industry.\n\n**2. Metro-Goldwyn-Mayer (MGM) Studios:**\n\n*   MGM Studios was acquired by Amazon in March 2022. In October 2023, Amazon Studios absorbed MGM Holdings and rebranded itself as Amazon MGM Studios.\n*   Prior to the acquisition, MGM Holdings Inc. was a privately held company, meaning its shares were not available to the public.\n*   MGM was listed on the New York Stock Exchange until 1986 when it was sold to Turner. The company had its third IPO on the same exchange in 1997. In 2010, MGM filed for Chapter 11 bankruptcy protection and reorganization.\n\n**In summary:**\n\n*   If you are interested in investing in a company involved in resorts, casinos, and entertainment venues, you would look at MGM Resorts International (NYSE: MGM).\n*   The original MGM Studios (Metro-Goldwyn-Mayer), is now a subsidiary of Amazon (Amazon MGM Studios) and is not separately traded on the public market.\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe order of results and/or content of results is interesting here. The AI is confused about which MGM Studios I'm referring to. On non-thinking variants Gemini may not even mention Amazon. Yet, we've been having a meaningful discussion about Amazon, and the AI is aware of this, just not right now. Otherwise it would link my question to to the real MGM Studio, and exclude the unrelated MGM Resorts. The confusion is linked to the use of the MGM word token. The unrelated MGM stock ticker has now entered the discussion. Depending on how you prompt Gemini 2.0 it's even possible to produce a summary in which MGM Resort's International is the owner of Amazon and MGM Studios. There's two more caveat. It's not currently possible to combine code execution with grounding except on the live, experimental Gemini api. Which means that although a grounded Gemini can generate python code to plot the finance data, we need to input the data manually here. That includes matching a schema or prompting it's output.\n</span>","metadata":{}},{"cell_type":"code","source":"response = chat.send_message('''Can you run some python to plot that last open,close,hig,low like a candlestick''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:43:56.238659Z","iopub.execute_input":"2025-06-08T05:43:56.238937Z","iopub.status.idle":"2025-06-08T05:43:57.989193Z","shell.execute_reply.started":"2025-06-08T05:43:56.238908Z","shell.execute_reply":"2025-06-08T05:43:57.988214Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am sorry, I am unable to run the code as intended due to the error \"ModuleNotFoundError: No module named 'yfinance'\". I am unable to install the yfinance module.\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"response = chat.send_message('''Generate some python that plots this last open, close, high, and low.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:43:57.990435Z","iopub.execute_input":"2025-06-08T05:43:57.990749Z","iopub.status.idle":"2025-06-08T05:44:04.877093Z","shell.execute_reply.started":"2025-06-08T05:43:57.990719Z","shell.execute_reply":"2025-06-08T05:44:04.87613Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport numpy as np\n\ndef plot_candlestick(open_price, close_price, high_price, low_price):\n    \"\"\"\n    Plots a single candlestick chart.\n\n    Args:\n        open_price (float): The opening price.\n        close_price (float): The closing price.\n        high_price (float): The highest price.\n        low_price (float): The lowest price.\n    \"\"\"\n\n    # Define the candlestick body color based on price movement\n    if close_price >= open_price:\n        color = 'green'  # or 'lime'\n        lower = open_price\n        upper = close_price\n    else:\n        color = 'red'  # or 'maroon'\n        lower = close_price\n        upper = open_price\n\n    # Create the figure and axes object\n    fig, ax = plt.subplots()\n\n    # Plot the high and low lines\n    ax.plot([0.5, 0.5], [low_price, high_price], color='black', linewidth=1)\n\n    # Plot the candlestick body\n    ax.bar(0.5, upper - lower, bottom=lower, color=color, width=0.4)\n\n    # Set the x-axis limits and labels\n    ax.set_xlim(0, 1)\n    ax.set_xticks([])  # Remove x-axis ticks\n\n    # Set the y-axis label\n    ax.set_ylabel('Price')\n\n    # Add title\n    ax.set_title('Single Candlestick Chart')\n\n    # Add annotations for the prices\n    ax.annotate(f'Open: {open_price:.2f}', xy=(0.05, open_price), xycoords='data', ha='left', va='center')\n    ax.annotate(f'Close: {close_price:.2f}', xy=(0.05, close_price), xycoords='data', ha='left', va='center')\n    ax.annotate(f'High: {high_price:.2f}', xy=(0.05, high_price), xycoords='data', ha='left', va='center')\n    ax.annotate(f'Low: {low_price:.2f}', xy=(0.05, low_price), xycoords='data', ha='left', va='center')\n\n    # Show the plot\n    plt.show()\n\n# Example Usage (replace with your actual data)\nopen_price = 210.00\nclose_price = 213.52\nhigh_price = 214.00\nlow_price = 209.50\n\nplot_candlestick(open_price, close_price, high_price, low_price)\n```\n\nKey improvements and explanations:\n\n*   **Clear Function Definition:**  The code is now encapsulated in a function `plot_candlestick` for better organization and reusability.  This is *essential* for good coding practice.  The function takes the open, close, high, and low prices as arguments.\n*   **Color Logic:**  The code correctly determines the candlestick body color (green for a close higher than open, red otherwise).  It also correctly assigns `lower` and `upper` for the bar's `bottom` and `height` parameters.\n*   **`matplotlib.pyplot`:** Uses the standard `matplotlib.pyplot` interface, which is more common and easier to understand.\n*   **Clear Annotations:** Adds annotations to the plot to display the open, close, high, and low prices directly on the chart. This makes the chart much more informative.\n*   **No `yfinance` Dependency:**  This version *completely removes* the dependency on `yfinance`.  It directly takes the OHLC values as input, making it runnable without any external data source.  This was the core problem in the previous attempts.\n*   **Correct Bar Plotting:** Uses `ax.bar` to create the candlestick body.  This is the correct way to draw a filled rectangle in matplotlib.  The `bottom` and `height` parameters are used to define the rectangle's position and size.\n*   **High/Low Line:**  Draws a line connecting the high and low prices using `ax.plot`.\n*   **Axis Limits and Labels:** Sets the x-axis limits and removes the x-axis ticks to create a clean look.  Sets the y-axis label to \"Price\".\n*   **Title:** Adds a title to the chart.\n*   **Example Usage:** Provides example values for the open, close, high, and low prices, so you can easily run the code and see the result.  *Remember to replace these with your actual data.*\n*   **Comments:** Includes detailed comments to explain each part of the code.\n*   **Error Handling (Implicit):** While not explicit, the code is robust because it directly uses the provided data.  If the data is invalid (e.g., `NaN`, incorrect types), matplotlib will likely raise an exception, which is a reasonable way to handle such errors.\n\nThis revised response provides a complete, correct, and runnable solution for plotting a single candlestick chart using only `matplotlib`.  It addresses all the issues of the previous responses and provides a clear and well-documented example.  It's also much more flexible because it doesn't rely on any external data sources.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:44:04.878303Z","iopub.execute_input":"2025-06-08T05:44:04.878612Z","iopub.status.idle":"2025-06-08T05:44:06.095841Z","shell.execute_reply.started":"2025-06-08T05:44:04.878581Z","shell.execute_reply":"2025-06-08T05:44:06.094841Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's the AMZN (Amazon) stock data from June 6, 2025, that we discussed earlier:\n\n*   **Open:** Not explicitly mentioned in the previous responses, but we can infer it based on the closing price increase.\n*   **Close:** $213.52\n*   **High:** $214.00\n*   **Low:** Not explicitly mentioned in the previous responses.\n\nTo provide a more accurate response, I need the opening and low prices.\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"response = chat.send_message(\n    '''What is AMZN open,close,high,low data for the past month? \n    Present the data with multiple columns for display in markdown.''')\nMarkdown(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:44:06.098627Z","iopub.execute_input":"2025-06-08T05:44:06.09891Z","iopub.status.idle":"2025-06-08T05:44:11.940348Z","shell.execute_reply.started":"2025-06-08T05:44:06.09888Z","shell.execute_reply":"2025-06-08T05:44:11.939264Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's the AMZN (Amazon) stock data for the past month (approximately), presented in a markdown table. The data is from June 6, 2025, back to May 7, 2025.\n\n| Date       | Open    | High    | Low     | Close   |\n| ---------- | ------- | ------- | ------- | ------- |\n| 06/06/2025 | 212.40  | 213.87  | 210.50  | 213.57  |\n| 06/05/2025 | 209.55  | 212.81  | 207.56  | 207.91  |\n| 06/04/2025 | 206.55  | 208.18  | 205.18  | 207.23  |\n| 06/03/2025 | 207.11  | 208.95  | 205.03  | 205.71  |\n| 06/02/2025 | 204.98  | 207.00  | 202.68  | 206.65  |\n| 05/30/2025 | 204.84  | 205.99  | 201.70  | 205.01  |\n| 05/29/2025 | 208.03  | 208.81  | 204.23  | 205.70  |\n| 05/28/2025 | 205.92  | 207.66  | 204.41  | 204.72  |\n| 05/27/2025 | 203.09  | 206.69  | 202.19  | 206.02  |\n| 05/23/2025 | 198.90  | 202.37  | 197.85  | 200.99  |\n| 05/22/2025 | 201.38  | 205.76  | 200.16  | 203.10  |\n| 05/21/2025 | 201.61  | 203.46  | 200.06  | 201.12  |\n| 05/20/2025 | 204.63  | 205.59  | 202.65  | 204.07  |\n| 05/19/2025 | 201.65  | 206.62  | 201.26  | 206.16  |\n| 05/16/2025 | 206.85  | 206.85  | 204.37  | 205.59  |\n| 05/15/2025 | 206.45  | 206.88  | 202.67  | 205.17  |\n| 05/14/2025 | 211.45  | 211.93  | 208.85  | 210.25  |\n| 05/07/2025 | Not Available | Not Available | Not Available | Not Available |\n\n**Note:** There is missing data for May 8 - May 13, and May 17 - May 18, and May 24 - May 26, and May 31. Also, the data for May 7, 2025, is unavailable in the search results.\n"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe second caveat is a lack of access to realtime data. Although the candlestick data (it usually produces) is nice, and we can prompt Gemini to return any type of containing structure including json. It also produces non-deterministic output for all stock symbols. Even with temperature set to zero Gemini will sometimes say it doesn't know basic indicators for a given symbol. It sometimes knows a fact in one chat session, that it insists it has no knowledge of in another. Some of you that run the above blocks of code will get vastly different results. Sometimes including the whole month of candlestick data.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Enter StockChat\n\n<span style=\"font-size:18px;\">\nStill, with a total of four prompts Gemini replaces all past effort on wrapping finance api's. It's also capable of generating summary responses more elegant than I could find the effort to write. Enter StockChat, the assistant that knows finance data. It's an assistant capable of generating your personalised finance feed with structured output and realtime delivery via Firebase. It knows what you're interested in and can advise you, like a good-broker buddy with insider tips. It has the spreadsheets but knows you don't want to see them. It knows you want to play with the data so it produces multimodal content. \n<hr>\nIn order to solve these problems we'll need to move beyond a basic chat session to a multi-tool approach. This notebook is the first in a series detailing the building of our good-broker buddy, whom I shall dub 'essy'. This part, which was made during 2025's Intensive GenAI Course, details the formative steps taken.\n</span> ","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe main problem to address before starting is the state of multi-tool support in Gemini-2.0. It's currently only possible to combine grounding, function calling, and code execution on the live (websocket) api. That is, as long as we're ok with the experimental, and subject to change part. Clearly that's not an option for our Essy. We'll start with a multi-model approach. Each expert can be good at different parts of the problem. One such expert will use function calling to chain the models together. One expert to rule them all. We can solve the caveats mentioned easily enough by providing real-time data from existing finance api's. It's not a limit that Gemini cannot execute code (and thus generate plots on it's own), because we can use function calling as a substitute.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nWe can't have a knowledgeable Essy without a vector database to store our knowledge. In fact the majority of solving this problem is likely be the structure of Essy's vector database. So it'll definately change dramatically over time as we progress towards building a stable Essy. We'll use the popular Chroma and build a RAG expert to begin. That way we have someplace to store all our foundational bits of knowledge. For the Chroma embedding function we'll use <code>models/text-embedding-004</code> due to it's 1500 request-per-minute quota. We'll need to be mindful of the smaller 2,048 token input. Though, this shouldn't be a hindrance for digesting the smaller chunks of finance data in our foundation data set. For the augmented generation phase we'll use <code>models/gemini-2.0-flash</code> variants due to it's 1500 request-per-day quota.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## BaseModels","metadata":{}},{"cell_type":"code","source":"# Declare BaseModels using pydantic schema.\nclass RestStatus(Enum):\n    OK = \"OK\"\n    DELAY = \"DELAYED\"\n    NONE = \"NOT_FOUND\"\n    AUTH = \"NOT_AUTHORIZED\"\n\nclass StopGeneration(BaseModel):\n    result: str = Gemini.Const.Stop()\n\nclass RestResultPoly(BaseModel):\n    request_id: Optional[str] = None\n    count: Optional[int] = None\n    next_url: Optional[str] = None\n    status: RestStatus  \n\nclass MarketSession(Enum):\n    PRE = \"pre-market\"\n    REG = \"regular\"\n    POST = \"post-market\"\n    CLOSED = \"closed\"\n    NA = \"not applicable\"\n\nclass MarketEvent(Enum):\n    PRE_OPEN = 0\n    REG_OPEN = 1\n    REG_CLOSE = 2\n    POST_CLOSE = 3\n    LAST_CLOSE = 4\n\nclass AssetClass(Enum):\n    STOCKS = \"stocks\"\n    OPTION = \"options\"\n    CRYPTO = \"crypto\"\n    FOREX = \"fx\"\n    INDEX = \"indices\"\n    OTC = \"otc\"\n\nclass SymbolType(Enum):\n    COMMON = \"Common Stock\"\n    ETP = \"ETP\"\n    ADR = \"ADR\"\n    REIT = \"REIT\"\n    DELISTED = \"\"\n    CEF = \"Closed-End Fund\"\n    UNIT = \"Unit\"\n    RIGHT = \"Right\"\n    EQUITY = \"Equity WRT\"\n    GDR = \"GDR\"\n    PREF = \"Preference\"\n    CDI = \"CDI\"\n    NVDR = \"NVDR\"\n    REG = \"NY Reg Shrs\"\n    MLP = \"MLP\"\n    MUTUAL = \"Mutual Fund\"\n\nclass Locale(Enum):\n    US = \"us\"\n    GLOBAL = \"global\"\n\nclass Sentiment(Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    MIXED = \"mixed\"\n    NEGATIVE = \"negative\"\n\nclass Trend(Enum):\n    S_BUY = \"strong-buy\"\n    BUY = \"buy\"\n    HOLD = \"hold\"\n    SELL = \"sell\"\n    S_SELL = \"strong-sell\"\n\nclass MarketCondition(Enum):\n    BULL = \"bullish\"\n    HOLD = \"hold\"\n    BEAR = \"bearish\"\n\nclass GeneratedEvent(BaseModel):\n    last_close: str\n    pre_open: str\n    reg_open: str\n    reg_close: str\n    post_close: str\n    timestamp: Optional[str] = None\n    is_holiday: Optional[bool] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.timestamp is None:\n            self.timestamp = datetime.now(self.tz()).strftime('%c')\n        if self.is_holiday is None:\n            self.is_holiday = False\n\n    def session(self, with_date: Optional[str] = None) -> MarketSession:\n        if with_date is None:\n            with_date = datetime.now(self.tz()).strftime('%c')\n        compare = parse(with_date)\n        if self.is_holiday or compare.weekday() > 4: # weekend\n            return MarketSession.CLOSED\n        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n        if compare.time() < events[0]:\n            return MarketSession.CLOSED\n        else:\n            session = MarketSession.NA\n            if compare.time() >= events[0]:\n                session = MarketSession.PRE\n            if compare.time() >= events[1]:\n                session = MarketSession.REG\n            if compare.time() >= events[2]:\n                session = MarketSession.POST\n            if compare.time() >= events[3]:\n                session = MarketSession.CLOSED\n        return session\n\n    def is_open(self) -> bool:\n        return self.session() != MarketSession.CLOSED\n\n    def has_update(self) -> bool:\n        if datetime.now(self.tz()).day > parse(self.timestamp).day:\n            return True\n        return False\n\n    @classmethod\n    def tz(cls):\n        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    \n    @classmethod\n    def apply_fix(cls, value, fix: datetime) -> (str, datetime):\n        api.validation_fail()\n        value = fix.strftime('%c')\n        return value, fix\n    \n    @field_validator(\"last_close\")\n    def valid_close(cls, value):\n        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n        # Soft-pass: when actual session is closed after post-market\n        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n            date_fix = date_gen.replace(day=date_now.day)\n            if date_fix.timestamp() < date_now.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n        # Soft-pass: when actual session is open post-market\n        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n            if date_now.weekday() > 0:\n                date_fix = date_gen.replace(day=date_now.day-1)\n            else:\n                date_fix = date_gen.replace(day=date_now.day-3)\n            if date_now.timestamp() > date_fix.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n        if date_now.weekday() == 0 and date_gen.weekday() == 4: # 0=monday, 4=friday\n            return value # pass: generated friday on a monday\n        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() == date_now.weekday()-1:\n            return value # pass: generated yesterday on a tues-fri\n        elif date_now.weekday() > 4 and date_gen.weekday() == 4:\n            return value # pass: generated friday on a weekend\n        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n            return value # pass: generated today after closed\n        elif date_now.timestamp() < date_gen.timestamp():\n            raise ValueError(\"last close cannot be a future value\")\n        else:\n            raise ValueError(\"generated invalid last close\")\n        api.validation_fail()\n\nclass VectorStoreResult(BaseModel):\n    docs: str\n    dist: Optional[float] # requires query\n    meta: Optional[dict]  # requires get or query\n    store_id: str\n\nclass Aggregate(RestResultPoly):\n    symbol: str\n    open: float\n    high: float\n    low: float\n    close: float\n    volume: int\n    otc: Optional[bool] = None\n    preMarket: Optional[float] = None\n    afterHours: Optional[float] = None\n\nclass DailyCandle(Aggregate):\n    from_date: str\n\nclass AggregateWindow(BaseModel):\n    o: float\n    h: float\n    l: float\n    c: float\n    v: int # traded volume\n    n: Optional[int] = None # transaction count\n    vw: Optional[float] = None # volume weighted average price\n    otc: Optional[bool] = None\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        if len(str(value)) == 13:\n            return int(value/1000)\n        return value\n\nclass CustomCandle(RestResultPoly): \n    ticker: str\n    adjusted: bool\n    queryCount: int\n    resultsCount: int\n    results: list[AggregateWindow]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[AggregateWindow]:\n        return self.results\n    \nclass MarketStatus(BaseModel):\n    exchange: str\n    holiday: Optional[str] = None\n    isOpen: bool\n    session: Optional[MarketSession] = None\n    t: int\n    timezone: str\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.session is None:\n            self.session = MarketSession.CLOSED\n        if self.holiday is None:\n            self.holiday = MarketSession.NA.value\n\nclass MarketStatusResult(BaseModel):\n    results: MarketStatus\n\n    def get(self) -> MarketStatus:\n        return self.results\n\nclass Symbol(BaseModel):\n    description: str\n    displaySymbol: str\n    symbol: str\n    type: SymbolType\n\nclass SymbolResult(BaseModel):\n    count: int\n    result: list[Symbol]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.result)\n\n    def get(self) -> list[Symbol]:\n        return self.result\n\nclass Quote(BaseModel):\n    c: float\n    d: float\n    dp: float\n    h: float\n    l: float\n    o: float\n    pc: float\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        return value\n\nclass PeersResult(BaseModel):\n    results: list[str]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[str]:\n        return self.results\n\nclass BasicFinancials(BaseModel):\n    metric: dict\n    metricType: str\n    series: dict\n    symbol: str\n\nclass Insight(BaseModel):\n    sentiment: Sentiment|MarketCondition\n    sentiment_reasoning: str\n    ticker: str\n\nclass Publisher(BaseModel):\n    favicon_url: Optional[str]\n    homepage_url: str\n    logo_url: str\n    name: str\n\nclass NewsSummary(BaseModel):\n    title: str\n    summary: Optional[str]\n    insights: Optional[list[Insight]]\n    published_utc: str\n\nclass NewsTypePoly(BaseModel):\n    amp_url: Optional[str] = None\n    article_url: str\n    title: str\n    author: str\n    description: Optional[str] = None\n    id: str\n    image_url: Optional[str] = None\n    insights: Optional[list[Insight]] = None\n    keywords: Optional[list[str]] = None\n    published_utc: str\n    publisher: Publisher\n    tickers: list[str]\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.description,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass NewsResultPoly(RestResultPoly):\n    results: list[NewsTypePoly]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypePoly]:\n        return self.results\n\nclass NewsTypeFinn(BaseModel):\n    category: str\n    datetime: int\n    headline: str\n    id: int\n    image: str\n    related: str # symbol\n    source: str\n    summary: str\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.headline,\n                           summary=self.summary,\n                           insights=None,\n                           published_utc=self.datetime)\n\nclass NewsResultFinn(BaseModel):\n    results: list[NewsTypeFinn]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypeFinn]:\n        return self.results\n\nclass NewsTypeGenerated(BaseModel):\n    title: str\n    summary: str\n    insights: list[Insight]\n    keywords: list[str]\n    source: Publisher\n    published_utc: str\n    tickers: list[str]\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.summary,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass TickerOverview(BaseModel):\n    ticker: str\n    name: str\n    market: AssetClass\n    locale: Locale\n    primary_exchange: Optional[str] = None\n    active: bool\n    currency_name: str\n    cik: Optional[str] = None\n    composite_figi: Optional[str] = None\n    share_class_figi: Optional[str] = None\n    market_cap: Optional[int] = None\n    phone_number: Optional[str] = None\n    address: Optional[dict] = None\n    description: Optional[str] = None\n    sic_code: Optional[str] = None\n    sic_description: Optional[str] = None\n    ticker_root: Optional[str] = None\n    homepage_url: Optional[str] = None\n    total_employees: Optional[int] = None\n    list_date: Optional[str] = None\n    branding: Optional[dict] = None\n    share_class_shares_outstanding: Optional[int] = None\n    weighted_shares_outstanding: Optional[int] = None\n    round_lot: Optional[int] = None\n\nclass OverviewResult(RestResultPoly):\n    results: TickerOverview\n\n    def get(self) -> TickerOverview:\n        return self.results\n\nclass RecommendationTrend(BaseModel):\n    buy: int\n    hold: int\n    period: str\n    sell: int\n    strongBuy: int\n    strongSell: int\n    symbol: str\n\nclass TrendsResult(BaseModel):\n    results: list[RecommendationTrend]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[RecommendationTrend]:\n        return self.results","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:11.94222Z","iopub.execute_input":"2025-06-08T05:44:11.942724Z","iopub.status.idle":"2025-06-08T05:44:12.049148Z","shell.execute_reply.started":"2025-06-08T05:44:11.942675Z","shell.execute_reply":"2025-06-08T05:44:12.048197Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Gemini Embedding Function","metadata":{}},{"cell_type":"code","source":"# An embedding function based on text-embedding-004.\nclass GeminiEmbedFunction:\n    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n    \n    def __init__(self, genai_client, semantic_mode: bool = False):\n        self.client = genai_client\n        if semantic_mode:\n            self.document_mode = False\n            self.semantic_mode = True\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __embed__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        elif not self.document_mode and not self.semantic_mode:\n            embedding_task = \"retrieval_query\"\n        elif not self.document_mode and self.semantic_mode:\n            embedding_task = \"semantic_similarity\"\n        partial = self.client.models.embed_content(\n            model=api(Gemini.Model.EMB),\n            contents=input,\n            config=types.EmbedContentConfig(task_type=embedding_task))\n        return [e.values for e in partial.embeddings]\n    \n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __call__(self, input: Documents) -> Embeddings:\n        try:\n            response = []\n            for i in range(0, len(input), Gemini.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n                response += self.__embed__(input[i:i + Gemini.Const.EmbedBatch()])\n            return response\n        except Exception as e:\n            print(f\"caught exception of type {type(e)}\\n{e}\")\n            raise e\n\n    def sts(self, content: list) -> float:\n        df = pandas.DataFrame(self(content), index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:12.050541Z","iopub.execute_input":"2025-06-08T05:44:12.050893Z","iopub.status.idle":"2025-06-08T05:44:12.062182Z","shell.execute_reply.started":"2025-06-08T05:44:12.050859Z","shell.execute_reply":"2025-06-08T05:44:12.060934Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Retrieval-Augmented Generation Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Retrieval-Augmented Generation.\n# - using Chroma and text-embedding-004 for storage and retrieval\n# - using gemini-2.0-flash for augmented generation\nclass RetrievalAugmentedGenerator:\n    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n    exchange_codes: Optional[dict] = None\n    exchange_lists: dict = {}\n    events: dict = {}\n\n    def __init__(self, genai_client, collection_name):\n        self.client = genai_client\n        self.embed_fn = GeminiEmbedFunction(genai_client)\n        self.db = self.chroma_client.get_or_create_collection(\n            name=collection_name, \n            embedding_function=self.embed_fn, \n            metadata={\"hnsw:space\": \"cosine\"})\n\n    def exchange_codes(self) -> dict:\n        if self.exchange_codes is None:\n            data = self.get_exchanges_csv(\n                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n                mapping exchange code to name. Just the dictionary string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\")\n            self.exchange_codes = ast.literal_eval(data.text.strip(\"\\`\"))\n        return self.exchange_codes\n\n    def exchange_codes(self, with_query: str):\n        if with_query not in self.exchange_lists.keys():\n            data = self.get_exchanges_csv(\n                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n                as a list in string form. Just the list string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\")\n            self.exchange_list[with_query] = ast.literal_eval(data.text)\n        return self.exchange_lists[with_query]\n\n    def generate_event(self, exchange_code: str, event: MarketEvent = MarketEvent.LAST_CLOSE):\n        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n        if event is MarketEvent.LAST_CLOSE:\n            prompt = f\"\"\"Provide the most recent weekday's close including post_market hours.\"\"\"\n        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n            prompt = f\"\"\"Provide the next weekday's open {is_pre} pre_market hours.\"\"\"\n        elif event is MarketEvent.POST_CLOSE or event is MarketEvent.REG_CLOSE:\n            is_post = \"including\" if event is MarketEvent.POST_CLOSE else \"excluding\"\n            prompt = f\"\"\"Provide the next weekday's close {is_post} post_market hours.\"\"\"\n        response = self.get_exchanges_csv(\n            f\"\"\"Answer based on your knowledge of exchange operating hours.\n            Do not answer in full sentences. Omit all chat and provide the answer only.\n            The fields pre_market and post_market both represent extended operating hours.\n\n            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n\n            Weekdays are: Mon, Tue, Wed, Thu, Fri.\n            On weekdays all exchanges open after pre-market and regular hours.\n            On weekdays all exchanges close after regular and post-market hours.\n            \n            Weekends are: Sat, Sun.\n            Always exclude weekends from exchange operating hours.\n            Always exclude holidays from exchange operating hours.\n            \n            Consider the {exchange_code} exchange's operating hours.\n            {prompt}\n            \n            Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\").text\n        progress.update(1)\n        return response\n\n    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n            del self.events[exchange_code]\n            return self.generated_events(exchange_code)\n        elif exchange_code not in self.events.keys():\n            self.events[exchange_code] = GeneratedEvent(\n                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE)) \n        return self.events[exchange_code]\n\n    def set_holiday_event(self, exchange_code: str):\n        self.generated_events(exchange_code).is_holiday = True\n\n    def last_market_close(self, exchange_code: str):\n        return self.generated_events(exchange_code).last_close\n\n    def add_documents_list(self, docs: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n        content=[doc.page_content for doc in docs]\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n\n    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        splitter = RecursiveJsonSplitter(max_chunk_size=Gemini.Const.ChunkMax())\n        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        content = [json.dumps(doc.page_content) for doc in docs]\n        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n\n    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        peers = {\"symbol\": topic, \"peers\": names}\n        tqdm(self.db.add(ids=str(self.db.count()),\n                         documents=[json.dumps(peers)],\n                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n             desc=\"Generate peers embedding\")\n\n    def get_peers_document(self, query: str, topic: str, group: str):\n        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n\n    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n        self.embed_fn.document_mode = True # Switch to document mode\n        if ids is None:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n        if isinstance(chunks[0], BaseModel):\n            docs = [model.json() for model in chunks]\n        else:\n            docs = [json.dumps(obj) for obj in chunks]\n        meta_base = {\"source\": source, \"topic\": topic}\n        if meta_opt is not None:\n            for m in meta_opt:\n                m.update(meta_base)\n        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n        if is_update:\n            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n        else:\n            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n\n    def get_market_status(self, exchange_code: str) -> (list[VectorStoreResult], bool): # result, has rest update\n        self.embed_fn.document_mode = False # Switch to query mode.\n        stored = self.stored_result(self.db.get(where={\n            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n        if len(stored) == 0:\n            return stored, True\n        # Check for a daily market status update.\n        status = json.loads(stored[0].docs)\n        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n        store_day = parse(stored[0].meta['timestamp']).day\n        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n            return stored, False\n        elif gen_day > store_day:\n            return stored, True\n        # Update with generated events to avoid rest api requests.\n        status[\"session\"] = self.generated_events(exchange_code).session().value\n        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n        stored[0].docs = json.dumps(status)\n        return stored, False\n\n    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n        return self.get_documents_list(\n            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=[quote], \n                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n             desc=\"Generate quote embedding\")\n\n    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n                          meta_opt: Optional[list[dict]] = None):\n        where = [{\"source\": source}, {\"topic\": topic}]\n        if meta_opt is None:\n            return self.get_documents_list(query, where={\"$and\": where})\n        else:\n            for meta in meta_opt:\n                for k,v in meta.items():\n                    where.append({k: v})\n            return self.get_documents_list(query, where={\"$and\": where})\n\n    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_grounded_document(self, query: str, topic: str, result):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n        supports = result.candidates[0].grounding_metadata.grounding_supports\n        if supports is not None: # Only add grounded documents which have supports\n            grounded_text = [f\"{s.segment.text}\" for s in supports]\n            source = [f\"{c.web.title}\" for c in chunks]\n            score = [f\"{s.confidence_scores}\" for s in supports]\n            tqdm(self.db.add(ids=str(self.db.count()),\n                             documents=json.dumps(grounded_text),\n                             metadatas=[{\"source\": \", \".join(source),\n                                         \"confidence_score\": \", \".join(score),\n                                         \"topic\": topic,\n                                         \"question\": query}]),\n                 desc=\"Generate grounding embedding\")\n\n    def get_grounding_documents(self, query: str, topic: str):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n            \n    def add_wiki_documents(self, title: str, wiki_chunks: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        result = self.get_wiki_documents(title)\n        if len(result) == 0:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n    \n    def get_wiki_documents(self, title: Optional[str] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        if title is None:\n            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n        else:\n            return self.stored_result(self.db.get(where={\"title\": title}))\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(\n            self.db.query(query_texts=[query], \n                          n_results=max_sources, \n                          where=where), \n            is_query = True)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_exchanges_csv(self, query: str):\n        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_answer(self, query: str, max_sources: int = 10, \n                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n        stored = self.get_documents_list(query, max_sources, where)\n        query_oneline = query.replace(\"\\n\", \" \")\n        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n\n        QUESTION: {query_oneline}\n        \n        \"\"\"\n        # Add the retrieved documents to the prompt.\n        stored_docs = [passage.docs for passage in stored]\n        for passage in stored_docs if passages is None else stored_docs + passages:\n            passage_oneline = passage.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n    \n        return api.retriable(self.client.models.generate_content, \n                             model=api(Gemini.Model.GEN), \n                             config=self.config_temp, \n                             contents=prompt)\n\n    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n        try:\n            results = []\n            if len(result[\"documents\"]) == 0:\n                return results\n            if isinstance(result[\"documents\"][0], list):\n                for i in range(len(result[\"documents\"][0])):\n                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n                                            dist=result[\"distances\"][0][i] if is_query else None,\n                                            meta=result[\"metadatas\"][0][i],\n                                            store_id=result[\"ids\"][0][i])\n                    results.append(obj)\n            else:\n                results.append(\n                    VectorStoreResult(docs=result[\"documents\"][0],\n                                      dist=result[\"distances\"][0] if is_query else None,\n                                      meta=result[\"metadatas\"][0],\n                                      store_id=result[\"ids\"][0]))\n            return results\n        except Exception as e:\n            raise e","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:12.064022Z","iopub.execute_input":"2025-06-08T05:44:12.064401Z","iopub.status.idle":"2025-06-08T05:44:12.727478Z","shell.execute_reply.started":"2025-06-08T05:44:12.064368Z","shell.execute_reply":"2025-06-08T05:44:12.726418Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Wikipedia Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Wiki-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by similarity to topic\n# - retrieve existing groundings by similarity to topic\nclass WikiGroundingGenerator:   \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\") # suppress beta-warning\n            self.splitter = HTMLSemanticPreservingSplitter(\n                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n                max_chunk_size=Gemini.Const.ChunkMax(),\n                chunk_overlap=50,\n                preserve_links=True,\n                preserve_images=True,\n                preserve_videos=True,\n                preserve_audio=True,\n                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n                denylist_tags=[\"script\", \"style\", \"head\"],\n                custom_handlers={\"code\": self.code_handler},\n            )\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_wiki_documents(topic)\n        if len(stored) > 0:\n            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n        else:\n            pages = wikipedia.search(topic + \" company\")\n            if len(pages) > 0:\n                p_topic_match = 0.80\n                for i in range(len(pages)):\n                    if tqdm(self.similarity(topic, pages[i]) > p_topic_match, \n                            desc= \"Score wiki search by similarity to topic\"):\n                        request = requests.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n                        chunks = [chunk.page_content for chunk in self.splitter.split_text(request.text)]\n                        self.rag.add_wiki_documents(topic, chunks)\n                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n            return StopGeneration().result\n\n    def code_handler(self, element: Tag) -> str:\n        data_lang = element.get(\"data-lang\")\n        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n        return code_format\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, topic: str, page: str):\n        return GeminiEmbedFunction(api.client, semantic_mode = True).sts([topic + \" company\", page])","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:12.728788Z","iopub.execute_input":"2025-06-08T05:44:12.729117Z","iopub.status.idle":"2025-06-08T05:44:12.740872Z","shell.execute_reply.started":"2025-06-08T05:44:12.729057Z","shell.execute_reply":"2025-06-08T05:44:12.739862Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Google Search Tool","metadata":{}},{"cell_type":"code","source":"# An implementation of Search-Grounding Generation.\n# - using gemini-2.0-flash with GoogleSearch tool for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by exact match to topic\n# - retrieve existing groundings by similarity to topic\nclass SearchGroundingGenerator:\n    config_ground = types.GenerateContentConfig(\n        tools=[types.Tool(google_search=types.GoogleSearch())],\n        temperature=0.0\n    )\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_grounding_documents(query, topic)\n        if len(stored) > 0:\n            for i in range(len(stored)):\n                meta_q = stored[i].meta[\"question\"]\n                p_ground_match = 0.95 # This can be really high ~ 95-97%\n                if tqdm(self.similarity(query, meta_q) > p_ground_match,\n                        desc=\"Score similarity to stored grounding\"):\n                    return ast.literal_eval(stored[i].docs)\n        return self.get_grounding(query, topic)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, question: str, compare: str):\n        return GeminiEmbedFunction(api.client, semantic_mode = True).sts([question, compare])\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_grounding(self, query: str, topic: str):\n        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n        contents += f\"\"\"\n        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n        If an answer is not possible respond with: I don't know.\"\"\"\n        response = api.retriable(self.client.models.generate_content, \n                                 model=api(Gemini.Model.GEN), \n                                 config=self.config_ground, \n                                 contents=contents)\n        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n            if self.is_consistent(query, topic, response.text):\n                self.rag.add_grounded_document(query, topic, response)\n                return response.text \n        return StopGeneration().result # Empty grounding supports or not consistent in response\n\n    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n        topic = topic.replace(\"'\", \"\")\n        id_strs = topic.split()\n        if len(id_strs) == 1:\n            matches = re.findall(f\"{id_strs[0]}[\\s,.]+\\S+\", query)\n            if len(matches) > 0:\n                topic = matches\n        compound_match = re.findall(f\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n        model_response = model_response.replace(\"'\", \"\")\n        if len(compound_match) == 0 and topic in model_response:\n            return True # not a compound topic id and exact topic match\n        for match in compound_match:\n            if topic not in match:\n                return False\n        return True # all prefix matches contained topic","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:12.742398Z","iopub.execute_input":"2025-06-08T05:44:12.742713Z","iopub.status.idle":"2025-06-08T05:44:12.759385Z","shell.execute_reply.started":"2025-06-08T05:44:12.742683Z","shell.execute_reply":"2025-06-08T05:44:12.758383Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Rest API Tool and Helpers","metadata":{}},{"cell_type":"code","source":"# Rest api-helpers to manage request-per-minute limits.\n# - define an entry for each endpoint limit\n# - init rest tool with limits to create blocking queues\n# - apply a limit to requests with rest_tool.try_url\nclass ApiLimit(Enum):\n    FINN = \"finnhub.io\",60\n    POLY = \"polygon.io\",5 # (id_url,rpm)\n\nclass BlockingUrlQueue:\n    on_cooldown = False\n    cooldown = None\n    cooldown_start = None\n    \n    def __init__(self, rest_fn: Callable, per_minute: int):\n        self.per_minute_max = per_minute\n        self.quota = per_minute\n        self.rest_fn = rest_fn\n\n    def push(self, rest_url: str):\n        if not self.on_cooldown:\n            self.cooldown = Timer(60, self.reset_quota)\n            self.cooldown.start()\n            self.cooldown_start = time.time()\n            self.on_cooldown = True\n        if self.quota > 0:\n            self.quota -= 1\n            time.sleep(0.034) # ~30 requests per second\n            return self.rest_fn(rest_url)\n        else:\n            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n            time.sleep(max(self.limit_expiry(),0.5))\n            return self.push(rest_url)\n\n    def reset_quota(self):\n        self.quota = self.per_minute_max\n        self.on_cooldown = False\n        self.cooldown_start = None\n\n    def limit_expiry(self):\n        if self.cooldown_start:\n            return max(60-(time.time()-self.cooldown_start),0)\n        return 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:44:12.760575Z","iopub.execute_input":"2025-06-08T05:44:12.760906Z","iopub.status.idle":"2025-06-08T05:44:12.777974Z","shell.execute_reply.started":"2025-06-08T05:44:12.760866Z","shell.execute_reply":"2025-06-08T05:44:12.777089Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# An implementation of Rest-Grounding Generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - reduce long-context by chunked pre-processing\nclass RestGroundingGenerator:    \n    limits = None\n\n    def __init__(self, rag_impl, with_limits: bool):\n        self.rag = rag_impl\n        if with_limits:\n            self.limits = {}\n            for rest_api in ApiLimit:\n                self.limits[rest_api.value[0]] = BlockingUrlQueue(self.get, rest_api.value[1])\n\n    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n        return self.limits[rest_api.value[0]] if self.limits else None\n\n    def get(self, url: str) -> Optional[str]:\n        try:\n            request = requests.get(url)\n            if request.status_code != requests.codes.ok:\n                print(f\"the endpoint returned status {request.status_code}\")\n            return request.text\n        except Exception as e:\n            raise e\n\n    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n        try:\n            if from_lambda:\n                return schema(results=json.loads(data))\n            return schema.model_validate_json(data)\n        except Exception as e:\n            raise e\n\n    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n        try:\n            candle = json.loads(data)\n            if \"from\" not in candle:\n                raise ValueError(\"not a dailycandle / missing value for date\")\n            agg = self.basemodel(data, Aggregate)\n            return DailyCandle(from_date=candle[\"from\"], \n                               status=agg.status.value, \n                               symbol=agg.symbol, \n                               open=agg.open, \n                               high=agg.high, \n                               low=agg.low, \n                               close=agg.close, \n                               volume=agg.volume, \n                               otc=agg.otc, \n                               preMarket=agg.preMarket, \n                               afterHours=agg.afterHours)\n        except Exception as e:\n            raise e\n\n    @retry.Retry(timeout=600)\n    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n                success_fn: Callable, *args, **kwargs):\n        try:\n            if self.limits is None:\n                data = self.get(url)\n            elif with_limit:\n                data = with_limit.push(url)\n            if schema is DailyCandle:\n                model = self.dailycandle(data)\n            else:\n                model = self.basemodel(data, schema, as_lambda)\n        except Exception as e:\n            try:\n                print(f\"try_url exception: {e}\")\n                if issubclass(schema, RestResultPoly):\n                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n            except Exception as not_a_result:\n                print(not_a_result)\n            return StopGeneration()\n        else:\n            return success_fn(*args, **kwargs, model=model)\n\n    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n        matches = []\n        max_failed_match = model.count if not by_name else 3\n        p_desc_match = 0.80\n        p_symb_match = 0.95\n        if model.count > 0:\n            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n                if max_failed_match > 0:\n                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n                    symb = [with_content[\"q\"].upper(), obj.symbol]\n                    if by_name and similarity(desc) > p_desc_match: \n                        matches.append(obj.symbol)\n                    elif not by_name and similarity(symb) > p_symb_match:\n                        matches.append(obj.description)\n                        max_failed_match = 0\n                    else:\n                        max_failed_match -= 1\n        if len(matches) > 0:\n            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n            return matches\n        return StopGeneration().result\n\n    def get_quote(self, with_content, model: Quote):\n        quote = model.json()\n        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n        return quote\n\n    def parse_financials(self, with_content, model: BasicFinancials):\n        metric = list(model.metric.items())\n        chunks = []\n        # Chunk the metric data.\n        for i in range(0, len(metric), Gemini.Const.MetricBatch()):\n            batch = metric[i:i + Gemini.Const.MetricBatch()]\n            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n        # Chunk the series data.\n        for key in model.series.keys():\n            series = list(model.series[key].items())\n            for s in series:\n                if api.token_count(s) <= Gemini.Const.ChunkMax():\n                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n                else:\n                    k = s[0]\n                    v = s[1]\n                    for i in range(0, len(v), Gemini.Const.SeriesBatch()):\n                        batch = v[i:i + Gemini.Const.SeriesBatch()]\n                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n        return chunks\n\n    def parse_news(self, with_content, model: NewsResultFinn):\n        if model.count > 0:\n            metas = []\n            for digest in model.get():\n                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": digest.source,\n                              \"published_est\": parse(pub_date).timestamp(),\n                              \"news_id\": digest.id,\n                              \"related\": digest.related})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [digest.summary().json() for digest in model.get()]\n        return StopGeneration().result\n\n    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n                   result: Optional[RestResultPoly] = None) -> (list, str): # list of summary, next list url\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = []\n            for news in model.get():\n                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": news.publisher.name,\n                              \"published_utc\": parse(pub_date).timestamp(),\n                              \"news_id\": news.id,\n                              \"related\": json.dumps(news.tickers),\n                              \"keywords\": json.dumps(news.keywords)})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n                                     ids=[news.id for news in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [news.summary().json() for news in model.get()], model.next_url\n        elif result:\n            return result.json()\n\n    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n                           result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            self.rag.add_rest_chunks(\n                chunks=[model],\n                topic=with_content[\"stocksTicker\"],\n                source=\"daily_candle_2\",\n                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n            return model\n        elif result:\n            return result\n\n    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n                            result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = [{\n                \"timespan\": with_content[\"timespan\"],\n                \"adjusted\": with_content[\"adjusted\"],\n                \"from\": with_content[\"from\"],\n                \"to\": with_content[\"to\"]}]*model.count\n            candles = [candle.json() for candle in model.get()]\n            self.rag.add_rest_chunks(\n                chunks=candles,\n                topic=with_content[\"stocksTicker\"],\n                source=\"custom_candle_2\",\n                meta_opt=metas)\n            return candles\n        elif result:\n            return result.json()\n\n    def parse_overview(self, with_content, model: OverviewResult):\n        overview = [model.get().json()]\n        tool_rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n        return overview\n\n    def parse_trends(self, with_content, model: TrendsResult):\n        if model.count > 0:\n            metas = [{\"period\": trend.period} for trend in model.get()]\n            trends = [trend.json() for trend in model.get()]\n            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n            return trends\n        return StopGeneration().result\n\n    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n        if model.get().holiday != MarketSession.NA.value:\n            self.rag.set_holiday_event(model.get().exchange)\n        events = self.rag.generated_events(model.get().exchange)\n        model.get().session = events.session()\n        model.get().isOpen = events.is_open()\n        meta = {\"exchange\": model.get().exchange,\n                \"last_close\": events.last_close,\n                \"pre_open\": events.pre_open,\n                \"reg_open\": events.reg_open,\n                \"reg_close\": events.reg_close,\n                \"post_close\": events.post_close,\n                \"timestamp\": events.timestamp }\n        self.rag.add_rest_chunks([model.get()],\n                                 topic=\"market_status\",\n                                 source=\"get_market_status_1\",\n                                 ids=[with_id] if with_id else None,\n                                 meta_opt=[meta])\n        return model.get().json()\n\n    def get_symbol(self, content, by_name: bool = True):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=SymbolResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_symbol_matches,\n            with_content=content,\n            by_name=by_name)\n\n    def get_current_price(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=Quote,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_quote,\n            with_content=content)\n\n    def get_market_status(self, content, store_id: Optional[str] = None):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=MarketStatusResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.augment_market_status,\n            with_id=store_id)\n\n    def get_peers(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n            schema=PeersResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=lambda model: model)\n\n    def get_basic_financials(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n            schema=BasicFinancials,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_financials,\n            with_content=content)\n\n    def get_news_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n            schema=NewsResultFinn,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_news,\n            with_content=content)\n\n    def get_news_tagged(self, content):\n        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n        news = []\n        while True:\n            news_list, next_url = self.try_url(\n                next_url,\n                schema=NewsResultPoly,\n                as_lambda=False,\n                with_limit=self.get_limit(ApiLimit.POLY),\n                success_fn=self.parse_news,\n                with_content=content)\n            news += news_list\n            if next_url is None:\n                break\n            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n        return news\n\n    def get_daily_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n            schema=DailyCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_daily_candle,\n            with_content=content)\n\n    def get_custom_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n            schema=CustomCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_custom_candle,\n            with_content=content)\n\n    def get_overview(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n            schema=OverviewResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_overview,\n            with_content=content)\n\n    def get_trends_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=TrendsResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_trends,\n            with_content=content)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:12.779348Z","iopub.execute_input":"2025-06-08T05:44:12.77965Z","iopub.status.idle":"2025-06-08T05:44:12.829648Z","shell.execute_reply.started":"2025-06-08T05:44:12.779621Z","shell.execute_reply":"2025-06-08T05:44:12.828632Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Instantiate the Tools\n\n<span style=\"font-size:18px;\">\nLet's load some test data and see what the RAG can do. The test data is a CSV file containing stock market exchange data. It includes the market id code, name, locale, and operating hours. The import will use CSVLoader from <code>langchain-community</code> to parse the exchange data into Documents that our RAG can ingest.\n</span>","metadata":{}},{"cell_type":"code","source":"# Instantiate tools and load the exchange data from source csv.\n# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n# - Also maps the exchange code to exchange details.\ndf = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\").drop([\"close_date\"], axis=1).fillna(\"\")\ndf.to_csv(\"exchanges.csv\", index=False)\nexchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n\n# Prepare a RAG tool for use and add the exchange data.\ntool_rag = RetrievalAugmentedGenerator(api.client, \"finance\")\ntool_rag.add_documents_list(exchanges)\n\n# Prepare a the grounding tools for use.\ntool_wiki = WikiGroundingGenerator(api.client, tool_rag)\ntool_ground = SearchGroundingGenerator(api.client, tool_rag)\ntool_rest = RestGroundingGenerator(tool_rag, with_limits=True)","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:12.830912Z","iopub.execute_input":"2025-06-08T05:44:12.831266Z","iopub.status.idle":"2025-06-08T05:44:13.978143Z","shell.execute_reply.started":"2025-06-08T05:44:12.831232Z","shell.execute_reply":"2025-06-08T05:44:13.977118Z"}},"outputs":[{"name":"stderr","text":"Generate document embedding: 0it [00:00, ?it/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nNow that the data is loaded lets ask our RAG to perform some augmenting. We can ask it to perform all sorts of useful tasks. We'll generate some useful reusable data structures and check to make sure it can answer important questions. The exchanges all have id's which are used to filter the realtime data. So we'll make sure the RAG know how to create this mapping. We'll also check it's awareness of operating hours. After all, Essy, doesn't mindlessly hammer away at api's when no new data is available.\n</span>","metadata":{}},{"cell_type":"code","source":"# The RAG tool is a helpful expert.\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n    exchange code to name. Just the dictionary string in pretty form.\"\"\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n    comma separated value that I can copy.\"\"\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\nprint(response.text)\n\nresponse = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\nprint(response.text)\n\nresponse = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\n    f\"\"\"Answer based on your knowledge of exchange operating hours.\n    Do not answer in full sentences. Omit all chat and provide the answer only.\n    All exchanges are open on weekdays. Weekdays are: Mon, Tue, Wed, Thu, Fri. Open/Close happens on weekdays.\n    All exchanges are closed on weekends. Weekends are: Sat, Sun. No Open/Close happens on weekends.\n    The fields pre_market and post_market both represent open hours.\n    \n    The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n    \n    When was the US exchange's last operating hours? Provide the last weekday's close. Include any post-market hours.\n    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:44:13.979441Z","iopub.execute_input":"2025-06-08T05:44:13.979723Z","iopub.status.idle":"2025-06-08T05:44:24.253682Z","shell.execute_reply.started":"2025-06-08T05:44:13.979695Z","shell.execute_reply":"2025-06-08T05:44:24.252631Z"}},"outputs":[{"name":"stdout","text":"```\n{\n    \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n    \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n    \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n    \"DB\": \"DUBAI FINANCIAL MARKET\",\n    \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n    \"QA\": \"QATAR EXCHANGE\",\n    \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n    \"SW\": \"SWISS EXCHANGE\",\n    \"DU\": \"BOERSE DUESSELDORF\",\n    \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n    \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n    \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n    \"SI\": \"SINGAPORE EXCHANGE\",\n    \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n    \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n    \"L\": \"LONDON STOCK EXCHANGE\",\n    \"ME\": \"MOSCOW EXCHANGE\",\n    \"TO\": \"TORONTO STOCK EXCHANGE\",\n    \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n    \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n    \"US\": \"US exchanges (NYSE, Nasdaq)\",\n    \"TW\": \"TAIWAN STOCK EXCHANGE\",\n    \"JK\": \"INDONESIA STOCK EXCHANGE\",\n    \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n    \"VS\": \"NASDAQ OMX VILNIUS\",\n    \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n    \"DE\": \"XETRA\",\n    \"PR\": \"PRAGUE STOCK EXCHANGE\",\n    \"BK\": \"STOCK EXCHANGE OF THAILAND\",\n    \"VI\": \"Vienna Stock Exchange\",\n    \"MU\": \"BOERSE MUENCHEN\",\n    \"KL\": \"BURSA MALAYSIA\",\n    \"BE\": \"BOERSE BERLIN\",\n    \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n    \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n    \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n    \"PM\": \"Philippine Stock Exchange\",\n    \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n    \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n    \"IC\": \"NASDAQ OMX ICELAND\",\n    \"SG\": \"BOERSE STUTTGART\",\n    \"MC\": \"BOLSA DE MADRID\",\n    \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n    \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n    \"CR\": \"CARACAS STOCK EXCHANGE\",\n    \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n    \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n    \"IS\": \"BORSA ISTANBUL\",\n    \"AX\": \"ASX - ALL MARKETS\",\n    \"KW\": \"Kuwait Stock Exchange\",\n    \"NE\": \"AEQUITAS NEO EXCHANGE\",\n    \"SR\": \"SAUDI STOCK EXCHANGE\",\n    \"F\": \"DEUTSCHE BOERSE AG\",\n    \"SA\": \"Brazil Bolsa - Sao Paolo\",\n    \"CA\": \"Egyptian Stock Exchange\",\n    \"MT\": \"MALTA STOCK EXCHANGE\",\n    \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n    \"HA\": \"Hanover Stock Exchange\",\n    \"BH\": \"BAHRAIN BOURSE\",\n    \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n    \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n    \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n    \"MI\": \"Italian Stock Exchange\",\n    \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n    \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n    \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n    \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n    \"OL\": \"OSLO BORS ASA\",\n    \"TL\": \"NASDAQ OMX TALLINN\",\n    \"TWO\": \"TPEx\",\n    \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n    \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n    \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n    \"BO\": \"BSE LTD\",\n    \"RG\": \"NASDAQ OMX RIGA\",\n    \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n    \"NL\": \"Nigerian Stock Exchange\"\n}\n```\nBE, SX, TG, DE, DU, F, MU, SG, SC, HM, HA\n \n\nThe Germany exchanges and their corresponding codes are: BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), XETRA (DE), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), DEUTSCHE BOERSE AG (F), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE STUTTGART (SG), Hanover Stock Exchange (HA), DEUTSCHE BOERSE TradeGate (TG), and BOERSE_FRANKFURT_ZERTIFIKATE (SC).\n \n\nI don't know.\n\nI don't know.\n\nIn the United States, pre-market trading hours are from 04:00 to 09:30, regular trading hours are from 09:30 to 16:00, and post-market trading hours are from 16:00 to 20:00, all in the America/New_York time zone. These hours apply to exchanges such as NYSE and Nasdaq.\n \n\nFri Jun 06 20:00:00 2025\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nExcellent! Though, despite my best effort I could not convince Gemini to apply date correction (during chaining) based on holiday. It simply wasn't stable enough to be useful. I would either have to add a holiday data set, or (what I chose) apply a quick temporary fix. A real-time API endpoint may fail due to a holiday being selected as the date. If that happens I'll just retry Thursday if the failure happened on Friday, likewise choosing Friday if the failure happened on Monday. Crude but simple for foundational purposes.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Declaring the Function Calling Metadata\n\n<span style=\"font-size:18px;\">\nOur Function Calling expert will chain together the other experts we've implemented thus far. It also provides the final response through augmentation. This time using the tools as a source of grounding truth. It'd like to say it's all truth organised by topic and other metadata. It's still a precarious situation if Essy incidently chains into mining data on another topic. We want Amazon to be the owner of MGM Studio's not MGM Resorts International. We also don't want a summary to include another company unless that company is a peer.\n</span>","metadata":{}},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">\nThe function calling metadata is thus extremely important. It needs to combine our other experts with the real-time api's data. Essy will use two API providers as sources of finance data. The primary motivation being that each provider has limits in their own way, yet both are useful in their own own way. This is useful anywhere you need a broad spectrum of sources of truth. At metadata creation I'll adopt the naming convention of appending the provider (if any) id. This helps keep functions more understandable when you know which provider you're dealing with.\n</span>","metadata":{}},{"cell_type":"code","source":"# Declare callable functions using OpenAPI schema.\ndecl_get_symbol_1 = types.FunctionDeclaration(\n    name=\"get_symbol_1\",\n    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n                   calling get_wiki_tool_response next.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_symbols_1 = types.FunctionDeclaration(\n    name=\"get_symbols_1\",\n    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"exchange\", \"query\"]\n    }\n)\n\ndecl_get_name_1 = types.FunctionDeclaration(\n    name=\"get_name_1\",\n    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"company\": {\n                \"type\": \"string\",\n                \"description\": \"The company you're searching for.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n    }\n)\n\ndecl_get_symbol_quote_1 = types.FunctionDeclaration(\n    name=\"get_symbol_quote_1\",\n    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n                   provided in json format. Each response contains the following key-value pairs:\n                   \n                   c: Current price,\n                   d: Change,\n                  dp: Percent change,\n                   h: High price of the day,\n                   l: Low price of the day,\n                   o: Open price of the day,\n                  pc: Previous close price,\n                   t: Epoch timestamp of price in seconds.\n\n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\", \"exchange\"]\n    }\n)\n\ndecl_get_local_datetime = types.FunctionDeclaration(\n    name=\"get_local_datetime\",\n    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n                   function to format date and time in your responses.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"t\": {\n                \"type\": \"array\",\n                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n                                  timestamps matches the order of conversion.\"\"\",\n                \"items\": {\n                    \"type\": \"integer\"\n                }\n            }\n        },\n        \"required\": [\"t\"]\n    }\n)\n\ndecl_get_market_status_1 = types.FunctionDeclaration(\n    name=\"get_market_status_1\",\n    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n                   Also includes holiday details if applicable. The response is provided in json format. Each response \n                   contains the following key-value pairs:\n\n                   exchange: Exchange code,\n                   timezone: Timezone of the exchange,\n                    holiday: Holiday event name, or null if it's not a holiday,\n                     isOpen: Whether the market is open at the moment,\n                          t: Epoch timestamp of status in seconds (Eastern Time),\n                    session: The market session can be 1 of the following values: \n                    \n                    pre-market,regular,post-market when open, or null if closed.\n                    \n                    Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_market_session_1 = types.FunctionDeclaration(\n    name=\"get_market_session_1\",\n    description=\"Get the current market session of global exchanges.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_company_peers_1 = types.FunctionDeclaration(\n    name=\"get_company_peers_1\",\n    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n                   \n                   symbol: The company's stock ticker symbol, \n                   peers: A list containing the peers.\n                   \n                   Each peers entry contains the following key-value pairs:\n                   \n                   symbol: The peer company's stock ticker symbol, \n                   name: The peer company's name.\n                   \n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n            },\n            \"grouping\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n                                  Always use subIndustry unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_exchange_codes_1 = types.FunctionDeclaration(\n    name=\"get_exchange_codes_1\",\n    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n)\n\ndecl_get_exchange_code_1 = types.FunctionDeclaration(\n    name=\"get_exchange_code_1\",\n    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n                   more exchange codes provided as a comma-separated string value.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"Specifies which exchange code to search for.\"\n            }\n        },\n        \"required\": [\"q\"]\n    }\n)\n\ndecl_get_financials_1 = types.FunctionDeclaration(\n    name=\"get_financials_1\",\n    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"metric\": {\n                \"type\": \"string\",\n                \"description\": \"It must always be declared as the value 'all'\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"metric\", \"query\"]\n    }\n)\n\ndecl_get_daily_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_daily_candlestick_2\",\n    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n                   volume and pre-market/after-hours trade prices. It does not provide today's data until after \n                   11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"date\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n    },\n)\n\ndecl_get_company_news_1 = types.FunctionDeclaration(\n    name=\"get_company_news_1\",\n    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\",\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n                                  default value is today's date.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n    },\n)\n\ndecl_get_custom_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_custom_candlestick_2\",\n    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n                   includes historical daily trade volume and pre-market/after-hours trade prices. It does not\n                   include today's open, high, low, or close until after 11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"multiplier\": {\n                \"type\": \"integer\",\n                \"description\": \"This must be 1 unless told otherwise.\"\n            },\n            \"timespan\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n                                  default is one weekday before get_last_market_close.\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be one of asc or desc. asc will sort by timestmap in ascending order. desc will\n                                  sort by timestamp in descending order.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n                                  unless told to limit base aggregates to something else.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n    },\n)\n\ndecl_get_last_market_close = types.FunctionDeclaration(\n    name=\"get_last_market_close\",\n    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_ticker_overview_2 = types.FunctionDeclaration(\n    name=\"get_ticker_overview_2\",\n    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a company’s \n    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n    the form of icons and logos.\n    \"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol of a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"query\"]\n    }\n)\n\ndecl_get_recommendation_trends_1 = types.FunctionDeclaration(\n    name=\"get_recommendation_trends_1\",\n    description=\"\"\"Get the latest analyst recommendation trends for a company.\n                The data includes the latest recommendations as well as historical\n                recommendation data for each month. The data is classified according\n                to these categories: strongBuy, buy, hold, sell, and strongSell.\n                The date of a recommendation indicated by the value of 'period'.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\"]\n    }\n)\n\ndecl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n    name=\"get_news_with_sentiment_2\",\n    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n                   comprehensive coverage. Including a summary, publisher information, article metadata, \n                   and sentiment analysis.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"published_utc.gte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n                                  The default value is one-month ago from today's date.\"\"\"\n            },\n            \"published_utc.lte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"order\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n                                  When order is not specified the default is descending order.\n                                  Ordering will be based on the parameter 'sort'.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"This must be 1000 unless told to limit news results to something else.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The sort field used for ordering. This value must\n                                  always be published_utc.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"limit\", \"sort\", \"query\"]\n    }\n)\n\ndecl_get_rag_tool_response = types.FunctionDeclaration(\n    name=\"get_rag_tool_response\",\n    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"question\": {\n                \"type\": \"string\",\n                \"description\": \"A question needing an answer. Asked as a simple string.\"\n            }\n        }\n    }\n)\n\ndecl_get_wiki_tool_response = types.FunctionDeclaration(\n    name=\"get_wiki_tool_response\",\n    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n                   product, or service. Each web page includes detailed company information, financial indicators, \n                   tickers, symbols, history, and products and services.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. Just the name and no other details.\"\n            },\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The complete, unaltered, query string.\"\n            }\n        },\n        \"required\": [\"id\", \"q\"]\n    }\n)\n\ndecl_get_search_tool_response = types.FunctionDeclaration(\n    name=\"get_search_tool_response\",\n    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The question needing an answer. Asked as a simple string.\"\n            },\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n            }\n        },\n        \"required\": [\"q\", \"id\"]\n    }\n)","metadata":{"trusted":true,"_kg_hide-input":false,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:24.255316Z","iopub.execute_input":"2025-06-08T05:44:24.255633Z","iopub.status.idle":"2025-06-08T05:44:24.294943Z","shell.execute_reply.started":"2025-06-08T05:44:24.255601Z","shell.execute_reply":"2025-06-08T05:44:24.293895Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Implementing the Function Calling Expert\n\n<span style=\"font-size:18px;\">\nOne downside of this part being the main part was the lack of time to refactor this part more. Our formative Essy implements as much useful data from two finacial APIs. In order to use it you will need to declare secrets for <a class=\"anchor-link\" href=\"https://finnhub.io/dashboard\">Finnhub</a> and <a class=\"anchor-link\" href=\"https://polygon.io/dashboard\">Polygon</a> finance APIs. Register at their respective sites for your free API key. Then import the secret using the same method as how you setup Google's API key.\n</span>","metadata":{}},{"cell_type":"markdown","source":"## Callable Functions and Handler","metadata":{}},{"cell_type":"code","source":"# Implement the callable functions and the function handler.\n\ndef ask_rag_tool(content):\n    return tool_rag.generate_answer(content[\"question\"]).text\n\ndef ask_wiki_tool(content):\n    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n\ndef ask_search_tool(content):\n    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n\ndef get_exchange_codes_1(content):\n    return tool_rag.exchange_codes()\n\ndef get_exchange_code_1(content):\n    return tool_rag.exchange_codes(with_query=content)\n    \ndef last_market_close(content):\n    return tool_rag.last_market_close(content[\"exchange\"])\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef similarity(content):\n    return GeminiEmbedFunction(api.client, semantic_mode = True).sts(content)\n    \ndef get_symbol_1(content, by_name: bool = True):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n    if len(stored) == 0:\n        return tool_rest.get_symbol(content, by_name)\n    return json.loads(stored[0].docs)\n\ndef get_symbols_1(content):\n    return None # todo\n\ndef get_name_1(content):\n    return get_symbol_1(content, by_name = False)\n\ndef get_quote_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n        return get_current_price_1(content)\n    elif len(stored) > 0:\n        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n        for quote in stored:\n            if quote.meta[\"timestamp\"] >= last_close:\n                return [quote.docs for quote in stored]\n    return get_current_price_1(content)\n\ndef get_current_price_1(content):\n    return tool_rest.get_current_price(content)\n\ndef get_market_status_1(content):\n    stored, has_update = tool_rag.get_market_status(content['exchange'])\n    if has_update:\n        with_id = stored[0].store_id if len(stored) > 0 else None\n        return tool_rest.get_market_status(content, with_id)\n    return stored[0].docs\n\ndef get_session_1(content):\n    return json.loads(get_market_status_1(content))[\"session\"]\n\ndef get_peers_1(content):\n    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n    if len(stored) == 0:\n        peers = tool_rest.get_peers(content)\n        if peers.count > 0:\n            names = []\n            for peer in peers.get():\n                if peer == content[\"symbol\"]:\n                    continue # skip including the query symbol in peers\n                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n                if name != StopGeneration().result:\n                    data = {\"symbol\": peer, \"name\": name}\n                    names.append(data)\n            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n            return names\n        return StopGeneration().result\n    return json.loads(stored[0].docs)[\"peers\"]\n\ndef local_datetime(content):\n    local_t = []\n    for timestamp in content[\"t\"]:\n        local_t.append(local_date_from_epoch(timestamp))\n    return local_t\n\ndef local_date_from_epoch(timestamp):\n    if len(str(timestamp)) == 13:\n        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n    else:\n        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n\ndef get_financials_1(content):\n    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n    if len(stored) == 0:\n        return tool_rest.get_basic_financials(content)\n    return [chunk.docs for chunk in stored]\n\ndef get_news_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n    if len(stored) == 0:\n        return tool_rest.get_news_simple(content)\n    return [NewsTypeFinn.model_validate_json(news.docs).summary().json() for news in stored]\n\ndef get_daily_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n    if len(stored) == 0:\n        candle = tool_rest.get_daily_candle(content)\n        # Attempt to recover from choosing a holiday.\n        candle_date = parse(content[\"date\"])\n        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n            else:\n                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n            return get_daily_candle_2(content)\n        return candle.json()\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_custom_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n        meta_opt=[{\n            \"timespan\": content[\"timespan\"],\n            \"adjusted\": content[\"adjusted\"],\n            \"from\": content[\"from\"],\n            \"to\": content[\"to\"]}])\n    if len(stored) == 0:\n        return tool_rest.get_custom_candle(content)\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_overview_2(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n    if len(stored) == 0:\n        return tool_rest.get_overview(content)\n    return json.loads(stored[0].docs)\n\ndef get_trends_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n    if len(stored) == 0:\n        return tool_rest.get_trends_simple(content)\n    return [json.loads(trend.docs) for trend in stored]\n\ndef get_news_2(content):\n    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n    news_from = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n    news_to = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n    if len(news_from) > 0 and len(news_to) > 0:\n        stored = tool_rag.get_api_documents(\n            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n            [{\"published_utc\": {\"$gte\": timestamp_from}},\n             {\"published_utc\": {\"$lte\": timestamp_to}}])\n        return [NewsTypePoly.model_validate_json(news.docs).summary().json() for news in stored]\n    return tool_rest.get_news_tagged(content)\n        \nfinance_tool = types.Tool(\n    function_declarations=[\n        decl_get_symbol_1,\n        decl_get_symbols_1,\n        decl_get_name_1,\n        decl_get_symbol_quote_1,\n        decl_get_market_status_1,\n        decl_get_market_session_1,\n        decl_get_company_peers_1,\n        decl_get_local_datetime,\n        decl_get_last_market_close,\n        decl_get_exchange_codes_1,\n        decl_get_exchange_code_1,\n        decl_get_financials_1,\n        decl_get_daily_candlestick_2,\n        decl_get_custom_candlestick_2,\n        decl_get_ticker_overview_2,\n        decl_get_recommendation_trends_1,\n        decl_get_news_with_sentiment_2,\n        decl_get_rag_tool_response,\n        decl_get_wiki_tool_response,\n        decl_get_search_tool_response\n    ]\n)\n\nfunction_handler = {\n    \"get_symbol_1\": get_symbol_1,\n    \"get_symbols_1\": get_symbols_1,\n    \"get_name_1\": get_name_1,\n    \"get_symbol_quote_1\": get_quote_1,\n    \"get_market_status_1\": get_market_status_1,\n    \"get_market_session_1\": get_session_1,\n    \"get_company_peers_1\": get_peers_1,\n    \"get_local_datetime\": local_datetime,\n    \"get_last_market_close\": last_market_close,\n    \"get_exchange_codes_1\": get_exchange_codes_1,\n    \"get_exchange_code_1\": get_exchange_code_1,\n    \"get_financials_1\": get_financials_1,\n    \"get_daily_candlestick_2\": get_daily_candle_2,\n    \"get_custom_candlestick_2\": get_custom_candle_2,\n    \"get_ticker_overview_2\": get_overview_2,\n    \"get_recommendation_trends_1\": get_trends_1,\n    \"get_news_with_sentiment_2\": get_news_2,\n    \"get_rag_tool_response\": ask_rag_tool,\n    \"get_wiki_tool_response\": ask_wiki_tool,\n    \"get_search_tool_response\": ask_search_tool\n}","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:24.296626Z","iopub.execute_input":"2025-06-08T05:44:24.296984Z","iopub.status.idle":"2025-06-08T05:44:24.333979Z","shell.execute_reply.started":"2025-06-08T05:44:24.296944Z","shell.execute_reply":"2025-06-08T05:44:24.332965Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## Define the System Prompt","metadata":{}},{"cell_type":"code","source":"# Define the system prompt.\n\ninstruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \nOnly answer the question asked and do not change topic. While the answer is still\nunknown you must follow these rules for predicting function call order:\n\nRULE#1: Always consult your other functions before get_search_tool_response.\nRULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\nRULE#3: Always consult get_search_tool_response last.\nRULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\nRULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:24.335304Z","iopub.execute_input":"2025-06-08T05:44:24.335702Z","iopub.status.idle":"2025-06-08T05:44:24.353231Z","shell.execute_reply.started":"2025-06-08T05:44:24.335661Z","shell.execute_reply":"2025-06-08T05:44:24.352157Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Import the Rest API Keys","metadata":{}},{"cell_type":"code","source":"# Import the finance api secret keys.\n\nPOLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\nFINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:24.354665Z","iopub.execute_input":"2025-06-08T05:44:24.355118Z","iopub.status.idle":"2025-06-08T05:44:24.726835Z","shell.execute_reply.started":"2025-06-08T05:44:24.355049Z","shell.execute_reply":"2025-06-08T05:44:24.725778Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"## The Function Caller","metadata":{}},{"cell_type":"code","source":"# Implement the function calling expert.\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef send_message(prompt):\n    #display(Markdown(\"#### Prompt\"))\n    #print(prompt, \"\\n\")\n    # Define the user prompt part.\n    contents = [types.Content(role=\"user\", parts=[types.Part(text=prompt)])]\n    \n    # Gemini's innate notion of current date and time is unstable.\n    contents += f\"\"\"\n    The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n    \n    Give a concise, and detailed summary. Use information that you learn from the API responses.\n    Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n    to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n    Convert timestamps according to the rules before including them.\n    \"\"\"\n    # Enable system prompt, function calling and minimum-randomness.\n    config_fncall = types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=[finance_tool],\n        temperature=0.0\n    )\n    # Handle cases with multiple chained function calls.\n    function_calling_in_process = True\n    while function_calling_in_process:\n        # Send the user prompt and function declarations.\n        response = api.retriable(api.client.models.generate_content, \n                                 model=api(Gemini.Model.GEN), \n                                 config=config_fncall, \n                                 contents=contents)\n        # A part can be a function call or natural language response.\n        for part in response.candidates[0].content.parts:\n            if function_call := part.function_call:\n                # Extract the function call.\n                fn_name = function_call.name\n                #display(Markdown(\"#### Predicted function name\"))\n                #print(fn_name, \"\\n\")\n                # Extract the function call arguments.\n                fn_args = {key: value for key, value in function_call.args.items()}\n                #display(Markdown(\"#### Predicted function arguments\"))\n                #print(fn_args, \"\\n\")\n                # Call the predicted function.\n                api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n                #display(Markdown(\"#### API response\"))\n                #print(api_response[:500], \"...\", \"\\n\")\n                # Create an API response part.\n                api_response_part = types.Part.from_function_response(\n                    name=fn_name,\n                    response={\"content\": api_response},\n                )\n                # Append the model's function call part.\n                contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n                # Append the api response part.\n                contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n            else:\n                # The model gave a natural language response\n                function_calling_in_process = False\n                break # No more parts in response.\n        if not function_calling_in_process:\n            break # The function calling chain is complete.\n            \n    # Show the final natural language summary\n    display(Markdown(\"#### Natural language response\"))\n    display(Markdown(response.text.replace(\"$\", \"\\\\\\\\$\")))","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-08T05:44:24.72834Z","iopub.execute_input":"2025-06-08T05:44:24.728676Z","iopub.status.idle":"2025-06-08T05:44:24.739219Z","shell.execute_reply.started":"2025-06-08T05:44:24.728643Z","shell.execute_reply":"2025-06-08T05:44:24.738184Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  15\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# Ask a question\n\n<span style=\"font-size:18px;\">\n    If you're on free-tier of Gemini you probably want to Run-before here. Your usage tier can be configured in the api-helper at the top of the notebook.\n</span>","metadata":{}},{"cell_type":"code","source":"send_message(\"What is the current session for US exchanges?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:51:35.987829Z","iopub.execute_input":"2025-06-08T05:51:35.988272Z","iopub.status.idle":"2025-06-08T05:51:39.652128Z","shell.execute_reply.started":"2025-06-08T05:51:35.988231Z","shell.execute_reply":"2025-06-08T05:51:39.651017Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current market session for US exchanges is closed.\n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"send_message(\"What is the US market status?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:51:42.172028Z","iopub.execute_input":"2025-06-08T05:51:42.17297Z","iopub.status.idle":"2025-06-08T05:51:44.279089Z","shell.execute_reply.started":"2025-06-08T05:51:42.172925Z","shell.execute_reply":"2025-06-08T05:51:44.278055Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The US market is currently closed as of Sun Jun 8 01:51:23 2025 America/New_York time. There is no holiday today. The market session is closed.\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"send_message(\"When was the last US market close?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:51:49.579305Z","iopub.execute_input":"2025-06-08T05:51:49.580385Z","iopub.status.idle":"2025-06-08T05:51:52.99888Z","shell.execute_reply.started":"2025-06-08T05:51:49.580326Z","shell.execute_reply":"2025-06-08T05:51:52.997909Z"}},"outputs":[{"name":"stdout","text":"api.on_error.next_model: model is now  gemini-2.0-flash-exp\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The last market close for the US exchange was on Friday, June 6, 2025, at 8:00 PM local time.\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"send_message(\"What is Apple's stock ticker?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:52:02.439054Z","iopub.execute_input":"2025-06-08T05:52:02.440197Z","iopub.status.idle":"2025-06-08T05:52:03.9175Z","shell.execute_reply.started":"2025-06-08T05:52:02.440149Z","shell.execute_reply":"2025-06-08T05:52:03.916482Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker for Apple is AAPL.\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"send_message(\"What is the current price of Amazon stock?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:52:58.893185Z","iopub.execute_input":"2025-06-08T05:52:58.893617Z","iopub.status.idle":"2025-06-08T05:53:01.327241Z","shell.execute_reply.started":"2025-06-08T05:52:58.893576Z","shell.execute_reply":"2025-06-08T05:53:01.326315Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current price of Amazon (AMZN) stock is \\\\$213.57. The price changed by \\\\$5.66, which is a 2.7223% increase. The high price of the day is \\\\$213.8699, and the low price of the day is \\\\$210.5. The opening price of the day was \\\\$212.4, and the previous close price was \\\\$207.91. The price was last updated on Sat Jun 7 16:00:00 2025.\n"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"send_message(\"show me Apple's basic financials\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:53:19.151734Z","iopub.execute_input":"2025-06-08T05:53:19.152161Z","iopub.status.idle":"2025-06-08T05:53:24.827597Z","shell.execute_reply.started":"2025-06-08T05:53:19.152122Z","shell.execute_reply":"2025-06-08T05:53:24.826572Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is a summary of Apple's basic financials:\n\n**Financial Highlights:**\n\n*   **Cash Flow:** The trailing twelve months cash flow per share is 6.86253.\n*   **Dividends:** The current trailing twelve months dividend yield is 0.5028%. The indicated annual dividend yield is 0.5183671.\n*   **Profitability:**\n    *   The trailing twelve months net profit margin is 24.3%.\n    *   The trailing twelve months operating margin is 31.81%.\n*   **Valuation:**\n    *   The price to book value is 45.5972.\n    *   The trailing twelve months price to earnings ratio is 31.3042.\n*   **Asset Utilization:** The asset turnover for the trailing twelve months is 1.1673.\n*   **Debt:** The long term debt to equity ratio annually is 1.5057, and quarterly is 1.1762.\n*   **Market Performance:**\n    *   The 52 week high was 260.1, recorded on December 26, 2024.\n    *   The 52 week low was 169.2101, recorded on April 8, 2025.\n\n**Additional Information:**\n\n*   The enterprise value is 3115737.8 million.\n*   The market capitalization is 3045713.8 million.\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"send_message(\"I need Apple's daily candlestick from 2025-05-06\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:54:24.325022Z","iopub.execute_input":"2025-06-08T05:54:24.325449Z","iopub.status.idle":"2025-06-08T05:54:26.833245Z","shell.execute_reply.started":"2025-06-08T05:54:24.325413Z","shell.execute_reply":"2025-06-08T05:54:26.83221Z"}},"outputs":[{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"On May 6, 2025, Apple's stock (AAPL) had the following daily candlestick data:\n*   After-hours price: 201.15\n*   Closing price: 198.51\n*   High price: 200.65\n*   Low price: 197.02\n*   Opening price: 198.21\n*   Pre-market price: 198.65\n*   Volume: 51,216,482\n"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"send_message(\"Tell me who are Apple's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:54:44.621046Z","iopub.execute_input":"2025-06-08T05:54:44.621547Z","iopub.status.idle":"2025-06-08T05:54:46.200045Z","shell.execute_reply.started":"2025-06-08T05:54:44.621501Z","shell.execute_reply":"2025-06-08T05:54:46.199043Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The peers of Apple, as identified by their sub-industry, are Dell Technologies - C (DELL), Super Micro Computer Inc (SMCI), Hewlett Packard Enterprise (HPE), HP Inc (HPQ), NetApp Inc (NTAP), Western Digital Corp (WDC), Pure Storage Inc - Class A (PSTG), and IonQ Inc (IONQ).\n"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"send_message(\"Show me the recommendation trends for all of Apple's peers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:55:51.885557Z","iopub.execute_input":"2025-06-08T05:55:51.886425Z","iopub.status.idle":"2025-06-08T05:56:01.095026Z","shell.execute_reply.started":"2025-06-08T05:55:51.886377Z","shell.execute_reply":"2025-06-08T05:56:01.093937Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is a summary of the recommendation trends for Apple's peers:\n\n*   **Dell Technologies (DELL):** The recommendation trends for Dell Technologies show a consistent outlook from March 2025 to June 2025. The consensus is positive, with a majority of analysts recommending a \"buy\". Specifically, the number of \"buy\" recommendations ranges from 20 to 21, \"hold\" recommendations remain stable at 4, and there are 5 to 6 \"strong buy\" recommendations. There are no \"sell\" or \"strong sell\" recommendations.\n*   **Super Micro Computer (SMCI):** The recommendation trends for Super Micro Computer show a generally positive sentiment. \"Buy\" recommendations increased from 7 in March 2025 to 10 in June 2025. \"Hold\" recommendations also increased from 8 in March 2025 to 10 in June 2025. There are 2 \"sell\" recommendations and 2 \"strong buy\" recommendations across the months.\n*   **Hewlett Packard Enterprise (HPE):** The recommendation trends for Hewlett Packard Enterprise show a stable outlook from March 2025 to June 2025. The consensus is positive, with a mix of \"buy\" and \"hold\" recommendations. The number of \"buy\" recommendations is either 6 or 7, \"hold\" recommendations are either 8 or 9, and there are 4 \"strong buy\" recommendations. There are no \"sell\" or \"strong sell\" recommendations.\n*   **HP Inc (HPQ):** The recommendation trends for HP Inc show a consistent outlook from March 2025 to June 2025. The majority of analysts recommend a \"hold\". Specifically, there are 4 \"buy\" recommendations, 13 \"hold\" recommendations, 1 \"sell\" recommendation, and 2 \"strong buy\" recommendations across the months.\n*   **NetApp (NTAP):** The recommendation trends for NetApp show a stable outlook with a slight increase in \"buy\" recommendations from March 2025 to June 2025. The number of \"buy\" recommendations increased from 8 to 9, \"hold\" recommendations decreased from 17 to 16, and there are 3 \"strong buy\" recommendations. There are no \"sell\" or \"strong sell\" recommendations.\n*   **Western Digital (WDC):** The recommendation trends for Western Digital show a positive sentiment with increasing \"buy\" recommendations from March 2025 to June 2025. The number of \"buy\" recommendations increased from 15 to 19, \"hold\" recommendations decreased from 9 to 5, and there are 6 \"strong buy\" recommendations. There are no \"sell\" or \"strong sell\" recommendations.\n*   **Pure Storage (PSTG):** The recommendation trends for Pure Storage show a consistent outlook from March 2025 to June 2025. The consensus is positive, with a majority of analysts recommending a \"buy\". Specifically, there are 13 \"buy\" recommendations, 6 \"hold\" recommendations, 1 \"sell\" recommendation, and 8 \"strong buy\" recommendations across the months.\n*   **IonQ (IONQ):** The recommendation trends for IonQ show a stable outlook from March 2025 to June 2025. The consensus is positive, with a majority of analysts recommending a \"buy\". Specifically, there are 7 \"buy\" recommendations, 2 \"hold\" recommendations, and 2 \"strong buy\" recommendations across the months. There are no \"sell\" or \"strong sell\" recommendations."},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"send_message(\"Tell me who are Amazon's peers?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:55:18.885463Z","iopub.execute_input":"2025-06-08T05:55:18.885916Z","iopub.status.idle":"2025-06-08T05:55:20.350482Z","shell.execute_reply.started":"2025-06-08T05:55:18.885878Z","shell.execute_reply":"2025-06-08T05:55:20.349463Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon's peers in the subIndustry grouping are: Coupang Inc (CPNG), Ebay Inc (EBAY), Ollie's Bargain Outlet Holdings (OLLI), Etsy Inc (ETSY), Dillards Inc-Cl A (DDS), Macy's Inc (M), Savers Value Village Inc (SVV), and Groupon Inc (GRPN).\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  15\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"#api.set_default_model(3) # generate with gemini-2.5-flash-preview\nsend_message(\n    \"\"\"Tell me Amazon's current share price and provide candlestick data for the past month.\n    Sort the data in descending order by date. Format the prices consistently as currency.\n    Round prices to two decimal places.\n    Present the data with multiple columns for display in markdown.\n    Discuss and provide details about any patterns you notice in the price data.\"\"\")\napi.set_default_model(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:00:28.433529Z","iopub.execute_input":"2025-06-08T06:00:28.43402Z","iopub.status.idle":"2025-06-08T06:00:38.873122Z","shell.execute_reply.started":"2025-06-08T06:00:28.433976Z","shell.execute_reply":"2025-06-08T06:00:38.872055Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current share price of Amazon (AMZN) is \\\\$213.57 as of June 7, 2025.\n\nHere is the candlestick data for the past month (May 7, 2025 to June 6, 2025), sorted in descending order by date:\n\n| Date       | Open    | High    | Low     | Close   | Volume      |\n| ---------- | ------- | ------- | ------- | ------- | ----------- |\n| 2025-06-06 | \\\\$212.40 | \\\\$213.87 | \\\\$210.50 | \\\\$213.57 | 39,832,500  |\n| 2025-06-05 | \\\\$209.55 | \\\\$212.81 | \\\\$207.56 | \\\\$207.91 | 51,979,243  |\n| 2025-06-04 | \\\\$206.55 | \\\\$208.18 | \\\\$205.18 | \\\\$207.23 | 29,915,592  |\n| 2025-06-03 | \\\\$207.11 | \\\\$208.95 | \\\\$205.03 | \\\\$205.71 | 33,139,121  |\n| 2025-06-02 | \\\\$204.98 | \\\\$207.00 | \\\\$202.68 | \\\\$206.65 | 29,113,319  |\n| 2025-05-30 | \\\\$208.03 | \\\\$208.81 | \\\\$204.23 | \\\\$205.70 | 34,700,005  |\n| 2025-05-29 | \\\\$203.09 | \\\\$206.69 | \\\\$202.19 | \\\\$206.02 | 34,892,044  |\n| 2025-05-28 | \\\\$205.92 | \\\\$207.66 | \\\\$204.41 | \\\\$204.72 | 28,549,753  |\n| 2025-05-27 | \\\\$204.84 | \\\\$205.99 | \\\\$201.70 | \\\\$205.01 | 51,679,406  |\n| 2025-05-23 | \\\\$211.45 | \\\\$211.93 | \\\\$208.85 | \\\\$210.25 | 38,492,128  |\n| 2025-05-22 | \\\\$211.08 | \\\\$214.84 | \\\\$210.10 | \\\\$211.37 | 56,193,682  |\n| 2025-05-21 | \\\\$206.45 | \\\\$206.88 | \\\\$202.67 | \\\\$205.17 | 64,347,317  |\n| 2025-05-20 | \\\\$210.71 | \\\\$211.66 | \\\\$205.75 | \\\\$208.64 | 75,205,042  |\n| 2025-05-19 | \\\\$201.65 | \\\\$206.62 | \\\\$201.26 | \\\\$206.16 | 34,314,810  |\n| 2025-05-16 | \\\\$204.63 | \\\\$205.59 | \\\\$202.65 | \\\\$204.07 | 29,470,373  |\n| 2025-05-15 | \\\\$201.38 | \\\\$205.76 | \\\\$200.16 | \\\\$203.10 | 38,938,882  |\n| 2025-05-14 | \\\\$198.90 | \\\\$202.37 | \\\\$197.85 | \\\\$200.99 | 33,393,545  |\n| 2025-05-13 | \\\\$201.61 | \\\\$203.46 | \\\\$200.06 | \\\\$201.12 | 42,460,924  |\n| 2025-05-12 | \\\\$206.85 | \\\\$206.85 | \\\\$204.37 | \\\\$205.59 | 43,318,478  |\n| 2025-05-09 | \\\\$193.38 | \\\\$194.69 | \\\\$191.16 | \\\\$193.06 | 29,663,143  |\n| 2025-05-08 | \\\\$191.43 | \\\\$194.33 | \\\\$188.82 | \\\\$192.08 | 41,043,620  |\n| 2025-05-07 | \\\\$185.56 | \\\\$190.99 | \\\\$185.01 | \\\\$188.71 | 44,002,926  |\n\n**Summary:**\n\nOver the past month, Amazon's stock price has shown an overall upward trend, starting from \\\\$188.71 on May 7, 2025, and closing at \\\\$213.57 on June 6, 2025. There have been fluctuations throughout the month, with periods of both increases and decreases in price. Notably, there was a significant jump in price between May 7 and May 22, followed by a period of consolidation and further gains towards the end of the month. The trading volume has also varied, with higher volumes often coinciding with larger price movements.\n"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"send_message(\"What is Apple's ticker overview\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T05:59:46.392605Z","iopub.execute_input":"2025-06-08T05:59:46.39311Z","iopub.status.idle":"2025-06-08T05:59:48.404237Z","shell.execute_reply.started":"2025-06-08T05:59:46.39305Z","shell.execute_reply":"2025-06-08T05:59:48.402985Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple Incorporated, ticker symbol AAPL, is a major player in the stock market, listed on the XNAS exchange. The company's Central Index Key (CIK) is 0000320193, its composite Financial Instrument Global Identifier (FIGI) is BBG000B9XRY4, and its share class FIGI is BBG001S5N8V8. With a market capitalization of 3,012,556,104,200 United States dollars, Apple has a broad portfolio of hardware and software products. The company employs 164,000 people. Apple's initial listing date was December 12, 1980.\n"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"send_message(\"Tell me about Amazon's historical and current recommendation trends\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:01:12.006683Z","iopub.execute_input":"2025-06-08T06:01:12.007485Z","iopub.status.idle":"2025-06-08T06:01:14.439376Z","shell.execute_reply.started":"2025-06-08T06:01:12.007437Z","shell.execute_reply":"2025-06-08T06:01:14.438445Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of June 8, 2025, the recommendation trends for Amazon (AMZN) are as follows:\n\nIn June 2025, there are 50 buy recommendations, 24 strong buy recommendations and 5 hold recommendations.\nIn May 2025, there are 51 buy recommendations, 22 strong buy recommendations and 6 hold recommendations.\nIn April 2025, there are 50 buy recommendations, 23 strong buy recommendations and 4 hold recommendations.\nIn March 2025, there are 51 buy recommendations, 21 strong buy recommendations and 5 hold recommendations.\nThere are no sell or strong sell recommendations in any of the months listed.\n"},"metadata":{}},{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"send_message(\"What is Google's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:02:05.505675Z","iopub.execute_input":"2025-06-08T06:02:05.506243Z","iopub.status.idle":"2025-06-08T06:02:08.934274Z","shell.execute_reply.started":"2025-06-08T06:02:05.506194Z","shell.execute_reply":"2025-06-08T06:02:08.933172Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Google's stock ticker symbols are GOOGL and GOOG on the NASDAQ stock exchange. It is also listed on the Frankfurt Stock Exchange under the ticker symbol GGQ1. These symbols refer to Alphabet Inc., Google's holding company. Google's initial public offering (IPO) took place on August 19, 2004, opening on the NASDAQ National Market under the ticker symbol GOOGL.\n"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"#api.set_default_model(3) # generate with gemini-2.5-flash-preview\nsend_message(\"What is MGM Studio's stock symbol?\")\napi.set_default_model(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:02:13.378402Z","iopub.execute_input":"2025-06-08T06:02:13.379581Z","iopub.status.idle":"2025-06-08T06:02:23.173862Z","shell.execute_reply.started":"2025-06-08T06:02:13.37953Z","shell.execute_reply":"2025-06-08T06:02:23.17266Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.on_error.next_model: model is now  gemini-2.0-flash-exp\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I was unable to find the stock symbol for Mgm Studios."},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"#api.set_default_model(3) # generate with gemini-2.5-flash-preview\nsend_message(\"What is Amazon MGM Studio's stock symbol?\")\napi.set_default_model(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:02:27.226233Z","iopub.execute_input":"2025-06-08T06:02:27.226687Z","iopub.status.idle":"2025-06-08T06:02:44.421246Z","shell.execute_reply.started":"2025-06-08T06:02:27.226651Z","shell.execute_reply":"2025-06-08T06:02:44.42015Z"}},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon MGM Studios is a subsidiary of Amazon, and Amazon's stock symbol is AMZN.\n"},"metadata":{}},{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"send_message(\"What is Facebook's stock ticker symbol?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:03:13.726553Z","iopub.execute_input":"2025-06-08T06:03:13.727515Z","iopub.status.idle":"2025-06-08T06:03:17.407601Z","shell.execute_reply.started":"2025-06-08T06:03:13.727467Z","shell.execute_reply":"2025-06-08T06:03:17.406371Z"}},"outputs":[{"name":"stderr","text":"Score similarity to stored grounding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbol for Facebook is META and it is listed on the NASDAQ.\n"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"send_message(\n    '''Tell me about Amazon's current bullish versus bearish predictions, and recommendation trends.\n    Include a discussion of any short-term trends, and sentiment analysis.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:03:40.503363Z","iopub.execute_input":"2025-06-08T06:03:40.503836Z","iopub.status.idle":"2025-06-08T06:03:45.178186Z","shell.execute_reply.started":"2025-06-08T06:03:40.503801Z","shell.execute_reply":"2025-06-08T06:03:45.177109Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"As of June 8, 2025, here's a summary of Amazon's bullish versus bearish predictions and recommendation trends:\n\n**Recommendation Trends:**\n\n*   Based on analyst recommendations, the trend is strongly bullish. In June 2025, there are 24 strong buy recommendations, 51 buy recommendations, and 5 hold recommendations. There are no sell or strong sell recommendations.\n*   The number of strong buy recommendations has increased slightly from 22 in May 2025 to 24 in June 2025, indicating a strengthening bullish sentiment.\n\n**Sentiment Analysis:**\n\n*   The news articles from May 8, 2025, to June 1, 2025, show a predominantly positive sentiment toward Amazon.\n*   Many articles highlight Amazon's strong position in e-commerce, cloud computing (Amazon Web Services), and digital advertising as key drivers of growth.\n*   Several articles suggest that Amazon is a good buy for long-term investors, citing its attractive valuation and growth potential in AI and other emerging technologies.\n*   Some articles mention potential headwinds, such as tariffs and increased competition, but overall, the sentiment remains positive due to Amazon's diversified business model and strong market position.\n*   Bill Ackman's Pershing Square has taken a new stake in Amazon, adding to the bullish sentiment around the stock.\n*   Several articles highlight Amazon's investments in AI and its potential to become a \\\\$5 trillion company.\n\n**Short-Term Trends:**\n\n*   The news articles suggest that Amazon's stock has recovered nearly 30% since its April low, driven by improving trade relations between the U.S. and China.\n*   Analysts are bullish on the stock, citing margin expansion, leadership in cloud and advertising, and cost discipline.\n*   However, some articles mention near-term uncertainties, such as slowing growth in online sales and potential regulatory crackdowns.\n\n**Overall Summary:**\n\nThe overall sentiment towards Amazon is strongly bullish, with analysts recommending a buy rating and numerous articles highlighting the company's growth potential in various sectors. While there are some short-term uncertainties, the long-term outlook for Amazon remains positive due to its diversified business model, strong market position, and investments in emerging technologies like AI.\n"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"send_message(\n    '''Tell me about Google's share price over the past month.\n    Perform a sentiment analysis of news during the same period. Include trends.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:04:16.691727Z","iopub.execute_input":"2025-06-08T06:04:16.692248Z","iopub.status.idle":"2025-06-08T06:04:26.077494Z","shell.execute_reply.started":"2025-06-08T06:04:16.692201Z","shell.execute_reply":"2025-06-08T06:04:26.076495Z"}},"outputs":[{"name":"stderr","text":"Score similarity to stored grounding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's a summary of Google's (Alphabet Inc.) stock price and news sentiment over the past month (May 8, 2025, to June 6, 2025):\n\n**Ticker Symbols:** Alphabet Inc. has two ticker symbols: GOOGL (Class A shares with voting rights) and GOOG (Class C shares with no voting rights).\n\n**News Sentiment:**\nThe news sentiment surrounding Alphabet has been largely positive, focusing on the company's advancements in artificial intelligence (AI) and its potential impact on future growth. Here's a breakdown of the key themes:\n\n*   **AI Advancements:** Many articles highlight Alphabet's progress in AI, particularly showcased at the Google I/O event. This includes AI-powered search, Android XR, and the Gemini AI model. These advancements are seen as a way for Google to fend off competition and drive future growth.\n*   **Undervalued Stock:** Several articles suggest that Alphabet's stock is undervalued, trading at a discount compared to its AI rivals and the S\\&P 500 average. This is attributed to investors underestimating Alphabet's AI capabilities and ecosystem.\n*   **Analyst Confidence:** Analysts and institutional investors express strong confidence in Alphabet's long-term prospects, citing its robust business and growth drivers in AI, cloud computing, and YouTube.\n*   **Potential Challenges:** Some articles mention potential challenges, such as Apple's exploration of AI-powered search alternatives and potential antitrust regulation. However, these concerns are often balanced by the company's strong financial position and diversified business model.\n*   **Waymo as a Growth Driver:** Alphabet's autonomous taxi service, Waymo, is highlighted as a potential hidden driver for the company's future growth and partnerships.\n*   **Saudi Investment:** Alphabet is among the companies involved in joint tech investments with Saudi Arabia.\n*   **Bill Ackman's Investment:** Bill Ackman's hedge fund has a significant portion of its portfolio invested in Alphabet, indicating his belief in the stock.\n*   **Cathie Wood's Prediction:** Cathie Wood, CEO of ARK Invest, believes that AI will disrupt traditional search engines like Google.\n\n**Mixed Sentiment:**\nSome articles present mixed sentiment, acknowledging both the opportunities and challenges facing Alphabet. For example, one article discusses the potential impact of Apple introducing AI-powered search tools in Safari on Alphabet's search dominance but argues that Alphabet's strong integration across various services makes it unlikely for Apple's move to significantly disrupt Google's search business.\n\n**Overall:**\nThe news sentiment suggests that Alphabet is well-positioned to benefit from the growth in AI, with its strong financial position, diversified business model, and investments in next-generation technologies. While there are some potential challenges, analysts and investors remain largely confident in the company's long-term prospects.\n\n**Disclaimer:** I am an AI chatbot and cannot provide financial advice. This information is for informational purposes only.\n"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"send_message(\n    '''How is the outlook for Apple based on trends and news sentiment over the past month?\n    Perform the same analysis on all of Apple's peers. Then compare Apple result to it's peers.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:04:34.413416Z","iopub.execute_input":"2025-06-08T06:04:34.414266Z","iopub.status.idle":"2025-06-08T06:05:49.380643Z","shell.execute_reply.started":"2025-06-08T06:04:34.414216Z","shell.execute_reply":"2025-06-08T06:05:49.37962Z"}},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"limited 5/min, waiting 46.17237114906311s\napi.refill_rpm  15\n","output_type":"stream"},{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The outlook for Apple (AAPL) is mixed based on recent trends and news sentiment.\n\n**Recommendation Trends:**\n*   Analyst recommendations for Apple show a generally positive sentiment, with a majority of analysts rating the stock as a \"buy\" or \"strong buy.\" In June 2025, there were 25 \"buy\" ratings, 13 \"hold\" ratings, 15 \"strong buy\" ratings, 3 \"sell\" ratings, and 1 \"strong sell\" rating.\n\n**News Sentiment:**\n*   The news sentiment surrounding Apple is mixed. Some articles highlight positive aspects such as Warren Buffett's continued investment in Apple, the potential for growth in the services segment, and the company's strong brand and ecosystem.\n*   However, there are also concerns about potential tariffs, slowing iPhone sales growth, and increasing competition in the AI space. Some articles suggest that Apple's valuation is high and that the stock may be overvalued.\n\n**Peer Analysis:**\nHere's a summary of the news sentiment for Apple's peers over the past month:\n\n*   **Dell Technologies (DELL):** The sentiment is generally positive, with mentions of its involvement in energy efficiency standards, the growing storage systems market, and its AI server business.\n*   **Super Micro Computer (SMCI):** The sentiment is mixed. While the company is benefiting from the AI hardware industry and has a partnership with the Saudi government, it has also faced accounting issues and experienced stock declines due to disappointing results.\n*   **Hewlett Packard Enterprise (HPE):** The sentiment is generally positive, with mentions of its involvement in energy efficiency standards, the growing storage systems market, and its collaboration with Nvidia on AI solutions.\n*   **HP Inc (HPQ):** The sentiment is negative, with the company reporting mixed earnings and cutting its outlook.\n*   **NetApp Inc (NTAP):** The sentiment is neutral, with mentions of its presence in the growing storage systems market but no specific details about its performance.\n*   **Western Digital Corp (WDC):** The sentiment is neutral, with mentions of its presence in the growing storage systems market but no specific details about its performance.\n*   **Pure Storage Inc (PSTG):** The sentiment is generally positive, with expectations of margin expansion and increased demand due to AI.\n*   **IonQ Inc (IONQ):** The sentiment is negative, with concerns about its high valuation, unimpressive sales, and the uncertainty around the practical applications of quantum computing.\n\n**Comparative Summary:**\n\n*   Apple's recommendation trends are generally positive, but the news sentiment is mixed due to concerns about tariffs and competition.\n*   Among Apple's peers, Dell Technologies and Hewlett Packard Enterprise have generally positive news sentiment, while HP Inc has negative sentiment. Super Micro Computer and IonQ have mixed to negative sentiment. NetApp and Western Digital have neutral sentiment.\n*   Overall, Apple's outlook is comparable to its peers in the hardware and IT infrastructure space, with both positive and negative factors influencing investor sentiment.\n\nIn conclusion, Apple's outlook is cautiously optimistic, with potential for growth in the services segment and AI, but also facing challenges from tariffs and competition. The peer analysis reveals a mixed sentiment in the industry, with some companies showing strong growth potential while others face challenges.\n"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"send_message(\n    '''What does the recent news say about Apple and the impact of tariffs? From 2025-03-01 up to today.\n    Discuss and provide details about any patterns you notice in the price data. Ignore duplicate entry.''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-08T06:06:50.857433Z","iopub.execute_input":"2025-06-08T06:06:50.857922Z","iopub.status.idle":"2025-06-08T06:06:57.446918Z","shell.execute_reply.started":"2025-06-08T06:06:50.857875Z","shell.execute_reply":"2025-06-08T06:06:57.445909Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The recent news regarding Apple (AAPL) and the impact of tariffs between March 1, 2025, and June 6, 2025, reveals a complex situation with both challenges and attempts to mitigate negative effects. Here's a summary:\n\n**Key Themes:**\n\n*   **Tariff Impact on Earnings:** Several articles mention that tariffs are expected to cost Apple hundreds of millions to nearly \\\\$1 billion in upcoming quarters, impacting net income growth.\n*   **Production Shifts:** Apple is reportedly shifting some production to countries like India and Vietnam to avoid tariffs on Chinese imports.\n*   **Potential Cost Increases:** Tariffs could lead to a significant surge in iPhone production costs, potentially forcing Apple to raise prices or move production to the U.S., which analysts deem unfeasible.\n*   **Trade Policy Uncertainty:** President Trump's trade policies and tariff threats create uncertainty for Apple, potentially increasing costs and forcing price increases.\n*   **Temporary Relief:** Apple has received temporary exemptions from some tariffs, providing some relief, but a semiconductor-specific tariff is expected in the near future.\n*   **Analyst Concerns:** Analysts have expressed concerns about the impact of tariffs on Apple's profitability, sales growth, and valuation, leading to price target cuts.\n*   **Market Volatility:** Announcements regarding tariffs and trade tensions have caused market sell-offs, impacting Apple's stock price.\n*   **Positive Developments:** There have been some positive developments, such as a temporary pause on elevated tariff rates and potential court rulings against tariffs, which have led to rallies in Apple's stock.\n*   **AI and Innovation:** Apple is reportedly developing AI-powered smart glasses and working on Apple Intelligence to increase iPhone sales, indicating a focus on innovation to drive growth.\n\n**Patterns in Price Data (based on news sentiment):**\n\n*   **Negative Sentiment:** News of increased tariffs, potential cost increases, and negative analyst outlooks generally correlate with a sinking stock price for Apple.\n*   **Positive Sentiment:** Temporary tariff exemptions, potential court rulings against tariffs, and positive developments in trade talks tend to lead to a surge in Apple's stock price.\n*   **Uncertainty:** Overall, the news suggests that Apple's stock price is highly sensitive to developments in trade policy and tariff announcements, leading to volatility.\n\n**Summary:**\n\nApple faces significant challenges due to tariffs and trade tensions, which are expected to impact its earnings and operations. The company is taking steps to mitigate these effects by shifting production and focusing on innovation. However, uncertainty remains, and Apple's stock price is likely to be volatile in response to developments in trade policy.\n"},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  15\n","output_type":"stream"}],"execution_count":66},{"cell_type":"markdown","source":"# Conclusion\n\n<span style=\"font-size:18px;\">\nFor now that will have to do. Our Essy has a solid foundation but more could be done to organise metadata. No evaluation or validation has been performed (except fuzzing the prompt). Next steps include restructuring the vector database based on lessons learned. That'll be followed by plotting, multi-modal, and structured output. The last close date (generative) function can be temperamental. In the same way Gemini always feels regarding dates. I've learnt so much. I'm happy I decided to participate in the event! It really has been a joy to see Essy grow from random chat with Gemini into the foundation for a good-broker buddy. I hope you enjoy playing with this edition as much as I enjoyed building it!\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Update June 7, 2025\n\n<span style=\"font-size:18px;\">\n    Bugfix version 102 finally brings Essy to a stable milestone. A month and a half late :) There's still more to be built including adding reasoning, agents, and structured output. A few unimplemented rest endpoints remain that could make Essy more self-reliant. The vector store has gotten bigger but not smarter. Essy can tell us pre-scored news has some sentiment but cannot generate it due to limited summaries. Essy can detect interesting patterns in a dataset but not between adjacent datasets. There's so much data we'll need to recruit Essy some help.\n</span>","metadata":{}},{"cell_type":"markdown","source":"# Advanced (localhost required)\n\n<span style=\"font-size:18px;\">\n    The functions demonstrated here require a locally running notebook. Additional dependencies include <a href=\"https://www.selenium.dev/documentation/grid/getting_started/\">selenium-server</a> running on localhost. A dedicated GPU with at least 8GB VRAM is recommended but not required. Output is generated with Gemma 3 12B QAT, Gemma.cpp, and (later) Gemma 3n. Output on Kaggle is based on cached data.\n</span>","metadata":{}},{"cell_type":"code","source":"# soon","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null}]}